{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtrJDlV4lcnDABSf1/Va8g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5983c75c9c3441338cc4607809397769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8388ad0257c445509ab9ea3ce173f9d1",
              "IPY_MODEL_4e03a3d91399428e99254b1957d47750",
              "IPY_MODEL_918a9c6d482744d19c85c9c469e88abb"
            ],
            "layout": "IPY_MODEL_911cee2858b542e4ae4353a0080aae66"
          }
        },
        "8388ad0257c445509ab9ea3ce173f9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ddbfe235694a9e9c0870fc7127bcdc",
            "placeholder": "​",
            "style": "IPY_MODEL_58dd1009c09446ba988151b3b5649707",
            "value": "config.json: 100%"
          }
        },
        "4e03a3d91399428e99254b1957d47750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d68456e6a5f4bcb89abf86db26580e4",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c723645b9b3441c9023cef3d30a9e46",
            "value": 570
          }
        },
        "918a9c6d482744d19c85c9c469e88abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b44c587901a4f9ea94497db32bc956d",
            "placeholder": "​",
            "style": "IPY_MODEL_0fcd4f2751a34271bc3f785dd00e8bf5",
            "value": " 570/570 [00:00&lt;00:00, 29.2kB/s]"
          }
        },
        "911cee2858b542e4ae4353a0080aae66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ddbfe235694a9e9c0870fc7127bcdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58dd1009c09446ba988151b3b5649707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d68456e6a5f4bcb89abf86db26580e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c723645b9b3441c9023cef3d30a9e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b44c587901a4f9ea94497db32bc956d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fcd4f2751a34271bc3f785dd00e8bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eefd692688974c3ea99ddb622986899b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84bf510848ea46d6883004aa9f898018",
              "IPY_MODEL_c5f2bd42342043479e77a9236f57f178",
              "IPY_MODEL_d179cb1bb853430cb34986953e5fb4b2"
            ],
            "layout": "IPY_MODEL_8c09e2824fe344638214f7a635d6dfb3"
          }
        },
        "84bf510848ea46d6883004aa9f898018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62c385be836d465c9114e20b8f731896",
            "placeholder": "​",
            "style": "IPY_MODEL_66e7083084de4060b8ed188c7a7c1dc1",
            "value": "model.safetensors: 100%"
          }
        },
        "c5f2bd42342043479e77a9236f57f178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0fa7a6d060748289eb172390746c6fc",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97fcf24872d14dd298d0edf703d7f4cd",
            "value": 440449768
          }
        },
        "d179cb1bb853430cb34986953e5fb4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba3e424241854fda98654bc2e467c23f",
            "placeholder": "​",
            "style": "IPY_MODEL_da67ed177b52441ba16ad65c5870463c",
            "value": " 440M/440M [00:02&lt;00:00, 227MB/s]"
          }
        },
        "8c09e2824fe344638214f7a635d6dfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c385be836d465c9114e20b8f731896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e7083084de4060b8ed188c7a7c1dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0fa7a6d060748289eb172390746c6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97fcf24872d14dd298d0edf703d7f4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba3e424241854fda98654bc2e467c23f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da67ed177b52441ba16ad65c5870463c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f5217139ad445afa7e667cba49aabd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe1a74c1b0e7410c8581c24f692673ac",
              "IPY_MODEL_1495e910eb1a4a47bf72274c84d46fac",
              "IPY_MODEL_39bc3600ea75423dbf029b6d5a3300df"
            ],
            "layout": "IPY_MODEL_f93e7fbe49cf49c591b521976e4f29d3"
          }
        },
        "fe1a74c1b0e7410c8581c24f692673ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d896f2e5ad141b3b34adb3946b32a64",
            "placeholder": "​",
            "style": "IPY_MODEL_031a39f505c34a39a38e9466552c2a4b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1495e910eb1a4a47bf72274c84d46fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52ddebc74e2438eb7fe25d670e94625",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2c89b96d77a4747b6c02e516a3bb1f0",
            "value": 48
          }
        },
        "39bc3600ea75423dbf029b6d5a3300df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74bd0e7c4cfd4f22afee35793056413c",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec6675fd5074cd4ae3861806a1e7235",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.84kB/s]"
          }
        },
        "f93e7fbe49cf49c591b521976e4f29d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d896f2e5ad141b3b34adb3946b32a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031a39f505c34a39a38e9466552c2a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f52ddebc74e2438eb7fe25d670e94625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c89b96d77a4747b6c02e516a3bb1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74bd0e7c4cfd4f22afee35793056413c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec6675fd5074cd4ae3861806a1e7235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f57b69ce770400d83266d5f40cb9483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d0fb57c3c18459097f23e70d1892740",
              "IPY_MODEL_d06fa43398dc416ebcf33e859ac4ba39",
              "IPY_MODEL_d2de471a69f543fc897fa449610edbc1"
            ],
            "layout": "IPY_MODEL_22a73abed69e40dca1c2d8ec7b2cbb76"
          }
        },
        "5d0fb57c3c18459097f23e70d1892740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50542bd94ab4716b066d25c008b9940",
            "placeholder": "​",
            "style": "IPY_MODEL_da2e7e6534044122a3d02520fa480d75",
            "value": "vocab.txt: 100%"
          }
        },
        "d06fa43398dc416ebcf33e859ac4ba39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa30c39b0fdb4607abef8f71be0e543a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d1deefc4f02420695cf0260f5b42ccb",
            "value": 231508
          }
        },
        "d2de471a69f543fc897fa449610edbc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02c3689502c046f290d2a18d6d703e24",
            "placeholder": "​",
            "style": "IPY_MODEL_76462b31f5484fdcb409f47749552fec",
            "value": " 232k/232k [00:00&lt;00:00, 1.42MB/s]"
          }
        },
        "22a73abed69e40dca1c2d8ec7b2cbb76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50542bd94ab4716b066d25c008b9940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2e7e6534044122a3d02520fa480d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa30c39b0fdb4607abef8f71be0e543a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1deefc4f02420695cf0260f5b42ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02c3689502c046f290d2a18d6d703e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76462b31f5484fdcb409f47749552fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67f52a0496bb4626a5c6b0092c2dc6c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96a6c8c05330417a8989a744765119d5",
              "IPY_MODEL_328ce1de144c461a89f3f621039a11e5",
              "IPY_MODEL_83f92ab1935d4f43ba19624de7ef76de"
            ],
            "layout": "IPY_MODEL_3416ff8e50c04487af4895754eb6464c"
          }
        },
        "96a6c8c05330417a8989a744765119d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e33ddcc3154910a01ec0a038f006d6",
            "placeholder": "​",
            "style": "IPY_MODEL_9e9ad0ec119b486f9d6c52e864b4404e",
            "value": "tokenizer.json: 100%"
          }
        },
        "328ce1de144c461a89f3f621039a11e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04906a3e432e4d60ae05ad5952e064e4",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67cfa7214cc04db68c488cc76b36e93f",
            "value": 466062
          }
        },
        "83f92ab1935d4f43ba19624de7ef76de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1b9db3990d406e8723c6de81ddbf4d",
            "placeholder": "​",
            "style": "IPY_MODEL_3545882fadec432c86996351d2a0125f",
            "value": " 466k/466k [00:00&lt;00:00, 2.80MB/s]"
          }
        },
        "3416ff8e50c04487af4895754eb6464c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e33ddcc3154910a01ec0a038f006d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9ad0ec119b486f9d6c52e864b4404e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04906a3e432e4d60ae05ad5952e064e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67cfa7214cc04db68c488cc76b36e93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed1b9db3990d406e8723c6de81ddbf4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3545882fadec432c86996351d2a0125f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e877e5a42b4b0ba98bd6c2f6bf0a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1de7e2a651343358dbbd3f114381515",
              "IPY_MODEL_71bf7eb726bf4e2fa13d8d63ba79e244",
              "IPY_MODEL_6434a08bee9640e399a4a68522c2b7fe"
            ],
            "layout": "IPY_MODEL_4e30207e50834cf9b7fc3f96d9683a10"
          }
        },
        "b1de7e2a651343358dbbd3f114381515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a2ad9d910d0403f908ae35c32bfe175",
            "placeholder": "​",
            "style": "IPY_MODEL_a200939d5c03458886a46e308c86c7e6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "71bf7eb726bf4e2fa13d8d63ba79e244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd6f7654a2543d3b444b967702f4215",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6452d4012d94922aaf53f9d413c0464",
            "value": 25
          }
        },
        "6434a08bee9640e399a4a68522c2b7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_179c64ded93a42fc9ccbcfd284474d46",
            "placeholder": "​",
            "style": "IPY_MODEL_23591268f4104357aa1294e5b5012671",
            "value": " 25.0/25.0 [00:00&lt;00:00, 485B/s]"
          }
        },
        "4e30207e50834cf9b7fc3f96d9683a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a2ad9d910d0403f908ae35c32bfe175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a200939d5c03458886a46e308c86c7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd6f7654a2543d3b444b967702f4215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6452d4012d94922aaf53f9d413c0464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "179c64ded93a42fc9ccbcfd284474d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23591268f4104357aa1294e5b5012671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31c45fba852e440c8b89981438ee1518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a08254c86a724268839cc352d9de3fa6",
              "IPY_MODEL_1e7c71ca638c4ccca3da85eee6d3087d",
              "IPY_MODEL_9bcff0106b484ddc95eb63beb0c0a127"
            ],
            "layout": "IPY_MODEL_28cdef20fc8f4e0f9256daea45674633"
          }
        },
        "a08254c86a724268839cc352d9de3fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c045b58b6a17423692d91d3e5dc49262",
            "placeholder": "​",
            "style": "IPY_MODEL_e2bf57f4b59a4658be7138f03690b2b2",
            "value": "vocab.json: 100%"
          }
        },
        "1e7c71ca638c4ccca3da85eee6d3087d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ace726a8f523469e9a31856f93233d50",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dcdbf4546d143dc8fe6a7820b7f6417",
            "value": 898823
          }
        },
        "9bcff0106b484ddc95eb63beb0c0a127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_608951a98c3b49bf8487e0f7f03fdaed",
            "placeholder": "​",
            "style": "IPY_MODEL_aa35e752b55c4f31b7d75759f59bdb71",
            "value": " 899k/899k [00:00&lt;00:00, 3.64MB/s]"
          }
        },
        "28cdef20fc8f4e0f9256daea45674633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c045b58b6a17423692d91d3e5dc49262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2bf57f4b59a4658be7138f03690b2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ace726a8f523469e9a31856f93233d50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dcdbf4546d143dc8fe6a7820b7f6417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "608951a98c3b49bf8487e0f7f03fdaed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa35e752b55c4f31b7d75759f59bdb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "159b7cffbd60428e868beb1308abe5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c481e2fc4623483da547539d0e6ed13d",
              "IPY_MODEL_158843fc852d4497bad860b22f5a7f2e",
              "IPY_MODEL_4926114433b44a059e8edff256055fb3"
            ],
            "layout": "IPY_MODEL_c49427dd561d470d842a0690e1c5c4cf"
          }
        },
        "c481e2fc4623483da547539d0e6ed13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ec7bdb718047fd9b41f48d995da09b",
            "placeholder": "​",
            "style": "IPY_MODEL_5eca492203c24d77aa414994ee3e9de7",
            "value": "merges.txt: 100%"
          }
        },
        "158843fc852d4497bad860b22f5a7f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e7acaf165244f3f900bfda06e18c9f1",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f69fdaf623a644139a73711b1b40205c",
            "value": 456318
          }
        },
        "4926114433b44a059e8edff256055fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6068515f2eca4fc88f29200dd3dea50a",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0e3a138e974b9c94cffb80cde67964",
            "value": " 456k/456k [00:00&lt;00:00, 2.80MB/s]"
          }
        },
        "c49427dd561d470d842a0690e1c5c4cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ec7bdb718047fd9b41f48d995da09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eca492203c24d77aa414994ee3e9de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7acaf165244f3f900bfda06e18c9f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f69fdaf623a644139a73711b1b40205c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6068515f2eca4fc88f29200dd3dea50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0e3a138e974b9c94cffb80cde67964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "174b58551a5c478085d9a76c2eb82415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b02567c75e0946ab82071a470b910591",
              "IPY_MODEL_d0d011bf6ff44ff8b20fb63c7a9e7f64",
              "IPY_MODEL_15ae771f2865463390ccc8250509d375"
            ],
            "layout": "IPY_MODEL_5568f48d6a0d43a598f0f79020c9a883"
          }
        },
        "b02567c75e0946ab82071a470b910591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62493f9cc738410d83f292db7a299816",
            "placeholder": "​",
            "style": "IPY_MODEL_6b5af0c792b243ffbe92398e3797b4d1",
            "value": "tokenizer.json: 100%"
          }
        },
        "d0d011bf6ff44ff8b20fb63c7a9e7f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57fd9f332aec4e579ffad5b9ebc4980d",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66db060d1fdc4f24b902a742f38379da",
            "value": 1355863
          }
        },
        "15ae771f2865463390ccc8250509d375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2864c36a54794242a92118954ca50d33",
            "placeholder": "​",
            "style": "IPY_MODEL_223dd7970d8745c2ba49f4569348cc4e",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.19MB/s]"
          }
        },
        "5568f48d6a0d43a598f0f79020c9a883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62493f9cc738410d83f292db7a299816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5af0c792b243ffbe92398e3797b4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57fd9f332aec4e579ffad5b9ebc4980d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66db060d1fdc4f24b902a742f38379da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2864c36a54794242a92118954ca50d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "223dd7970d8745c2ba49f4569348cc4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff8b61c43e55480984d0cd107501b7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1d75bb1a60492f83dc5530a7ee501d",
              "IPY_MODEL_85620ce9bc2a497e90b8b62ec87daee0",
              "IPY_MODEL_1babd1b2970c44aba33bd8ce1aa25ae8"
            ],
            "layout": "IPY_MODEL_fbe26941b149479d82c1d9d0c98b07b8"
          }
        },
        "ee1d75bb1a60492f83dc5530a7ee501d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c90f6d69a2e49ac9c00c86045425a9f",
            "placeholder": "​",
            "style": "IPY_MODEL_2563baaf46894936ace37632a04172b2",
            "value": "config.json: 100%"
          }
        },
        "85620ce9bc2a497e90b8b62ec87daee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1c088e06f343b8a0ee4ebee2d9a881",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e82ce0fead6c44f4b7f5306bebbac74f",
            "value": 481
          }
        },
        "1babd1b2970c44aba33bd8ce1aa25ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07707b0803864bed9bbb7ebbc5a4f9fd",
            "placeholder": "​",
            "style": "IPY_MODEL_83ebf3f0622f44a28a85340b924c51f0",
            "value": " 481/481 [00:00&lt;00:00, 16.0kB/s]"
          }
        },
        "fbe26941b149479d82c1d9d0c98b07b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c90f6d69a2e49ac9c00c86045425a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2563baaf46894936ace37632a04172b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb1c088e06f343b8a0ee4ebee2d9a881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82ce0fead6c44f4b7f5306bebbac74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07707b0803864bed9bbb7ebbc5a4f9fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ebf3f0622f44a28a85340b924c51f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd27de7d86b44954bf67aa918a3a54b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d67196fa291c4c8db6b63a2321df4251",
              "IPY_MODEL_73e12c963ec1446eaee9665bf7752a53",
              "IPY_MODEL_a2600c1cfc9841bb96313dbb1026923d"
            ],
            "layout": "IPY_MODEL_2512c2ea17d64be7b7f8023a4debbd54"
          }
        },
        "d67196fa291c4c8db6b63a2321df4251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0f490255594452587eb1066335b816b",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a53649e685499fb5b497a54dab2324",
            "value": "spiece.model: 100%"
          }
        },
        "73e12c963ec1446eaee9665bf7752a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf3cc044ba5c4acaae6b03bc1b67a833",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59e59ea38a25491f8cca5440b0a59f6c",
            "value": 798011
          }
        },
        "a2600c1cfc9841bb96313dbb1026923d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb6f20e5b5674ee1bdf47a80729c9ef5",
            "placeholder": "​",
            "style": "IPY_MODEL_2a4c1c20d80e405a85d91fbf9cf9432a",
            "value": " 798k/798k [00:00&lt;00:00, 3.30MB/s]"
          }
        },
        "2512c2ea17d64be7b7f8023a4debbd54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0f490255594452587eb1066335b816b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a53649e685499fb5b497a54dab2324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf3cc044ba5c4acaae6b03bc1b67a833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e59ea38a25491f8cca5440b0a59f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb6f20e5b5674ee1bdf47a80729c9ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4c1c20d80e405a85d91fbf9cf9432a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c74a315647174ca7b98077dead4a996d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c04218a519f2401ba1f8b81593468a7d",
              "IPY_MODEL_45baf3962b2a40e58e3b382ff2bd61ff",
              "IPY_MODEL_60ae75a782564cf09c3526fa2a42ade2"
            ],
            "layout": "IPY_MODEL_a7515933d2984da8b0afa7db4b88438a"
          }
        },
        "c04218a519f2401ba1f8b81593468a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_277938db9c0649a0bef8d87d977c5b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_358eef977aa745ad8e6afeadcf050c6c",
            "value": "tokenizer.json: 100%"
          }
        },
        "45baf3962b2a40e58e3b382ff2bd61ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f2317af87f549f384e3a1d933018aca",
            "max": 1382015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1377f13fcd424c4cbe3fed3e70be2d2d",
            "value": 1382015
          }
        },
        "60ae75a782564cf09c3526fa2a42ade2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2262e44a3f8c4a8787d809864fb6b737",
            "placeholder": "​",
            "style": "IPY_MODEL_fc083c6a19c049d19cf8216c10ed21ec",
            "value": " 1.38M/1.38M [00:00&lt;00:00, 4.20MB/s]"
          }
        },
        "a7515933d2984da8b0afa7db4b88438a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "277938db9c0649a0bef8d87d977c5b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "358eef977aa745ad8e6afeadcf050c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f2317af87f549f384e3a1d933018aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1377f13fcd424c4cbe3fed3e70be2d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2262e44a3f8c4a8787d809864fb6b737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc083c6a19c049d19cf8216c10ed21ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddf40df9ae154fbc96bf84b61e49dc18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_862a236e7c9247cbb1668f61fcc3880f",
              "IPY_MODEL_e37cfda91d9844e8a9221fdff92529c8",
              "IPY_MODEL_36b8040cd0254a5e856d09db580be82a"
            ],
            "layout": "IPY_MODEL_c5d4285ee38645c68d901b4b32935fc3"
          }
        },
        "862a236e7c9247cbb1668f61fcc3880f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50043f9a85534a5d8b312203ec7daca8",
            "placeholder": "​",
            "style": "IPY_MODEL_afd29396911f40cd912b4afec1f348da",
            "value": "config.json: 100%"
          }
        },
        "e37cfda91d9844e8a9221fdff92529c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c7cfe5af0149e99c02820afa041311",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a2d4e2142e046eb9020ce1fb50dc900",
            "value": 760
          }
        },
        "36b8040cd0254a5e856d09db580be82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a069975a826541c69a8d0c7b2d5dd10b",
            "placeholder": "​",
            "style": "IPY_MODEL_b190aea9884042b59332b394183647ca",
            "value": " 760/760 [00:00&lt;00:00, 31.3kB/s]"
          }
        },
        "c5d4285ee38645c68d901b4b32935fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50043f9a85534a5d8b312203ec7daca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd29396911f40cd912b4afec1f348da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80c7cfe5af0149e99c02820afa041311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2d4e2142e046eb9020ce1fb50dc900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a069975a826541c69a8d0c7b2d5dd10b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b190aea9884042b59332b394183647ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rl-cyber/User-Engaged-Network-Diagnosis/blob/main/Reproduce_cellularlint_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edKRvzPqiZJq",
        "outputId": "13cfbddd-1cfb-4104-ea7a-6261ff276a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cellularlint-codes'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 127 (delta 66), reused 65 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (127/127), 2.17 MiB | 19.65 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CellularLint/cellularlint-codes.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd cellularlint-codes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Too8N-K7jJRD",
        "outputId": "ee8be55f-0b9c-4439-de0e-aa41a5bf21cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cellularlint-codes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uOTyNOHldiE",
        "outputId": "ceecd0de-f15a-478f-b264-04f44fb9afd1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Pretrained_Models.zip ./\n",
        "!unzip ./Pretrained_Models.zip -d Pretrained_Models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f45D89YznfHJ",
        "outputId": "5a70b3d5-15c5-45b7-91b8-f4d98e57c870"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./Pretrained_Models.zip\n",
            " extracting: Pretrained_Models/roberta_weights.zip  \n",
            " extracting: Pretrained_Models/bert_weights.zip  \n",
            " extracting: Pretrained_Models/xlnet_weights.zip  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 700 unpack.sh\n",
        "!./unpack.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMqtoteEpidN",
        "outputId": "068cc474-6099-4c42-bed3-b18f735b4a6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipped bert_weights.zip into bert_weights\n",
            "Unzipped roberta_weights.zip into roberta_weights\n",
            "Unzipped xlnet_weights.zip into xlnet_weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 tokenizer_and_sim_matrix.py 4G\n",
        "!python3 tokenizer_and_sim_matrix.py 5G"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAvpCsU3pvhy",
        "outputId": "085876a3-0573-462e-fc79-23b9c08d1f02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 100% 1.19k/1.19k [00:00<00:00, 9.49MB/s]\n",
            "config.json: 100% 594/594 [00:00<00:00, 4.61MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.44MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 2.82MB/s]\n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.91MB/s]\n",
            "2025-02-14 00:34:31.358217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739493271.641611   11826 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739493271.717437   11826 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-14 00:34:32.393621: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 438M/438M [00:01<00:00, 250MB/s]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "tokenizer_config.json: 100% 505/505 [00:00<00:00, 4.27MB/s]\n",
            "config.json: 100% 555/555 [00:00<00:00, 3.99MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.42MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 2.82MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 830kB/s]\n",
            "model.safetensors: 100% 265M/265M [00:01<00:00, 191MB/s]\n",
            "2025-02-14 00:37:47.131047: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739493467.151842   12790 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739493467.158276   12790 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-14 00:37:47.180083: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizerFast\n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/cellularlint-codes/saved_models/bert\"\n",
        "\n",
        "# Download and save BERT model and tokenizer\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "model.save_pretrained(MODEL_SAVE_PATH)\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
        "\n",
        "print(\"BERT model and tokenizer saved at:\", MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "5983c75c9c3441338cc4607809397769",
            "8388ad0257c445509ab9ea3ce173f9d1",
            "4e03a3d91399428e99254b1957d47750",
            "918a9c6d482744d19c85c9c469e88abb",
            "911cee2858b542e4ae4353a0080aae66",
            "e7ddbfe235694a9e9c0870fc7127bcdc",
            "58dd1009c09446ba988151b3b5649707",
            "8d68456e6a5f4bcb89abf86db26580e4",
            "5c723645b9b3441c9023cef3d30a9e46",
            "9b44c587901a4f9ea94497db32bc956d",
            "0fcd4f2751a34271bc3f785dd00e8bf5",
            "eefd692688974c3ea99ddb622986899b",
            "84bf510848ea46d6883004aa9f898018",
            "c5f2bd42342043479e77a9236f57f178",
            "d179cb1bb853430cb34986953e5fb4b2",
            "8c09e2824fe344638214f7a635d6dfb3",
            "62c385be836d465c9114e20b8f731896",
            "66e7083084de4060b8ed188c7a7c1dc1",
            "b0fa7a6d060748289eb172390746c6fc",
            "97fcf24872d14dd298d0edf703d7f4cd",
            "ba3e424241854fda98654bc2e467c23f",
            "da67ed177b52441ba16ad65c5870463c",
            "7f5217139ad445afa7e667cba49aabd4",
            "fe1a74c1b0e7410c8581c24f692673ac",
            "1495e910eb1a4a47bf72274c84d46fac",
            "39bc3600ea75423dbf029b6d5a3300df",
            "f93e7fbe49cf49c591b521976e4f29d3",
            "3d896f2e5ad141b3b34adb3946b32a64",
            "031a39f505c34a39a38e9466552c2a4b",
            "f52ddebc74e2438eb7fe25d670e94625",
            "a2c89b96d77a4747b6c02e516a3bb1f0",
            "74bd0e7c4cfd4f22afee35793056413c",
            "5ec6675fd5074cd4ae3861806a1e7235",
            "8f57b69ce770400d83266d5f40cb9483",
            "5d0fb57c3c18459097f23e70d1892740",
            "d06fa43398dc416ebcf33e859ac4ba39",
            "d2de471a69f543fc897fa449610edbc1",
            "22a73abed69e40dca1c2d8ec7b2cbb76",
            "c50542bd94ab4716b066d25c008b9940",
            "da2e7e6534044122a3d02520fa480d75",
            "fa30c39b0fdb4607abef8f71be0e543a",
            "7d1deefc4f02420695cf0260f5b42ccb",
            "02c3689502c046f290d2a18d6d703e24",
            "76462b31f5484fdcb409f47749552fec",
            "67f52a0496bb4626a5c6b0092c2dc6c1",
            "96a6c8c05330417a8989a744765119d5",
            "328ce1de144c461a89f3f621039a11e5",
            "83f92ab1935d4f43ba19624de7ef76de",
            "3416ff8e50c04487af4895754eb6464c",
            "42e33ddcc3154910a01ec0a038f006d6",
            "9e9ad0ec119b486f9d6c52e864b4404e",
            "04906a3e432e4d60ae05ad5952e064e4",
            "67cfa7214cc04db68c488cc76b36e93f",
            "ed1b9db3990d406e8723c6de81ddbf4d",
            "3545882fadec432c86996351d2a0125f"
          ]
        },
        "id": "tbW6XBs3um9w",
        "outputId": "0492b95c-f736-4bee-963d-717866095803"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5983c75c9c3441338cc4607809397769"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eefd692688974c3ea99ddb622986899b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f5217139ad445afa7e667cba49aabd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f57b69ce770400d83266d5f40cb9483"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67f52a0496bb4626a5c6b0092c2dc6c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model and tokenizer saved at: /content/cellularlint-codes/saved_models/bert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW, BertConfig, BertTokenizerFast\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from torch import nn\n",
        "np.random.seed(321)\n",
        "\n",
        "BertModel.from_pretrained(\"/content/cellularlint-codes/Pretrained Models/bert_weights/\")\n",
        "\n",
        "ROOT_PATH = \"/content/cellularlint-codes\"\n",
        "DATA_PATH = os.path.join(ROOT_PATH, \"Data/SNLI\")\n",
        "PRETRAINED_PATH = os.path.join(ROOT_PATH, \"Pretrained Models/bert_weights\")\n",
        "SAVE_MODEL_AT = os.path.join(ROOT_PATH, \"saved_models/bert\")\n",
        "PRETRAINED_TOKENIZER = SAVE_MODEL_AT  # Tokenizer is usually saved in the same model folder\n",
        "MODEL_PATH = None\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_train.csv\"))\n",
        "df_dev = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_dev.csv\"))\n",
        "df_test = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_test.csv\"))\n",
        "\n",
        "\n",
        "df_train = df_train.iloc[:500]\n",
        "df_dev = df_train.copy().iloc[:100]\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(os.path.join(ROOT_PATH,PRETRAINED_TOKENIZER))\n",
        "tokenizer = BertTokenizerFast.from_pretrained(os.path.join(ROOT_PATH,PRETRAINED_PATH))\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "\n",
        "labels = {'contradiction':1,\n",
        "          'entailment':0,\n",
        "          'neutral':2,\n",
        "          }\n",
        "NUM_LABELS = len(labels)\n",
        "\n",
        "def bert_encoding(sequence):\n",
        "    return tokenizer.encode(sequence, add_special_tokens = False)\n",
        "def str_to_int_list(data):\n",
        "    return list(map(int, data))\n",
        "\n",
        "df_train['token_type'] = df_train['token_type'].str.split()\n",
        "df_train['token_type'] = df_train['token_type'].apply(str_to_int_list)\n",
        "\n",
        "df_dev['token_type'] = df_dev['token_type'].str.split()\n",
        "df_dev['token_type'] = df_dev['token_type'].apply(str_to_int_list)\n",
        "\n",
        "df_test['token_type'] = df_test['token_type'].str.split()\n",
        "df_test['token_type'] = df_test['token_type'].apply(str_to_int_list)\n",
        "\n",
        "df_train['attention_mask'] = df_train['attention_mask'].str.split()\n",
        "df_train['attention_mask'] = df_train['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].str.split()\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "df_test['attention_mask'] = df_test['attention_mask'].str.split()\n",
        "df_test['attention_mask'] = df_test['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "\n",
        "df_train['input_ids'] = df_train['sequence'].apply(bert_encoding)\n",
        "df_dev['input_ids'] = df_dev['sequence'].apply(bert_encoding)\n",
        "df_test['input_ids'] = df_test['sequence'].apply(bert_encoding)\n",
        "\n",
        "\n",
        "max_length = 512\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = []\n",
        "        self.labels = [labels[label] for label in df['gold_label']]\n",
        "        for _, row in df.iterrows():\n",
        "            token_type_ids = row['token_type']\n",
        "            token_type_ids += [0] * (max_length - len(token_type_ids))\n",
        "            attention_mask = row['attention_mask']\n",
        "            attention_mask += [0] * (max_length - len(attention_mask))\n",
        "            input_ids = tokenizer.encode(\n",
        "                row['sequence'],\n",
        "                add_special_tokens=False,\n",
        "                padding='max_length',\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            datadict = {\n",
        "                'input_ids': input_ids.squeeze(0),\n",
        "                'token_type_ids': torch.tensor(token_type_ids),\n",
        "                'attention_mask': torch.tensor(attention_mask)\n",
        "            }\n",
        "            self.texts.append(datadict)\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_text = self.texts[idx]\n",
        "        batch_y = self.labels[idx]\n",
        "        return batch_text, batch_y\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, load_path = None, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(os.path.join(ROOT_PATH, load_path))\n",
        "        self.bert = BertModel.from_pretrained(load_path)\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, NUM_LABELS)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, input_id, mask, token_type_id):\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask = mask, token_type_ids = token_type_id,return_dict = False)\n",
        "\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "\n",
        "        linear_output = self.linear(dropout_output)\n",
        "\n",
        "        final_layer = self.softmax(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "    def save(self, save_dir, tokenizer, model_name = \"model_bert.pt\"):\n",
        "\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        # Save model weights\n",
        "        model_path = os.path.join(save_dir, model_name)\n",
        "        torch.save(self.state_dict(), model_path)\n",
        "        self.bert.save_pretrained(save_dir)\n",
        "\n",
        "        # Save tokenizer\n",
        "        tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "        # Save other related information\n",
        "        config_path = os.path.join(save_dir, \"config.json\")\n",
        "        self.bert.config.to_json_file(config_path)\n",
        "\n",
        "    def load(self, load_dir, is_eval = True, model_name = \"model_bert.pt\"):\n",
        "        # Load tokenizer\n",
        "        tokenizer = BertTokenizer.from_pretrained(load_dir)\n",
        "\n",
        "        # Load other related information\n",
        "        config_path = os.path.join(load_dir, \"config.json\")\n",
        "        config = BertConfig.from_json_file(config_path)\n",
        "        self.bert = BertModel(config)\n",
        "        if is_eval:\n",
        "            self.bert.eval()  # Set to evaluation mode\n",
        "\n",
        "        # Load model weights\n",
        "        model_path = os.path.join(load_dir, model_name)\n",
        "        self.load_state_dict(torch.load(model_path))\n",
        "\n",
        "        # Update the tokenizer\n",
        "        self.bert.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "learning_rates = [1e-5] #[5e-6, 1e-5, 2e-5, 3e-5, 5e-5]\n",
        "batch_sizes = [8] #[16, 24, 32, 40]\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs, batch_size):\n",
        "    #out_file.write(f\"-------------Starting with LR = {learning_rate} and BS = {batch_size}-----------------\\n\")\n",
        "    best_acc_val = -99999\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "                #print(train_input)\n",
        "                train_label = train_label.to(device)\n",
        "\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "                mask = train_input['attention_mask'].squeeze(1).to(device)\n",
        "                token_type_id = train_input['token_type_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask, token_type_id)\n",
        "                #logits = output.logits #For BertForSequenceClassification\n",
        "                logits = output\n",
        "                print(f'training logits: {logits}')\n",
        "                print(\"training outputs\")\n",
        "                print(output)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                batch_loss = criterion(logits, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                print(f'prediction: {torch.argmax(logits, dim=1)}')\n",
        "                print(f\"train labels: {train_label}\")\n",
        "                acc = (torch.argmax(logits, dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for val_input, val_label in val_dataloader:\n",
        "\n",
        "                val_label = val_label.to(device)\n",
        "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "                mask = val_input['attention_mask'].squeeze(1).to(device)\n",
        "                token_type_id = val_input['token_type_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask, token_type_id)\n",
        "                #logits = output.logits #For BertForSequenceClassification\n",
        "                logits = output\n",
        "                print(val_label)\n",
        "                print(f'validating logits: {logits}')\n",
        "                print(f'prediction: {torch.argmax(logits, dim=1)}')\n",
        "\n",
        "                batch_loss = criterion(logits, val_label.long())\n",
        "                total_loss_val += batch_loss.item()\n",
        "                print(output)\n",
        "                acc = (torch.argmax(logits, dim=1) == val_label).sum().item()\n",
        "                total_acc_val += acc\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "            | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "\n",
        "        if(total_acc_val / len(val_data) > best_acc_val):\n",
        "            best_acc_val = total_acc_val / len(val_data)\n",
        "            model.bert.save_pretrained(os.path.join(ROOT_PATH,\"saved_models/finetune_p1/bert/\"))\n",
        "            tokenizer.save_pretrained(os.path.join(ROOT_PATH,\"saved_models/finetune_p1/bert/\"))\n",
        "\n",
        "            model.save(save_dir = os.path.join(ROOT_PATH, SAVE_MODEL_AT), tokenizer = tokenizer)\n",
        "            print(\"Found a better model\")\n",
        "            model.save(save_dir = SAVE_MODEL_AT, tokenizer = tokenizer)\n",
        "\n",
        "EPOCHS = 8\n",
        "for LR in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = NUM_LABELS)\n",
        "        model = BertClassifier(load_path = PRETRAINED_PATH)\n",
        "        train(model, df_train, df_dev, LR, EPOCHS, bs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf3ao6oOsnnx",
        "outputId": "e37361d9-2483-4466-b411-2086cab55048"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at /content/cellularlint-codes/Pretrained Models/bert_weights/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at /content/cellularlint-codes/Pretrained Models/bert_weights and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at /content/cellularlint-codes/Pretrained Models/bert_weights and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "  0%|          | 0/63 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1497, 0.4707, 0.3797],\n",
            "        [0.2063, 0.1981, 0.5956],\n",
            "        [0.3649, 0.3388, 0.2963],\n",
            "        [0.0905, 0.3761, 0.5334],\n",
            "        [0.2920, 0.4067, 0.3013],\n",
            "        [0.2593, 0.3327, 0.4080],\n",
            "        [0.3846, 0.3945, 0.2209],\n",
            "        [0.1342, 0.5164, 0.3494]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1497, 0.4707, 0.3797],\n",
            "        [0.2063, 0.1981, 0.5956],\n",
            "        [0.3649, 0.3388, 0.2963],\n",
            "        [0.0905, 0.3761, 0.5334],\n",
            "        [0.2920, 0.4067, 0.3013],\n",
            "        [0.2593, 0.3327, 0.4080],\n",
            "        [0.3846, 0.3945, 0.2209],\n",
            "        [0.1342, 0.5164, 0.3494]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 2, 1, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/63 [00:01<01:54,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1645, 0.6726, 0.1629],\n",
            "        [0.1498, 0.7375, 0.1127],\n",
            "        [0.2062, 0.3230, 0.4708],\n",
            "        [0.2764, 0.1937, 0.5299],\n",
            "        [0.1485, 0.6557, 0.1958],\n",
            "        [0.4335, 0.2465, 0.3200],\n",
            "        [0.1616, 0.3109, 0.5275],\n",
            "        [0.1121, 0.7069, 0.1810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1645, 0.6726, 0.1629],\n",
            "        [0.1498, 0.7375, 0.1127],\n",
            "        [0.2062, 0.3230, 0.4708],\n",
            "        [0.2764, 0.1937, 0.5299],\n",
            "        [0.1485, 0.6557, 0.1958],\n",
            "        [0.4335, 0.2465, 0.3200],\n",
            "        [0.1616, 0.3109, 0.5275],\n",
            "        [0.1121, 0.7069, 0.1810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 2, 1, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/63 [00:02<01:09,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0858, 0.7757, 0.1385],\n",
            "        [0.2182, 0.3860, 0.3958],\n",
            "        [0.1798, 0.6259, 0.1943],\n",
            "        [0.2053, 0.5970, 0.1977],\n",
            "        [0.3709, 0.4067, 0.2224],\n",
            "        [0.0830, 0.7358, 0.1811],\n",
            "        [0.2173, 0.4439, 0.3388],\n",
            "        [0.1879, 0.4756, 0.3365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0858, 0.7757, 0.1385],\n",
            "        [0.2182, 0.3860, 0.3958],\n",
            "        [0.1798, 0.6259, 0.1943],\n",
            "        [0.2053, 0.5970, 0.1977],\n",
            "        [0.3709, 0.4067, 0.2224],\n",
            "        [0.0830, 0.7358, 0.1811],\n",
            "        [0.2173, 0.4439, 0.3388],\n",
            "        [0.1879, 0.4756, 0.3365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 2, 1, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/63 [00:03<00:54,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1468, 0.5677, 0.2856],\n",
            "        [0.2088, 0.4479, 0.3433],\n",
            "        [0.2365, 0.4317, 0.3317],\n",
            "        [0.1288, 0.3780, 0.4932],\n",
            "        [0.3098, 0.3671, 0.3232],\n",
            "        [0.1521, 0.5824, 0.2655],\n",
            "        [0.1451, 0.5420, 0.3130],\n",
            "        [0.2853, 0.4133, 0.3014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1468, 0.5677, 0.2856],\n",
            "        [0.2088, 0.4479, 0.3433],\n",
            "        [0.2365, 0.4317, 0.3317],\n",
            "        [0.1288, 0.3780, 0.4932],\n",
            "        [0.3098, 0.3671, 0.3232],\n",
            "        [0.1521, 0.5824, 0.2655],\n",
            "        [0.1451, 0.5420, 0.3130],\n",
            "        [0.2853, 0.4133, 0.3014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 1, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/63 [00:03<00:47,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1375, 0.1927, 0.6698],\n",
            "        [0.1568, 0.3003, 0.5430],\n",
            "        [0.2702, 0.4489, 0.2808],\n",
            "        [0.2388, 0.5528, 0.2084],\n",
            "        [0.3292, 0.3126, 0.3582],\n",
            "        [0.4945, 0.3814, 0.1240],\n",
            "        [0.4412, 0.3553, 0.2036],\n",
            "        [0.1594, 0.1795, 0.6610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1375, 0.1927, 0.6698],\n",
            "        [0.1568, 0.3003, 0.5430],\n",
            "        [0.2702, 0.4489, 0.2808],\n",
            "        [0.2388, 0.5528, 0.2084],\n",
            "        [0.3292, 0.3126, 0.3582],\n",
            "        [0.4945, 0.3814, 0.1240],\n",
            "        [0.4412, 0.3553, 0.2036],\n",
            "        [0.1594, 0.1795, 0.6610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 2, 1, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/63 [00:04<00:43,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3785, 0.4135, 0.2080],\n",
            "        [0.1258, 0.5087, 0.3655],\n",
            "        [0.3439, 0.4588, 0.1973],\n",
            "        [0.2647, 0.2394, 0.4958],\n",
            "        [0.3392, 0.4348, 0.2260],\n",
            "        [0.1966, 0.6086, 0.1948],\n",
            "        [0.2826, 0.5235, 0.1939],\n",
            "        [0.2296, 0.3362, 0.4343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3785, 0.4135, 0.2080],\n",
            "        [0.1258, 0.5087, 0.3655],\n",
            "        [0.3439, 0.4588, 0.1973],\n",
            "        [0.2647, 0.2394, 0.4958],\n",
            "        [0.3392, 0.4348, 0.2260],\n",
            "        [0.1966, 0.6086, 0.1948],\n",
            "        [0.2826, 0.5235, 0.1939],\n",
            "        [0.2296, 0.3362, 0.4343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 0, 1, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 6/63 [00:05<00:40,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1729, 0.3775, 0.4496],\n",
            "        [0.3543, 0.3544, 0.2913],\n",
            "        [0.2916, 0.4415, 0.2668],\n",
            "        [0.3701, 0.2265, 0.4034],\n",
            "        [0.2867, 0.5476, 0.1656],\n",
            "        [0.1209, 0.5667, 0.3124],\n",
            "        [0.2004, 0.6256, 0.1741],\n",
            "        [0.3956, 0.2406, 0.3639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1729, 0.3775, 0.4496],\n",
            "        [0.3543, 0.3544, 0.2913],\n",
            "        [0.2916, 0.4415, 0.2668],\n",
            "        [0.3701, 0.2265, 0.4034],\n",
            "        [0.2867, 0.5476, 0.1656],\n",
            "        [0.1209, 0.5667, 0.3124],\n",
            "        [0.2004, 0.6256, 0.1741],\n",
            "        [0.3956, 0.2406, 0.3639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 2, 1, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 0, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/63 [00:05<00:38,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3452, 0.2794, 0.3753],\n",
            "        [0.3286, 0.3369, 0.3345],\n",
            "        [0.5649, 0.3210, 0.1142],\n",
            "        [0.2851, 0.4713, 0.2437],\n",
            "        [0.3231, 0.5208, 0.1562],\n",
            "        [0.0843, 0.3489, 0.5668],\n",
            "        [0.3223, 0.2669, 0.4108],\n",
            "        [0.2269, 0.3770, 0.3961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3452, 0.2794, 0.3753],\n",
            "        [0.3286, 0.3369, 0.3345],\n",
            "        [0.5649, 0.3210, 0.1142],\n",
            "        [0.2851, 0.4713, 0.2437],\n",
            "        [0.3231, 0.5208, 0.1562],\n",
            "        [0.0843, 0.3489, 0.5668],\n",
            "        [0.3223, 0.2669, 0.4108],\n",
            "        [0.2269, 0.3770, 0.3961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 2, 1, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/63 [00:06<00:37,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3628, 0.4903, 0.1469],\n",
            "        [0.0892, 0.6864, 0.2244],\n",
            "        [0.2889, 0.3483, 0.3628],\n",
            "        [0.1377, 0.5559, 0.3064],\n",
            "        [0.0655, 0.5230, 0.4115],\n",
            "        [0.3218, 0.4747, 0.2035],\n",
            "        [0.2394, 0.4074, 0.3532],\n",
            "        [0.1828, 0.4518, 0.3654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3628, 0.4903, 0.1469],\n",
            "        [0.0892, 0.6864, 0.2244],\n",
            "        [0.2889, 0.3483, 0.3628],\n",
            "        [0.1377, 0.5559, 0.3064],\n",
            "        [0.0655, 0.5230, 0.4115],\n",
            "        [0.3218, 0.4747, 0.2035],\n",
            "        [0.2394, 0.4074, 0.3532],\n",
            "        [0.1828, 0.4518, 0.3654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 2, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/63 [00:06<00:36,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1617, 0.4253, 0.4130],\n",
            "        [0.2926, 0.3292, 0.3782],\n",
            "        [0.2392, 0.3456, 0.4152],\n",
            "        [0.2638, 0.2791, 0.4571],\n",
            "        [0.0932, 0.6333, 0.2734],\n",
            "        [0.3387, 0.5327, 0.1287],\n",
            "        [0.5051, 0.2112, 0.2837],\n",
            "        [0.6941, 0.2094, 0.0965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1617, 0.4253, 0.4130],\n",
            "        [0.2926, 0.3292, 0.3782],\n",
            "        [0.2392, 0.3456, 0.4152],\n",
            "        [0.2638, 0.2791, 0.4571],\n",
            "        [0.0932, 0.6333, 0.2734],\n",
            "        [0.3387, 0.5327, 0.1287],\n",
            "        [0.5051, 0.2112, 0.2837],\n",
            "        [0.6941, 0.2094, 0.0965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 2, 1, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 1, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/63 [00:07<00:35,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1545, 0.3079, 0.5376],\n",
            "        [0.2530, 0.2090, 0.5380],\n",
            "        [0.2736, 0.4969, 0.2295],\n",
            "        [0.1523, 0.5284, 0.3193],\n",
            "        [0.1654, 0.2698, 0.5648],\n",
            "        [0.1881, 0.1967, 0.6152],\n",
            "        [0.2433, 0.5838, 0.1729],\n",
            "        [0.2015, 0.2710, 0.5275]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1545, 0.3079, 0.5376],\n",
            "        [0.2530, 0.2090, 0.5380],\n",
            "        [0.2736, 0.4969, 0.2295],\n",
            "        [0.1523, 0.5284, 0.3193],\n",
            "        [0.1654, 0.2698, 0.5648],\n",
            "        [0.1881, 0.1967, 0.6152],\n",
            "        [0.2433, 0.5838, 0.1729],\n",
            "        [0.2015, 0.2710, 0.5275]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 1, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/63 [00:08<00:34,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1689, 0.4821, 0.3490],\n",
            "        [0.2376, 0.2568, 0.5056],\n",
            "        [0.2182, 0.3548, 0.4270],\n",
            "        [0.2833, 0.5371, 0.1796],\n",
            "        [0.1404, 0.2579, 0.6017],\n",
            "        [0.2220, 0.2210, 0.5570],\n",
            "        [0.3146, 0.3601, 0.3253],\n",
            "        [0.2186, 0.3979, 0.3835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1689, 0.4821, 0.3490],\n",
            "        [0.2376, 0.2568, 0.5056],\n",
            "        [0.2182, 0.3548, 0.4270],\n",
            "        [0.2833, 0.5371, 0.1796],\n",
            "        [0.1404, 0.2579, 0.6017],\n",
            "        [0.2220, 0.2210, 0.5570],\n",
            "        [0.3146, 0.3601, 0.3253],\n",
            "        [0.2186, 0.3979, 0.3835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 1, 2, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 2, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/63 [00:08<00:33,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1607, 0.5599, 0.2794],\n",
            "        [0.3176, 0.2677, 0.4147],\n",
            "        [0.2907, 0.3012, 0.4080],\n",
            "        [0.1789, 0.3029, 0.5182],\n",
            "        [0.3753, 0.3698, 0.2549],\n",
            "        [0.0903, 0.3613, 0.5484],\n",
            "        [0.2181, 0.4421, 0.3398],\n",
            "        [0.2512, 0.5891, 0.1597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1607, 0.5599, 0.2794],\n",
            "        [0.3176, 0.2677, 0.4147],\n",
            "        [0.2907, 0.3012, 0.4080],\n",
            "        [0.1789, 0.3029, 0.5182],\n",
            "        [0.3753, 0.3698, 0.2549],\n",
            "        [0.0903, 0.3613, 0.5484],\n",
            "        [0.2181, 0.4421, 0.3398],\n",
            "        [0.2512, 0.5891, 0.1597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 2, 0, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 2, 1, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 13/63 [00:09<00:32,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1944, 0.4470, 0.3586],\n",
            "        [0.1721, 0.3961, 0.4318],\n",
            "        [0.0441, 0.5866, 0.3693],\n",
            "        [0.2219, 0.1707, 0.6074],\n",
            "        [0.5142, 0.2288, 0.2569],\n",
            "        [0.2116, 0.5460, 0.2424],\n",
            "        [0.3094, 0.4469, 0.2437],\n",
            "        [0.2892, 0.3163, 0.3945]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1944, 0.4470, 0.3586],\n",
            "        [0.1721, 0.3961, 0.4318],\n",
            "        [0.0441, 0.5866, 0.3693],\n",
            "        [0.2219, 0.1707, 0.6074],\n",
            "        [0.5142, 0.2288, 0.2569],\n",
            "        [0.2116, 0.5460, 0.2424],\n",
            "        [0.3094, 0.4469, 0.2437],\n",
            "        [0.2892, 0.3163, 0.3945]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 0, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 1, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/63 [00:10<00:31,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1739, 0.4948, 0.3313],\n",
            "        [0.2189, 0.6884, 0.0926],\n",
            "        [0.1092, 0.3012, 0.5896],\n",
            "        [0.2853, 0.4646, 0.2501],\n",
            "        [0.5607, 0.2431, 0.1962],\n",
            "        [0.2359, 0.4157, 0.3484],\n",
            "        [0.1225, 0.2844, 0.5931],\n",
            "        [0.3448, 0.2845, 0.3706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1739, 0.4948, 0.3313],\n",
            "        [0.2189, 0.6884, 0.0926],\n",
            "        [0.1092, 0.3012, 0.5896],\n",
            "        [0.2853, 0.4646, 0.2501],\n",
            "        [0.5607, 0.2431, 0.1962],\n",
            "        [0.2359, 0.4157, 0.3484],\n",
            "        [0.1225, 0.2844, 0.5931],\n",
            "        [0.3448, 0.2845, 0.3706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 1, 0, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 2, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 15/63 [00:10<00:31,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7028, 0.1028, 0.1944],\n",
            "        [0.2660, 0.4898, 0.2442],\n",
            "        [0.1987, 0.5326, 0.2687],\n",
            "        [0.2119, 0.3126, 0.4756],\n",
            "        [0.0757, 0.5512, 0.3731],\n",
            "        [0.3652, 0.2067, 0.4281],\n",
            "        [0.2827, 0.5226, 0.1948],\n",
            "        [0.4523, 0.2759, 0.2718]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7028, 0.1028, 0.1944],\n",
            "        [0.2660, 0.4898, 0.2442],\n",
            "        [0.1987, 0.5326, 0.2687],\n",
            "        [0.2119, 0.3126, 0.4756],\n",
            "        [0.0757, 0.5512, 0.3731],\n",
            "        [0.3652, 0.2067, 0.4281],\n",
            "        [0.2827, 0.5226, 0.1948],\n",
            "        [0.4523, 0.2759, 0.2718]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 2, 1, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 2, 1, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/63 [00:11<00:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2538, 0.4448, 0.3015],\n",
            "        [0.2330, 0.3031, 0.4639],\n",
            "        [0.2312, 0.3715, 0.3973],\n",
            "        [0.2541, 0.3192, 0.4267],\n",
            "        [0.1211, 0.3623, 0.5167],\n",
            "        [0.3996, 0.3432, 0.2572],\n",
            "        [0.1784, 0.6528, 0.1688],\n",
            "        [0.1978, 0.2574, 0.5449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2538, 0.4448, 0.3015],\n",
            "        [0.2330, 0.3031, 0.4639],\n",
            "        [0.2312, 0.3715, 0.3973],\n",
            "        [0.2541, 0.3192, 0.4267],\n",
            "        [0.1211, 0.3623, 0.5167],\n",
            "        [0.3996, 0.3432, 0.2572],\n",
            "        [0.1784, 0.6528, 0.1688],\n",
            "        [0.1978, 0.2574, 0.5449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 2, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 0, 0, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/63 [00:12<00:29,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2906, 0.4736, 0.2358],\n",
            "        [0.1037, 0.7352, 0.1611],\n",
            "        [0.0727, 0.6699, 0.2574],\n",
            "        [0.3062, 0.3189, 0.3749],\n",
            "        [0.0984, 0.3201, 0.5815],\n",
            "        [0.1452, 0.5565, 0.2982],\n",
            "        [0.3207, 0.4600, 0.2192],\n",
            "        [0.3146, 0.3127, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2906, 0.4736, 0.2358],\n",
            "        [0.1037, 0.7352, 0.1611],\n",
            "        [0.0727, 0.6699, 0.2574],\n",
            "        [0.3062, 0.3189, 0.3749],\n",
            "        [0.0984, 0.3201, 0.5815],\n",
            "        [0.1452, 0.5565, 0.2982],\n",
            "        [0.3207, 0.4600, 0.2192],\n",
            "        [0.3146, 0.3127, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 2, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 0, 2, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 18/63 [00:12<00:28,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5030, 0.2617, 0.2353],\n",
            "        [0.4645, 0.3439, 0.1916],\n",
            "        [0.1277, 0.5330, 0.3393],\n",
            "        [0.3111, 0.3421, 0.3467],\n",
            "        [0.1213, 0.5103, 0.3684],\n",
            "        [0.0916, 0.6187, 0.2897],\n",
            "        [0.1434, 0.5809, 0.2757],\n",
            "        [0.3213, 0.3696, 0.3091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5030, 0.2617, 0.2353],\n",
            "        [0.4645, 0.3439, 0.1916],\n",
            "        [0.1277, 0.5330, 0.3393],\n",
            "        [0.3111, 0.3421, 0.3467],\n",
            "        [0.1213, 0.5103, 0.3684],\n",
            "        [0.0916, 0.6187, 0.2897],\n",
            "        [0.1434, 0.5809, 0.2757],\n",
            "        [0.3213, 0.3696, 0.3091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 2, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 1, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 19/63 [00:13<00:28,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1234, 0.4125, 0.4641],\n",
            "        [0.0606, 0.4819, 0.4575],\n",
            "        [0.1376, 0.3095, 0.5530],\n",
            "        [0.1646, 0.3064, 0.5290],\n",
            "        [0.1646, 0.2511, 0.5843],\n",
            "        [0.4906, 0.3128, 0.1966],\n",
            "        [0.1845, 0.4416, 0.3739],\n",
            "        [0.1834, 0.2790, 0.5376]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1234, 0.4125, 0.4641],\n",
            "        [0.0606, 0.4819, 0.4575],\n",
            "        [0.1376, 0.3095, 0.5530],\n",
            "        [0.1646, 0.3064, 0.5290],\n",
            "        [0.1646, 0.2511, 0.5843],\n",
            "        [0.4906, 0.3128, 0.1966],\n",
            "        [0.1845, 0.4416, 0.3739],\n",
            "        [0.1834, 0.2790, 0.5376]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 2, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 1, 0, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 20/63 [00:14<00:27,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1233, 0.5504, 0.3263],\n",
            "        [0.1365, 0.4193, 0.4442],\n",
            "        [0.3152, 0.4679, 0.2168],\n",
            "        [0.0883, 0.4842, 0.4275],\n",
            "        [0.3165, 0.3440, 0.3395],\n",
            "        [0.3533, 0.3606, 0.2861],\n",
            "        [0.2675, 0.4198, 0.3127],\n",
            "        [0.1621, 0.2380, 0.5999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1233, 0.5504, 0.3263],\n",
            "        [0.1365, 0.4193, 0.4442],\n",
            "        [0.3152, 0.4679, 0.2168],\n",
            "        [0.0883, 0.4842, 0.4275],\n",
            "        [0.3165, 0.3440, 0.3395],\n",
            "        [0.3533, 0.3606, 0.2861],\n",
            "        [0.2675, 0.4198, 0.3127],\n",
            "        [0.1621, 0.2380, 0.5999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 2, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/63 [00:14<00:27,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2025, 0.5056, 0.2919],\n",
            "        [0.3907, 0.3697, 0.2397],\n",
            "        [0.0847, 0.2424, 0.6729],\n",
            "        [0.2294, 0.4124, 0.3582],\n",
            "        [0.0808, 0.2395, 0.6797],\n",
            "        [0.2151, 0.5281, 0.2567],\n",
            "        [0.2336, 0.5585, 0.2079],\n",
            "        [0.1228, 0.7099, 0.1672]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2025, 0.5056, 0.2919],\n",
            "        [0.3907, 0.3697, 0.2397],\n",
            "        [0.0847, 0.2424, 0.6729],\n",
            "        [0.2294, 0.4124, 0.3582],\n",
            "        [0.0808, 0.2395, 0.6797],\n",
            "        [0.2151, 0.5281, 0.2567],\n",
            "        [0.2336, 0.5585, 0.2079],\n",
            "        [0.1228, 0.7099, 0.1672]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 1, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 2, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 22/63 [00:15<00:26,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1977, 0.4616, 0.3407],\n",
            "        [0.1556, 0.6496, 0.1948],\n",
            "        [0.1294, 0.4380, 0.4326],\n",
            "        [0.4441, 0.4020, 0.1539],\n",
            "        [0.1850, 0.3357, 0.4794],\n",
            "        [0.2658, 0.3051, 0.4291],\n",
            "        [0.2036, 0.4209, 0.3755],\n",
            "        [0.1290, 0.6119, 0.2591]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1977, 0.4616, 0.3407],\n",
            "        [0.1556, 0.6496, 0.1948],\n",
            "        [0.1294, 0.4380, 0.4326],\n",
            "        [0.4441, 0.4020, 0.1539],\n",
            "        [0.1850, 0.3357, 0.4794],\n",
            "        [0.2658, 0.3051, 0.4291],\n",
            "        [0.2036, 0.4209, 0.3755],\n",
            "        [0.1290, 0.6119, 0.2591]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 0, 2, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 1, 1, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 23/63 [00:16<00:25,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1673, 0.5249, 0.3078],\n",
            "        [0.0993, 0.4732, 0.4275],\n",
            "        [0.4456, 0.3525, 0.2020],\n",
            "        [0.3885, 0.3656, 0.2459],\n",
            "        [0.1384, 0.5583, 0.3034],\n",
            "        [0.0961, 0.2669, 0.6370],\n",
            "        [0.1084, 0.4068, 0.4848],\n",
            "        [0.2832, 0.4906, 0.2261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1673, 0.5249, 0.3078],\n",
            "        [0.0993, 0.4732, 0.4275],\n",
            "        [0.4456, 0.3525, 0.2020],\n",
            "        [0.3885, 0.3656, 0.2459],\n",
            "        [0.1384, 0.5583, 0.3034],\n",
            "        [0.0961, 0.2669, 0.6370],\n",
            "        [0.1084, 0.4068, 0.4848],\n",
            "        [0.2832, 0.4906, 0.2261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 0, 1, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 2, 2, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/63 [00:16<00:25,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1036, 0.2873, 0.6091],\n",
            "        [0.0342, 0.2367, 0.7291],\n",
            "        [0.1871, 0.4037, 0.4092],\n",
            "        [0.0929, 0.3144, 0.5927],\n",
            "        [0.2027, 0.2404, 0.5570],\n",
            "        [0.1538, 0.1735, 0.6727],\n",
            "        [0.1629, 0.4412, 0.3959],\n",
            "        [0.0769, 0.4134, 0.5096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1036, 0.2873, 0.6091],\n",
            "        [0.0342, 0.2367, 0.7291],\n",
            "        [0.1871, 0.4037, 0.4092],\n",
            "        [0.0929, 0.3144, 0.5927],\n",
            "        [0.2027, 0.2404, 0.5570],\n",
            "        [0.1538, 0.1735, 0.6727],\n",
            "        [0.1629, 0.4412, 0.3959],\n",
            "        [0.0769, 0.4134, 0.5096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 25/63 [00:17<00:24,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1519, 0.5486, 0.2995],\n",
            "        [0.1378, 0.4927, 0.3695],\n",
            "        [0.1555, 0.3488, 0.4957],\n",
            "        [0.2149, 0.4728, 0.3123],\n",
            "        [0.2539, 0.2212, 0.5249],\n",
            "        [0.0601, 0.7292, 0.2107],\n",
            "        [0.1045, 0.1901, 0.7054],\n",
            "        [0.1101, 0.5855, 0.3043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1519, 0.5486, 0.2995],\n",
            "        [0.1378, 0.4927, 0.3695],\n",
            "        [0.1555, 0.3488, 0.4957],\n",
            "        [0.2149, 0.4728, 0.3123],\n",
            "        [0.2539, 0.2212, 0.5249],\n",
            "        [0.0601, 0.7292, 0.2107],\n",
            "        [0.1045, 0.1901, 0.7054],\n",
            "        [0.1101, 0.5855, 0.3043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 1, 2, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 2, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 26/63 [00:17<00:23,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3497, 0.4033, 0.2470],\n",
            "        [0.4651, 0.2472, 0.2878],\n",
            "        [0.1750, 0.3767, 0.4483],\n",
            "        [0.3424, 0.2920, 0.3656],\n",
            "        [0.2309, 0.3766, 0.3925],\n",
            "        [0.2024, 0.3948, 0.4028],\n",
            "        [0.1758, 0.3765, 0.4477],\n",
            "        [0.4366, 0.2270, 0.3363]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3497, 0.4033, 0.2470],\n",
            "        [0.4651, 0.2472, 0.2878],\n",
            "        [0.1750, 0.3767, 0.4483],\n",
            "        [0.3424, 0.2920, 0.3656],\n",
            "        [0.2309, 0.3766, 0.3925],\n",
            "        [0.2024, 0.3948, 0.4028],\n",
            "        [0.1758, 0.3765, 0.4477],\n",
            "        [0.4366, 0.2270, 0.3363]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 2, 2, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 1, 2, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 27/63 [00:18<00:23,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0713, 0.3299, 0.5988],\n",
            "        [0.1488, 0.2629, 0.5883],\n",
            "        [0.3146, 0.4755, 0.2098],\n",
            "        [0.2173, 0.5006, 0.2821],\n",
            "        [0.1251, 0.1608, 0.7141],\n",
            "        [0.2758, 0.4209, 0.3033],\n",
            "        [0.2477, 0.3933, 0.3590],\n",
            "        [0.2706, 0.5321, 0.1973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0713, 0.3299, 0.5988],\n",
            "        [0.1488, 0.2629, 0.5883],\n",
            "        [0.3146, 0.4755, 0.2098],\n",
            "        [0.2173, 0.5006, 0.2821],\n",
            "        [0.1251, 0.1608, 0.7141],\n",
            "        [0.2758, 0.4209, 0.3033],\n",
            "        [0.2477, 0.3933, 0.3590],\n",
            "        [0.2706, 0.5321, 0.1973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 1, 0, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/63 [00:19<00:22,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1994, 0.4767, 0.3239],\n",
            "        [0.0591, 0.5231, 0.4179],\n",
            "        [0.4256, 0.3154, 0.2590],\n",
            "        [0.2502, 0.4088, 0.3410],\n",
            "        [0.0880, 0.4891, 0.4229],\n",
            "        [0.2043, 0.3993, 0.3964],\n",
            "        [0.3394, 0.3885, 0.2721],\n",
            "        [0.1598, 0.5844, 0.2558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1994, 0.4767, 0.3239],\n",
            "        [0.0591, 0.5231, 0.4179],\n",
            "        [0.4256, 0.3154, 0.2590],\n",
            "        [0.2502, 0.4088, 0.3410],\n",
            "        [0.0880, 0.4891, 0.4229],\n",
            "        [0.2043, 0.3993, 0.3964],\n",
            "        [0.3394, 0.3885, 0.2721],\n",
            "        [0.1598, 0.5844, 0.2558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 0, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 29/63 [00:19<00:22,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2068, 0.2018, 0.5913],\n",
            "        [0.4132, 0.4914, 0.0954],\n",
            "        [0.2949, 0.2949, 0.4103],\n",
            "        [0.2202, 0.1799, 0.5999],\n",
            "        [0.2361, 0.2777, 0.4862],\n",
            "        [0.0752, 0.6104, 0.3144],\n",
            "        [0.1621, 0.6606, 0.1773],\n",
            "        [0.2546, 0.3007, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2068, 0.2018, 0.5913],\n",
            "        [0.4132, 0.4914, 0.0954],\n",
            "        [0.2949, 0.2949, 0.4103],\n",
            "        [0.2202, 0.1799, 0.5999],\n",
            "        [0.2361, 0.2777, 0.4862],\n",
            "        [0.0752, 0.6104, 0.3144],\n",
            "        [0.1621, 0.6606, 0.1773],\n",
            "        [0.2546, 0.3007, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 2, 2, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 30/63 [00:20<00:21,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2661, 0.4776, 0.2563],\n",
            "        [0.1538, 0.2213, 0.6249],\n",
            "        [0.2383, 0.5284, 0.2333],\n",
            "        [0.1942, 0.1945, 0.6113],\n",
            "        [0.1538, 0.2844, 0.5617],\n",
            "        [0.3408, 0.2460, 0.4133],\n",
            "        [0.0770, 0.4922, 0.4308],\n",
            "        [0.1977, 0.4940, 0.3083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2661, 0.4776, 0.2563],\n",
            "        [0.1538, 0.2213, 0.6249],\n",
            "        [0.2383, 0.5284, 0.2333],\n",
            "        [0.1942, 0.1945, 0.6113],\n",
            "        [0.1538, 0.2844, 0.5617],\n",
            "        [0.3408, 0.2460, 0.4133],\n",
            "        [0.0770, 0.4922, 0.4308],\n",
            "        [0.1977, 0.4940, 0.3083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 2, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 31/63 [00:21<00:20,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4082, 0.2022, 0.3895],\n",
            "        [0.1745, 0.2646, 0.5608],\n",
            "        [0.1816, 0.4546, 0.3638],\n",
            "        [0.2229, 0.2312, 0.5459],\n",
            "        [0.2396, 0.6143, 0.1461],\n",
            "        [0.2366, 0.5379, 0.2254],\n",
            "        [0.2548, 0.3895, 0.3558],\n",
            "        [0.2507, 0.3969, 0.3525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4082, 0.2022, 0.3895],\n",
            "        [0.1745, 0.2646, 0.5608],\n",
            "        [0.1816, 0.4546, 0.3638],\n",
            "        [0.2229, 0.2312, 0.5459],\n",
            "        [0.2396, 0.6143, 0.1461],\n",
            "        [0.2366, 0.5379, 0.2254],\n",
            "        [0.2548, 0.3895, 0.3558],\n",
            "        [0.2507, 0.3969, 0.3525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 1, 2, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 1, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 32/63 [00:21<00:20,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2409, 0.4880, 0.2711],\n",
            "        [0.2554, 0.1314, 0.6132],\n",
            "        [0.1423, 0.6094, 0.2483],\n",
            "        [0.1698, 0.4470, 0.3832],\n",
            "        [0.1166, 0.5343, 0.3492],\n",
            "        [0.1435, 0.5028, 0.3537],\n",
            "        [0.3214, 0.5419, 0.1367],\n",
            "        [0.2059, 0.5030, 0.2911]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2409, 0.4880, 0.2711],\n",
            "        [0.2554, 0.1314, 0.6132],\n",
            "        [0.1423, 0.6094, 0.2483],\n",
            "        [0.1698, 0.4470, 0.3832],\n",
            "        [0.1166, 0.5343, 0.3492],\n",
            "        [0.1435, 0.5028, 0.3537],\n",
            "        [0.3214, 0.5419, 0.1367],\n",
            "        [0.2059, 0.5030, 0.2911]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 0, 0, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/63 [00:22<00:19,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2317, 0.5080, 0.2603],\n",
            "        [0.2888, 0.3874, 0.3238],\n",
            "        [0.0562, 0.4275, 0.5163],\n",
            "        [0.1267, 0.5841, 0.2892],\n",
            "        [0.2213, 0.3126, 0.4661],\n",
            "        [0.1097, 0.4420, 0.4482],\n",
            "        [0.2292, 0.3475, 0.4233],\n",
            "        [0.3472, 0.3829, 0.2699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2317, 0.5080, 0.2603],\n",
            "        [0.2888, 0.3874, 0.3238],\n",
            "        [0.0562, 0.4275, 0.5163],\n",
            "        [0.1267, 0.5841, 0.2892],\n",
            "        [0.2213, 0.3126, 0.4661],\n",
            "        [0.1097, 0.4420, 0.4482],\n",
            "        [0.2292, 0.3475, 0.4233],\n",
            "        [0.3472, 0.3829, 0.2699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 1, 2, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 34/63 [00:23<00:18,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2958, 0.4609, 0.2433],\n",
            "        [0.1941, 0.2025, 0.6034],\n",
            "        [0.2297, 0.5187, 0.2516],\n",
            "        [0.2836, 0.2617, 0.4547],\n",
            "        [0.1791, 0.2905, 0.5304],\n",
            "        [0.1640, 0.4309, 0.4052],\n",
            "        [0.2890, 0.4168, 0.2943],\n",
            "        [0.2361, 0.5725, 0.1914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2958, 0.4609, 0.2433],\n",
            "        [0.1941, 0.2025, 0.6034],\n",
            "        [0.2297, 0.5187, 0.2516],\n",
            "        [0.2836, 0.2617, 0.4547],\n",
            "        [0.1791, 0.2905, 0.5304],\n",
            "        [0.1640, 0.4309, 0.4052],\n",
            "        [0.2890, 0.4168, 0.2943],\n",
            "        [0.2361, 0.5725, 0.1914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 0, 1, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 35/63 [00:23<00:18,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1445, 0.4079, 0.4477],\n",
            "        [0.1085, 0.3388, 0.5527],\n",
            "        [0.1985, 0.4142, 0.3873],\n",
            "        [0.1553, 0.6283, 0.2164],\n",
            "        [0.2005, 0.3532, 0.4463],\n",
            "        [0.6235, 0.1194, 0.2571],\n",
            "        [0.1329, 0.4918, 0.3752],\n",
            "        [0.2161, 0.2157, 0.5682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1445, 0.4079, 0.4477],\n",
            "        [0.1085, 0.3388, 0.5527],\n",
            "        [0.1985, 0.4142, 0.3873],\n",
            "        [0.1553, 0.6283, 0.2164],\n",
            "        [0.2005, 0.3532, 0.4463],\n",
            "        [0.6235, 0.1194, 0.2571],\n",
            "        [0.1329, 0.4918, 0.3752],\n",
            "        [0.2161, 0.2157, 0.5682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 2, 2, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 36/63 [00:24<00:17,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4232, 0.3802, 0.1966],\n",
            "        [0.1022, 0.3181, 0.5797],\n",
            "        [0.0549, 0.1872, 0.7579],\n",
            "        [0.1335, 0.6713, 0.1952],\n",
            "        [0.1085, 0.4408, 0.4507],\n",
            "        [0.1860, 0.2230, 0.5910],\n",
            "        [0.1436, 0.6677, 0.1887],\n",
            "        [0.2311, 0.3264, 0.4424]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4232, 0.3802, 0.1966],\n",
            "        [0.1022, 0.3181, 0.5797],\n",
            "        [0.0549, 0.1872, 0.7579],\n",
            "        [0.1335, 0.6713, 0.1952],\n",
            "        [0.1085, 0.4408, 0.4507],\n",
            "        [0.1860, 0.2230, 0.5910],\n",
            "        [0.1436, 0.6677, 0.1887],\n",
            "        [0.2311, 0.3264, 0.4424]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 1, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 1, 0, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 37/63 [00:25<00:17,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2975, 0.2744, 0.4281],\n",
            "        [0.1471, 0.2160, 0.6369],\n",
            "        [0.2346, 0.2581, 0.5073],\n",
            "        [0.3111, 0.2208, 0.4681],\n",
            "        [0.1092, 0.6926, 0.1982],\n",
            "        [0.0632, 0.3460, 0.5908],\n",
            "        [0.3968, 0.2643, 0.3390],\n",
            "        [0.1240, 0.6565, 0.2194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2975, 0.2744, 0.4281],\n",
            "        [0.1471, 0.2160, 0.6369],\n",
            "        [0.2346, 0.2581, 0.5073],\n",
            "        [0.3111, 0.2208, 0.4681],\n",
            "        [0.1092, 0.6926, 0.1982],\n",
            "        [0.0632, 0.3460, 0.5908],\n",
            "        [0.3968, 0.2643, 0.3390],\n",
            "        [0.1240, 0.6565, 0.2194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 1, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 2, 2, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 38/63 [00:25<00:16,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2509, 0.2582, 0.4910],\n",
            "        [0.2987, 0.2802, 0.4211],\n",
            "        [0.1868, 0.3504, 0.4628],\n",
            "        [0.3094, 0.2798, 0.4109],\n",
            "        [0.0948, 0.4455, 0.4597],\n",
            "        [0.1223, 0.5141, 0.3636],\n",
            "        [0.3522, 0.2426, 0.4052],\n",
            "        [0.1128, 0.2479, 0.6393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2509, 0.2582, 0.4910],\n",
            "        [0.2987, 0.2802, 0.4211],\n",
            "        [0.1868, 0.3504, 0.4628],\n",
            "        [0.3094, 0.2798, 0.4109],\n",
            "        [0.0948, 0.4455, 0.4597],\n",
            "        [0.1223, 0.5141, 0.3636],\n",
            "        [0.3522, 0.2426, 0.4052],\n",
            "        [0.1128, 0.2479, 0.6393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 2, 2, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 39/63 [00:26<00:15,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2619, 0.5898, 0.1483],\n",
            "        [0.3764, 0.4358, 0.1879],\n",
            "        [0.2457, 0.4158, 0.3384],\n",
            "        [0.0901, 0.3485, 0.5614],\n",
            "        [0.0983, 0.5764, 0.3253],\n",
            "        [0.1818, 0.4961, 0.3220],\n",
            "        [0.3252, 0.4319, 0.2430],\n",
            "        [0.0734, 0.4625, 0.4641]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2619, 0.5898, 0.1483],\n",
            "        [0.3764, 0.4358, 0.1879],\n",
            "        [0.2457, 0.4158, 0.3384],\n",
            "        [0.0901, 0.3485, 0.5614],\n",
            "        [0.0983, 0.5764, 0.3253],\n",
            "        [0.1818, 0.4961, 0.3220],\n",
            "        [0.3252, 0.4319, 0.2430],\n",
            "        [0.0734, 0.4625, 0.4641]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 1, 2, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 40/63 [00:27<00:15,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1215, 0.6912, 0.1873],\n",
            "        [0.1992, 0.3101, 0.4906],\n",
            "        [0.2817, 0.2202, 0.4980],\n",
            "        [0.3486, 0.3390, 0.3125],\n",
            "        [0.1761, 0.2473, 0.5766],\n",
            "        [0.1798, 0.3449, 0.4753],\n",
            "        [0.3728, 0.3633, 0.2639],\n",
            "        [0.0958, 0.6191, 0.2852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1215, 0.6912, 0.1873],\n",
            "        [0.1992, 0.3101, 0.4906],\n",
            "        [0.2817, 0.2202, 0.4980],\n",
            "        [0.3486, 0.3390, 0.3125],\n",
            "        [0.1761, 0.2473, 0.5766],\n",
            "        [0.1798, 0.3449, 0.4753],\n",
            "        [0.3728, 0.3633, 0.2639],\n",
            "        [0.0958, 0.6191, 0.2852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 0, 2, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 1, 0, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 41/63 [00:27<00:14,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2079, 0.5590, 0.2331],\n",
            "        [0.4107, 0.3185, 0.2708],\n",
            "        [0.1274, 0.5053, 0.3673],\n",
            "        [0.1918, 0.2436, 0.5646],\n",
            "        [0.1412, 0.4137, 0.4451],\n",
            "        [0.2663, 0.3293, 0.4044],\n",
            "        [0.2474, 0.5476, 0.2050],\n",
            "        [0.4675, 0.4052, 0.1273]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2079, 0.5590, 0.2331],\n",
            "        [0.4107, 0.3185, 0.2708],\n",
            "        [0.1274, 0.5053, 0.3673],\n",
            "        [0.1918, 0.2436, 0.5646],\n",
            "        [0.1412, 0.4137, 0.4451],\n",
            "        [0.2663, 0.3293, 0.4044],\n",
            "        [0.2474, 0.5476, 0.2050],\n",
            "        [0.4675, 0.4052, 0.1273]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 2, 2, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 42/63 [00:28<00:13,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0925, 0.4215, 0.4860],\n",
            "        [0.1619, 0.3906, 0.4475],\n",
            "        [0.3963, 0.2809, 0.3228],\n",
            "        [0.1970, 0.3761, 0.4269],\n",
            "        [0.4525, 0.3853, 0.1622],\n",
            "        [0.4713, 0.3290, 0.1997],\n",
            "        [0.2002, 0.5088, 0.2910],\n",
            "        [0.2799, 0.3437, 0.3764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0925, 0.4215, 0.4860],\n",
            "        [0.1619, 0.3906, 0.4475],\n",
            "        [0.3963, 0.2809, 0.3228],\n",
            "        [0.1970, 0.3761, 0.4269],\n",
            "        [0.4525, 0.3853, 0.1622],\n",
            "        [0.4713, 0.3290, 0.1997],\n",
            "        [0.2002, 0.5088, 0.2910],\n",
            "        [0.2799, 0.3437, 0.3764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 2, 0, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 0, 1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 43/63 [00:29<00:13,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2790, 0.2753, 0.4457],\n",
            "        [0.1596, 0.4204, 0.4200],\n",
            "        [0.2264, 0.4012, 0.3724],\n",
            "        [0.3590, 0.2196, 0.4214],\n",
            "        [0.1591, 0.3570, 0.4838],\n",
            "        [0.1604, 0.4123, 0.4273],\n",
            "        [0.1748, 0.5032, 0.3219],\n",
            "        [0.2074, 0.2802, 0.5124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2790, 0.2753, 0.4457],\n",
            "        [0.1596, 0.4204, 0.4200],\n",
            "        [0.2264, 0.4012, 0.3724],\n",
            "        [0.3590, 0.2196, 0.4214],\n",
            "        [0.1591, 0.3570, 0.4838],\n",
            "        [0.1604, 0.4123, 0.4273],\n",
            "        [0.1748, 0.5032, 0.3219],\n",
            "        [0.2074, 0.2802, 0.5124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 0, 0, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 44/63 [00:29<00:12,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3666, 0.2933, 0.3401],\n",
            "        [0.3777, 0.3349, 0.2875],\n",
            "        [0.2008, 0.3838, 0.4154],\n",
            "        [0.2022, 0.2468, 0.5510],\n",
            "        [0.2723, 0.3557, 0.3720],\n",
            "        [0.3467, 0.3613, 0.2920],\n",
            "        [0.1776, 0.6548, 0.1676],\n",
            "        [0.1590, 0.5498, 0.2912]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3666, 0.2933, 0.3401],\n",
            "        [0.3777, 0.3349, 0.2875],\n",
            "        [0.2008, 0.3838, 0.4154],\n",
            "        [0.2022, 0.2468, 0.5510],\n",
            "        [0.2723, 0.3557, 0.3720],\n",
            "        [0.3467, 0.3613, 0.2920],\n",
            "        [0.1776, 0.6548, 0.1676],\n",
            "        [0.1590, 0.5498, 0.2912]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 2, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 0, 1, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 45/63 [00:30<00:11,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1595, 0.6847, 0.1558],\n",
            "        [0.2432, 0.4493, 0.3074],\n",
            "        [0.2730, 0.5641, 0.1629],\n",
            "        [0.1879, 0.2476, 0.5645],\n",
            "        [0.1830, 0.4221, 0.3949],\n",
            "        [0.2427, 0.4701, 0.2873],\n",
            "        [0.2302, 0.2700, 0.4998],\n",
            "        [0.3711, 0.2410, 0.3879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1595, 0.6847, 0.1558],\n",
            "        [0.2432, 0.4493, 0.3074],\n",
            "        [0.2730, 0.5641, 0.1629],\n",
            "        [0.1879, 0.2476, 0.5645],\n",
            "        [0.1830, 0.4221, 0.3949],\n",
            "        [0.2427, 0.4701, 0.2873],\n",
            "        [0.2302, 0.2700, 0.4998],\n",
            "        [0.3711, 0.2410, 0.3879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 1, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 2, 0, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 46/63 [00:31<00:11,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1127, 0.7236, 0.1637],\n",
            "        [0.2081, 0.3510, 0.4409],\n",
            "        [0.1080, 0.3406, 0.5514],\n",
            "        [0.0880, 0.7055, 0.2064],\n",
            "        [0.3331, 0.4167, 0.2502],\n",
            "        [0.2260, 0.3969, 0.3771],\n",
            "        [0.1067, 0.1591, 0.7342],\n",
            "        [0.2683, 0.5736, 0.1581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1127, 0.7236, 0.1637],\n",
            "        [0.2081, 0.3510, 0.4409],\n",
            "        [0.1080, 0.3406, 0.5514],\n",
            "        [0.0880, 0.7055, 0.2064],\n",
            "        [0.3331, 0.4167, 0.2502],\n",
            "        [0.2260, 0.3969, 0.3771],\n",
            "        [0.1067, 0.1591, 0.7342],\n",
            "        [0.2683, 0.5736, 0.1581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 1, 1, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 0, 0, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 47/63 [00:31<00:10,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4078, 0.3435, 0.2487],\n",
            "        [0.1614, 0.6160, 0.2226],\n",
            "        [0.0439, 0.4824, 0.4737],\n",
            "        [0.0839, 0.7586, 0.1575],\n",
            "        [0.2251, 0.6226, 0.1523],\n",
            "        [0.3646, 0.4881, 0.1473],\n",
            "        [0.3058, 0.3540, 0.3403],\n",
            "        [0.3246, 0.3630, 0.3124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4078, 0.3435, 0.2487],\n",
            "        [0.1614, 0.6160, 0.2226],\n",
            "        [0.0439, 0.4824, 0.4737],\n",
            "        [0.0839, 0.7586, 0.1575],\n",
            "        [0.2251, 0.6226, 0.1523],\n",
            "        [0.3646, 0.4881, 0.1473],\n",
            "        [0.3058, 0.3540, 0.3403],\n",
            "        [0.3246, 0.3630, 0.3124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 0, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 48/63 [00:32<00:09,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2122, 0.5271, 0.2607],\n",
            "        [0.1870, 0.4746, 0.3383],\n",
            "        [0.5348, 0.3056, 0.1597],\n",
            "        [0.1335, 0.6795, 0.1870],\n",
            "        [0.2754, 0.3614, 0.3632],\n",
            "        [0.2180, 0.3594, 0.4226],\n",
            "        [0.2578, 0.5448, 0.1973],\n",
            "        [0.5412, 0.2596, 0.1991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2122, 0.5271, 0.2607],\n",
            "        [0.1870, 0.4746, 0.3383],\n",
            "        [0.5348, 0.3056, 0.1597],\n",
            "        [0.1335, 0.6795, 0.1870],\n",
            "        [0.2754, 0.3614, 0.3632],\n",
            "        [0.2180, 0.3594, 0.4226],\n",
            "        [0.2578, 0.5448, 0.1973],\n",
            "        [0.5412, 0.2596, 0.1991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 2, 2, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 49/63 [00:33<00:09,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2012, 0.1095, 0.6893],\n",
            "        [0.3879, 0.2693, 0.3428],\n",
            "        [0.3192, 0.5493, 0.1315],\n",
            "        [0.2578, 0.3888, 0.3534],\n",
            "        [0.2091, 0.5051, 0.2858],\n",
            "        [0.1263, 0.2808, 0.5929],\n",
            "        [0.0868, 0.7171, 0.1961],\n",
            "        [0.1080, 0.4285, 0.4634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2012, 0.1095, 0.6893],\n",
            "        [0.3879, 0.2693, 0.3428],\n",
            "        [0.3192, 0.5493, 0.1315],\n",
            "        [0.2578, 0.3888, 0.3534],\n",
            "        [0.2091, 0.5051, 0.2858],\n",
            "        [0.1263, 0.2808, 0.5929],\n",
            "        [0.0868, 0.7171, 0.1961],\n",
            "        [0.1080, 0.4285, 0.4634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 1, 1, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 2, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 50/63 [00:33<00:08,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2098, 0.0606, 0.7296],\n",
            "        [0.1577, 0.4508, 0.3915],\n",
            "        [0.4643, 0.3845, 0.1512],\n",
            "        [0.1627, 0.6302, 0.2072],\n",
            "        [0.2750, 0.4955, 0.2295],\n",
            "        [0.1299, 0.4747, 0.3954],\n",
            "        [0.2318, 0.5539, 0.2144],\n",
            "        [0.2373, 0.4300, 0.3326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2098, 0.0606, 0.7296],\n",
            "        [0.1577, 0.4508, 0.3915],\n",
            "        [0.4643, 0.3845, 0.1512],\n",
            "        [0.1627, 0.6302, 0.2072],\n",
            "        [0.2750, 0.4955, 0.2295],\n",
            "        [0.1299, 0.4747, 0.3954],\n",
            "        [0.2318, 0.5539, 0.2144],\n",
            "        [0.2373, 0.4300, 0.3326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 0, 0, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 51/63 [00:34<00:07,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1502, 0.7384, 0.1114],\n",
            "        [0.2313, 0.3425, 0.4261],\n",
            "        [0.2547, 0.4497, 0.2956],\n",
            "        [0.1808, 0.4124, 0.4069],\n",
            "        [0.2181, 0.5792, 0.2028],\n",
            "        [0.2114, 0.4826, 0.3059],\n",
            "        [0.1897, 0.3480, 0.4623],\n",
            "        [0.1743, 0.5683, 0.2575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1502, 0.7384, 0.1114],\n",
            "        [0.2313, 0.3425, 0.4261],\n",
            "        [0.2547, 0.4497, 0.2956],\n",
            "        [0.1808, 0.4124, 0.4069],\n",
            "        [0.2181, 0.5792, 0.2028],\n",
            "        [0.2114, 0.4826, 0.3059],\n",
            "        [0.1897, 0.3480, 0.4623],\n",
            "        [0.1743, 0.5683, 0.2575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 1, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 0, 2, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 52/63 [00:34<00:07,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3488, 0.3598, 0.2914],\n",
            "        [0.2412, 0.2902, 0.4686],\n",
            "        [0.2280, 0.2036, 0.5684],\n",
            "        [0.2023, 0.3958, 0.4019],\n",
            "        [0.0858, 0.2786, 0.6357],\n",
            "        [0.2959, 0.4191, 0.2850],\n",
            "        [0.3372, 0.1949, 0.4678],\n",
            "        [0.2054, 0.5317, 0.2629]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3488, 0.3598, 0.2914],\n",
            "        [0.2412, 0.2902, 0.4686],\n",
            "        [0.2280, 0.2036, 0.5684],\n",
            "        [0.2023, 0.3958, 0.4019],\n",
            "        [0.0858, 0.2786, 0.6357],\n",
            "        [0.2959, 0.4191, 0.2850],\n",
            "        [0.3372, 0.1949, 0.4678],\n",
            "        [0.2054, 0.5317, 0.2629]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 2, 2, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 2, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 53/63 [00:35<00:06,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0298, 0.3277, 0.6425],\n",
            "        [0.3394, 0.5014, 0.1592],\n",
            "        [0.1950, 0.4343, 0.3707],\n",
            "        [0.2897, 0.3164, 0.3939],\n",
            "        [0.0959, 0.7263, 0.1778],\n",
            "        [0.2175, 0.4599, 0.3225],\n",
            "        [0.2576, 0.1804, 0.5620],\n",
            "        [0.2670, 0.3639, 0.3691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0298, 0.3277, 0.6425],\n",
            "        [0.3394, 0.5014, 0.1592],\n",
            "        [0.1950, 0.4343, 0.3707],\n",
            "        [0.2897, 0.3164, 0.3939],\n",
            "        [0.0959, 0.7263, 0.1778],\n",
            "        [0.2175, 0.4599, 0.3225],\n",
            "        [0.2576, 0.1804, 0.5620],\n",
            "        [0.2670, 0.3639, 0.3691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 2, 1, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 0, 0, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 54/63 [00:36<00:05,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3854, 0.2680, 0.3466],\n",
            "        [0.2650, 0.4162, 0.3188],\n",
            "        [0.2138, 0.1880, 0.5982],\n",
            "        [0.3456, 0.4911, 0.1633],\n",
            "        [0.1455, 0.4481, 0.4064],\n",
            "        [0.1016, 0.7837, 0.1147],\n",
            "        [0.0995, 0.3693, 0.5312],\n",
            "        [0.1351, 0.4105, 0.4544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3854, 0.2680, 0.3466],\n",
            "        [0.2650, 0.4162, 0.3188],\n",
            "        [0.2138, 0.1880, 0.5982],\n",
            "        [0.3456, 0.4911, 0.1633],\n",
            "        [0.1455, 0.4481, 0.4064],\n",
            "        [0.1016, 0.7837, 0.1147],\n",
            "        [0.0995, 0.3693, 0.5312],\n",
            "        [0.1351, 0.4105, 0.4544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 1, 1, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 0, 2, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 55/63 [00:36<00:05,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2713, 0.3261, 0.4025],\n",
            "        [0.1759, 0.4513, 0.3729],\n",
            "        [0.2457, 0.3108, 0.4435],\n",
            "        [0.2929, 0.4538, 0.2533],\n",
            "        [0.2140, 0.6284, 0.1577],\n",
            "        [0.2963, 0.2159, 0.4878],\n",
            "        [0.2210, 0.4109, 0.3681],\n",
            "        [0.2571, 0.4798, 0.2631]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2713, 0.3261, 0.4025],\n",
            "        [0.1759, 0.4513, 0.3729],\n",
            "        [0.2457, 0.3108, 0.4435],\n",
            "        [0.2929, 0.4538, 0.2533],\n",
            "        [0.2140, 0.6284, 0.1577],\n",
            "        [0.2963, 0.2159, 0.4878],\n",
            "        [0.2210, 0.4109, 0.3681],\n",
            "        [0.2571, 0.4798, 0.2631]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 1, 1, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 1, 1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 56/63 [00:37<00:04,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4059, 0.2806, 0.3134],\n",
            "        [0.2274, 0.5463, 0.2262],\n",
            "        [0.5629, 0.1437, 0.2934],\n",
            "        [0.1158, 0.5353, 0.3488],\n",
            "        [0.5108, 0.1482, 0.3409],\n",
            "        [0.2720, 0.4375, 0.2905],\n",
            "        [0.2224, 0.2692, 0.5084],\n",
            "        [0.1373, 0.5249, 0.3377]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4059, 0.2806, 0.3134],\n",
            "        [0.2274, 0.5463, 0.2262],\n",
            "        [0.5629, 0.1437, 0.2934],\n",
            "        [0.1158, 0.5353, 0.3488],\n",
            "        [0.5108, 0.1482, 0.3409],\n",
            "        [0.2720, 0.4375, 0.2905],\n",
            "        [0.2224, 0.2692, 0.5084],\n",
            "        [0.1373, 0.5249, 0.3377]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 1, 0, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 0, 0, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 57/63 [00:38<00:03,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2426, 0.4641, 0.2933],\n",
            "        [0.0654, 0.5893, 0.3452],\n",
            "        [0.6040, 0.1843, 0.2117],\n",
            "        [0.3620, 0.5105, 0.1275],\n",
            "        [0.3338, 0.4199, 0.2464],\n",
            "        [0.2472, 0.1854, 0.5675],\n",
            "        [0.1718, 0.3872, 0.4409],\n",
            "        [0.1957, 0.3941, 0.4102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2426, 0.4641, 0.2933],\n",
            "        [0.0654, 0.5893, 0.3452],\n",
            "        [0.6040, 0.1843, 0.2117],\n",
            "        [0.3620, 0.5105, 0.1275],\n",
            "        [0.3338, 0.4199, 0.2464],\n",
            "        [0.2472, 0.1854, 0.5675],\n",
            "        [0.1718, 0.3872, 0.4409],\n",
            "        [0.1957, 0.3941, 0.4102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 1, 0, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 58/63 [00:38<00:03,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2975, 0.3437, 0.3588],\n",
            "        [0.1704, 0.2300, 0.5996],\n",
            "        [0.4304, 0.2638, 0.3058],\n",
            "        [0.2894, 0.5660, 0.1446],\n",
            "        [0.2207, 0.4275, 0.3518],\n",
            "        [0.1607, 0.2535, 0.5858],\n",
            "        [0.2045, 0.2261, 0.5694],\n",
            "        [0.2327, 0.3825, 0.3848]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2975, 0.3437, 0.3588],\n",
            "        [0.1704, 0.2300, 0.5996],\n",
            "        [0.4304, 0.2638, 0.3058],\n",
            "        [0.2894, 0.5660, 0.1446],\n",
            "        [0.2207, 0.4275, 0.3518],\n",
            "        [0.1607, 0.2535, 0.5858],\n",
            "        [0.2045, 0.2261, 0.5694],\n",
            "        [0.2327, 0.3825, 0.3848]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 0, 1, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 59/63 [00:39<00:02,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1249, 0.2885, 0.5866],\n",
            "        [0.3074, 0.1788, 0.5138],\n",
            "        [0.3249, 0.1821, 0.4931],\n",
            "        [0.1821, 0.3739, 0.4440],\n",
            "        [0.2548, 0.3299, 0.4154],\n",
            "        [0.4875, 0.2547, 0.2577],\n",
            "        [0.1612, 0.5126, 0.3261],\n",
            "        [0.1297, 0.2994, 0.5709]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1249, 0.2885, 0.5866],\n",
            "        [0.3074, 0.1788, 0.5138],\n",
            "        [0.3249, 0.1821, 0.4931],\n",
            "        [0.1821, 0.3739, 0.4440],\n",
            "        [0.2548, 0.3299, 0.4154],\n",
            "        [0.4875, 0.2547, 0.2577],\n",
            "        [0.1612, 0.5126, 0.3261],\n",
            "        [0.1297, 0.2994, 0.5709]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 60/63 [00:40<00:01,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3254, 0.3839, 0.2907],\n",
            "        [0.1302, 0.2746, 0.5953],\n",
            "        [0.2179, 0.4538, 0.3283],\n",
            "        [0.1476, 0.3493, 0.5032],\n",
            "        [0.1937, 0.4744, 0.3318],\n",
            "        [0.1585, 0.3132, 0.5282],\n",
            "        [0.2530, 0.3430, 0.4040],\n",
            "        [0.0958, 0.5029, 0.4013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3254, 0.3839, 0.2907],\n",
            "        [0.1302, 0.2746, 0.5953],\n",
            "        [0.2179, 0.4538, 0.3283],\n",
            "        [0.1476, 0.3493, 0.5032],\n",
            "        [0.1937, 0.4744, 0.3318],\n",
            "        [0.1585, 0.3132, 0.5282],\n",
            "        [0.2530, 0.3430, 0.4040],\n",
            "        [0.0958, 0.5029, 0.4013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 1, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 1, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 61/63 [00:40<00:01,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3385, 0.4384, 0.2230],\n",
            "        [0.3799, 0.3019, 0.3182],\n",
            "        [0.3371, 0.3848, 0.2781],\n",
            "        [0.2762, 0.4885, 0.2353],\n",
            "        [0.2422, 0.5979, 0.1599],\n",
            "        [0.1556, 0.1993, 0.6451],\n",
            "        [0.1551, 0.4695, 0.3754],\n",
            "        [0.0675, 0.1427, 0.7898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3385, 0.4384, 0.2230],\n",
            "        [0.3799, 0.3019, 0.3182],\n",
            "        [0.3371, 0.3848, 0.2781],\n",
            "        [0.2762, 0.4885, 0.2353],\n",
            "        [0.2422, 0.5979, 0.1599],\n",
            "        [0.1556, 0.1993, 0.6451],\n",
            "        [0.1551, 0.4695, 0.3754],\n",
            "        [0.0675, 0.1427, 0.7898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 1, 1, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 0, 2, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 62/63 [00:41<00:00,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3143, 0.4375, 0.2482],\n",
            "        [0.3072, 0.3701, 0.3226],\n",
            "        [0.1562, 0.6332, 0.2106],\n",
            "        [0.2734, 0.4093, 0.3173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3143, 0.4375, 0.2482],\n",
            "        [0.3072, 0.3701, 0.3226],\n",
            "        [0.1562, 0.6332, 0.2106],\n",
            "        [0.2734, 0.4093, 0.3173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:42<00:00,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.2114, 0.5253, 0.2633],\n",
            "        [0.3347, 0.5149, 0.1504],\n",
            "        [0.3259, 0.1941, 0.4800],\n",
            "        [0.3198, 0.5170, 0.1632],\n",
            "        [0.1681, 0.4184, 0.4135],\n",
            "        [0.6058, 0.1837, 0.2105],\n",
            "        [0.2190, 0.5703, 0.2107],\n",
            "        [0.3138, 0.4191, 0.2671]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 1, 1, 0, 1, 1], device='cuda:0')\n",
            "tensor([[0.2114, 0.5253, 0.2633],\n",
            "        [0.3347, 0.5149, 0.1504],\n",
            "        [0.3259, 0.1941, 0.4800],\n",
            "        [0.3198, 0.5170, 0.1632],\n",
            "        [0.1681, 0.4184, 0.4135],\n",
            "        [0.6058, 0.1837, 0.2105],\n",
            "        [0.2190, 0.5703, 0.2107],\n",
            "        [0.3138, 0.4191, 0.2671]], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2308, 0.3639, 0.4053],\n",
            "        [0.2233, 0.1619, 0.6148],\n",
            "        [0.1085, 0.7086, 0.1829],\n",
            "        [0.1167, 0.5100, 0.3732],\n",
            "        [0.1634, 0.2259, 0.6108],\n",
            "        [0.1595, 0.1788, 0.6617],\n",
            "        [0.2595, 0.2926, 0.4479],\n",
            "        [0.4021, 0.3228, 0.2751]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 1, 2, 2, 2, 0], device='cuda:0')\n",
            "tensor([[0.2308, 0.3639, 0.4053],\n",
            "        [0.2233, 0.1619, 0.6148],\n",
            "        [0.1085, 0.7086, 0.1829],\n",
            "        [0.1167, 0.5100, 0.3732],\n",
            "        [0.1634, 0.2259, 0.6108],\n",
            "        [0.1595, 0.1788, 0.6617],\n",
            "        [0.2595, 0.2926, 0.4479],\n",
            "        [0.4021, 0.3228, 0.2751]], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.1840, 0.2557, 0.5603],\n",
            "        [0.1960, 0.3429, 0.4611],\n",
            "        [0.1381, 0.2810, 0.5809],\n",
            "        [0.1775, 0.4496, 0.3730],\n",
            "        [0.2181, 0.1390, 0.6429],\n",
            "        [0.2391, 0.2693, 0.4916],\n",
            "        [0.0975, 0.4447, 0.4578],\n",
            "        [0.2107, 0.5984, 0.1909]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 2, 1, 2, 2, 2, 1], device='cuda:0')\n",
            "tensor([[0.1840, 0.2557, 0.5603],\n",
            "        [0.1960, 0.3429, 0.4611],\n",
            "        [0.1381, 0.2810, 0.5809],\n",
            "        [0.1775, 0.4496, 0.3730],\n",
            "        [0.2181, 0.1390, 0.6429],\n",
            "        [0.2391, 0.2693, 0.4916],\n",
            "        [0.0975, 0.4447, 0.4578],\n",
            "        [0.2107, 0.5984, 0.1909]], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.2773, 0.3678, 0.3549],\n",
            "        [0.1748, 0.4662, 0.3589],\n",
            "        [0.1742, 0.3172, 0.5086],\n",
            "        [0.4706, 0.3140, 0.2154],\n",
            "        [0.2868, 0.3099, 0.4033],\n",
            "        [0.1431, 0.3222, 0.5346],\n",
            "        [0.2163, 0.2984, 0.4853],\n",
            "        [0.2786, 0.2518, 0.4697]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 0, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[0.2773, 0.3678, 0.3549],\n",
            "        [0.1748, 0.4662, 0.3589],\n",
            "        [0.1742, 0.3172, 0.5086],\n",
            "        [0.4706, 0.3140, 0.2154],\n",
            "        [0.2868, 0.3099, 0.4033],\n",
            "        [0.1431, 0.3222, 0.5346],\n",
            "        [0.2163, 0.2984, 0.4853],\n",
            "        [0.2786, 0.2518, 0.4697]], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2281, 0.4836, 0.2883],\n",
            "        [0.3895, 0.4104, 0.2001],\n",
            "        [0.4198, 0.4271, 0.1531],\n",
            "        [0.2159, 0.2969, 0.4872],\n",
            "        [0.1908, 0.2066, 0.6027],\n",
            "        [0.4382, 0.2973, 0.2645],\n",
            "        [0.2012, 0.1798, 0.6190],\n",
            "        [0.1806, 0.5167, 0.3027]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 1, 2, 2, 0, 2, 1], device='cuda:0')\n",
            "tensor([[0.2281, 0.4836, 0.2883],\n",
            "        [0.3895, 0.4104, 0.2001],\n",
            "        [0.4198, 0.4271, 0.1531],\n",
            "        [0.2159, 0.2969, 0.4872],\n",
            "        [0.1908, 0.2066, 0.6027],\n",
            "        [0.4382, 0.2973, 0.2645],\n",
            "        [0.2012, 0.1798, 0.6190],\n",
            "        [0.1806, 0.5167, 0.3027]], device='cuda:0')\n",
            "tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.1884, 0.4217, 0.3899],\n",
            "        [0.2303, 0.2555, 0.5142],\n",
            "        [0.3416, 0.2813, 0.3771],\n",
            "        [0.2655, 0.3700, 0.3645],\n",
            "        [0.3743, 0.2761, 0.3496],\n",
            "        [0.3647, 0.3739, 0.2614],\n",
            "        [0.1588, 0.5416, 0.2996],\n",
            "        [0.2543, 0.3252, 0.4205]], device='cuda:0')\n",
            "prediction: tensor([1, 2, 2, 1, 0, 1, 1, 2], device='cuda:0')\n",
            "tensor([[0.1884, 0.4217, 0.3899],\n",
            "        [0.2303, 0.2555, 0.5142],\n",
            "        [0.3416, 0.2813, 0.3771],\n",
            "        [0.2655, 0.3700, 0.3645],\n",
            "        [0.3743, 0.2761, 0.3496],\n",
            "        [0.3647, 0.3739, 0.2614],\n",
            "        [0.1588, 0.5416, 0.2996],\n",
            "        [0.2543, 0.3252, 0.4205]], device='cuda:0')\n",
            "tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2656, 0.3596, 0.3748],\n",
            "        [0.2944, 0.2978, 0.4078],\n",
            "        [0.1584, 0.5095, 0.3321],\n",
            "        [0.2427, 0.2731, 0.4842],\n",
            "        [0.3645, 0.2431, 0.3924],\n",
            "        [0.0905, 0.1427, 0.7668],\n",
            "        [0.2502, 0.3740, 0.3758],\n",
            "        [0.3447, 0.3165, 0.3389]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 2, 2, 2, 2, 0], device='cuda:0')\n",
            "tensor([[0.2656, 0.3596, 0.3748],\n",
            "        [0.2944, 0.2978, 0.4078],\n",
            "        [0.1584, 0.5095, 0.3321],\n",
            "        [0.2427, 0.2731, 0.4842],\n",
            "        [0.3645, 0.2431, 0.3924],\n",
            "        [0.0905, 0.1427, 0.7668],\n",
            "        [0.2502, 0.3740, 0.3758],\n",
            "        [0.3447, 0.3165, 0.3389]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.2017, 0.6528, 0.1454],\n",
            "        [0.2933, 0.3779, 0.3288],\n",
            "        [0.1709, 0.1155, 0.7136],\n",
            "        [0.3869, 0.2822, 0.3308],\n",
            "        [0.3126, 0.3167, 0.3707],\n",
            "        [0.2766, 0.3285, 0.3949],\n",
            "        [0.3246, 0.5017, 0.1737],\n",
            "        [0.2586, 0.5132, 0.2281]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 0, 2, 2, 1, 1], device='cuda:0')\n",
            "tensor([[0.2017, 0.6528, 0.1454],\n",
            "        [0.2933, 0.3779, 0.3288],\n",
            "        [0.1709, 0.1155, 0.7136],\n",
            "        [0.3869, 0.2822, 0.3308],\n",
            "        [0.3126, 0.3167, 0.3707],\n",
            "        [0.2766, 0.3285, 0.3949],\n",
            "        [0.3246, 0.5017, 0.1737],\n",
            "        [0.2586, 0.5132, 0.2281]], device='cuda:0')\n",
            "tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2961, 0.4779, 0.2260],\n",
            "        [0.3367, 0.3961, 0.2672],\n",
            "        [0.1454, 0.1751, 0.6796],\n",
            "        [0.2385, 0.2181, 0.5434],\n",
            "        [0.2791, 0.3237, 0.3972],\n",
            "        [0.1349, 0.4155, 0.4496],\n",
            "        [0.2310, 0.3448, 0.4242],\n",
            "        [0.2361, 0.2790, 0.4848]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[0.2961, 0.4779, 0.2260],\n",
            "        [0.3367, 0.3961, 0.2672],\n",
            "        [0.1454, 0.1751, 0.6796],\n",
            "        [0.2385, 0.2181, 0.5434],\n",
            "        [0.2791, 0.3237, 0.3972],\n",
            "        [0.1349, 0.4155, 0.4496],\n",
            "        [0.2310, 0.3448, 0.4242],\n",
            "        [0.2361, 0.2790, 0.4848]], device='cuda:0')\n",
            "tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.2323, 0.5384, 0.2293],\n",
            "        [0.2788, 0.3009, 0.4203],\n",
            "        [0.4442, 0.2806, 0.2752],\n",
            "        [0.2930, 0.4320, 0.2750],\n",
            "        [0.1819, 0.5017, 0.3164],\n",
            "        [0.3863, 0.2094, 0.4042],\n",
            "        [0.3841, 0.3329, 0.2829],\n",
            "        [0.2080, 0.4569, 0.3351]], device='cuda:0')\n",
            "prediction: tensor([1, 2, 0, 1, 1, 2, 0, 1], device='cuda:0')\n",
            "tensor([[0.2323, 0.5384, 0.2293],\n",
            "        [0.2788, 0.3009, 0.4203],\n",
            "        [0.4442, 0.2806, 0.2752],\n",
            "        [0.2930, 0.4320, 0.2750],\n",
            "        [0.1819, 0.5017, 0.3164],\n",
            "        [0.3863, 0.2094, 0.4042],\n",
            "        [0.3841, 0.3329, 0.2829],\n",
            "        [0.2080, 0.4569, 0.3351]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.2698, 0.2650, 0.4652],\n",
            "        [0.1405, 0.5578, 0.3017],\n",
            "        [0.3576, 0.3510, 0.2914],\n",
            "        [0.0852, 0.5207, 0.3941],\n",
            "        [0.1717, 0.3531, 0.4752],\n",
            "        [0.1240, 0.4658, 0.4102],\n",
            "        [0.3331, 0.1840, 0.4830],\n",
            "        [0.2298, 0.3716, 0.3987]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 1, 2, 1, 2, 2], device='cuda:0')\n",
            "tensor([[0.2698, 0.2650, 0.4652],\n",
            "        [0.1405, 0.5578, 0.3017],\n",
            "        [0.3576, 0.3510, 0.2914],\n",
            "        [0.0852, 0.5207, 0.3941],\n",
            "        [0.1717, 0.3531, 0.4752],\n",
            "        [0.1240, 0.4658, 0.4102],\n",
            "        [0.3331, 0.1840, 0.4830],\n",
            "        [0.2298, 0.3716, 0.3987]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.3209, 0.2558, 0.4233],\n",
            "        [0.2019, 0.2100, 0.5881],\n",
            "        [0.2536, 0.4256, 0.3208],\n",
            "        [0.1672, 0.4543, 0.3785],\n",
            "        [0.2205, 0.2617, 0.5178],\n",
            "        [0.5505, 0.2669, 0.1827],\n",
            "        [0.2331, 0.3061, 0.4608],\n",
            "        [0.1867, 0.2237, 0.5897]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 1, 2, 0, 2, 2], device='cuda:0')\n",
            "tensor([[0.3209, 0.2558, 0.4233],\n",
            "        [0.2019, 0.2100, 0.5881],\n",
            "        [0.2536, 0.4256, 0.3208],\n",
            "        [0.1672, 0.4543, 0.3785],\n",
            "        [0.2205, 0.2617, 0.5178],\n",
            "        [0.5505, 0.2669, 0.1827],\n",
            "        [0.2331, 0.3061, 0.4608],\n",
            "        [0.1867, 0.2237, 0.5897]], device='cuda:0')\n",
            "tensor([0, 2, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.1110, 0.4601, 0.4289],\n",
            "        [0.1732, 0.7536, 0.0733],\n",
            "        [0.3000, 0.4164, 0.2836],\n",
            "        [0.2071, 0.4198, 0.3731]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "tensor([[0.1110, 0.4601, 0.4289],\n",
            "        [0.1732, 0.7536, 0.0733],\n",
            "        [0.3000, 0.4164, 0.2836],\n",
            "        [0.2071, 0.4198, 0.3731]], device='cuda:0')\n",
            "Epochs: 1 | Train Loss:  0.140             | Train Accuracy:  0.306             | Val Loss:  0.145             | Val Accuracy:  0.310\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2519, 0.4342, 0.3139],\n",
            "        [0.3762, 0.2475, 0.3762],\n",
            "        [0.4682, 0.4489, 0.0829],\n",
            "        [0.2431, 0.4005, 0.3564],\n",
            "        [0.4010, 0.4810, 0.1180],\n",
            "        [0.3119, 0.2370, 0.4511],\n",
            "        [0.1235, 0.6838, 0.1927],\n",
            "        [0.2468, 0.2383, 0.5149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2519, 0.4342, 0.3139],\n",
            "        [0.3762, 0.2475, 0.3762],\n",
            "        [0.4682, 0.4489, 0.0829],\n",
            "        [0.2431, 0.4005, 0.3564],\n",
            "        [0.4010, 0.4810, 0.1180],\n",
            "        [0.3119, 0.2370, 0.4511],\n",
            "        [0.1235, 0.6838, 0.1927],\n",
            "        [0.2468, 0.2383, 0.5149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 1, 1, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 1, 0, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/63 [00:00<00:43,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2756, 0.4387, 0.2857],\n",
            "        [0.3170, 0.2971, 0.3860],\n",
            "        [0.1634, 0.2038, 0.6328],\n",
            "        [0.2645, 0.3856, 0.3499],\n",
            "        [0.1233, 0.2904, 0.5863],\n",
            "        [0.0961, 0.4648, 0.4392],\n",
            "        [0.2202, 0.4936, 0.2863],\n",
            "        [0.0815, 0.5057, 0.4129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2756, 0.4387, 0.2857],\n",
            "        [0.3170, 0.2971, 0.3860],\n",
            "        [0.1634, 0.2038, 0.6328],\n",
            "        [0.2645, 0.3856, 0.3499],\n",
            "        [0.1233, 0.2904, 0.5863],\n",
            "        [0.0961, 0.4648, 0.4392],\n",
            "        [0.2202, 0.4936, 0.2863],\n",
            "        [0.0815, 0.5057, 0.4129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 1, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 2, 0, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/63 [00:01<00:41,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4626, 0.4059, 0.1316],\n",
            "        [0.2367, 0.4764, 0.2869],\n",
            "        [0.4867, 0.2935, 0.2198],\n",
            "        [0.1254, 0.7286, 0.1460],\n",
            "        [0.1093, 0.3791, 0.5116],\n",
            "        [0.0794, 0.3024, 0.6182],\n",
            "        [0.2418, 0.4783, 0.2799],\n",
            "        [0.4036, 0.2425, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4626, 0.4059, 0.1316],\n",
            "        [0.2367, 0.4764, 0.2869],\n",
            "        [0.4867, 0.2935, 0.2198],\n",
            "        [0.1254, 0.7286, 0.1460],\n",
            "        [0.1093, 0.3791, 0.5116],\n",
            "        [0.0794, 0.3024, 0.6182],\n",
            "        [0.2418, 0.4783, 0.2799],\n",
            "        [0.4036, 0.2425, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 2, 0, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/63 [00:02<00:40,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1586, 0.4893, 0.3521],\n",
            "        [0.3434, 0.3220, 0.3346],\n",
            "        [0.2763, 0.3883, 0.3354],\n",
            "        [0.3165, 0.3676, 0.3159],\n",
            "        [0.2079, 0.4635, 0.3286],\n",
            "        [0.2370, 0.3298, 0.4332],\n",
            "        [0.2904, 0.5781, 0.1315],\n",
            "        [0.2089, 0.5127, 0.2784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1586, 0.4893, 0.3521],\n",
            "        [0.3434, 0.3220, 0.3346],\n",
            "        [0.2763, 0.3883, 0.3354],\n",
            "        [0.3165, 0.3676, 0.3159],\n",
            "        [0.2079, 0.4635, 0.3286],\n",
            "        [0.2370, 0.3298, 0.4332],\n",
            "        [0.2904, 0.5781, 0.1315],\n",
            "        [0.2089, 0.5127, 0.2784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 1, 1, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 0, 2, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/63 [00:02<00:39,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2935, 0.4440, 0.2625],\n",
            "        [0.0727, 0.3888, 0.5386],\n",
            "        [0.1366, 0.3339, 0.5295],\n",
            "        [0.4089, 0.2566, 0.3345],\n",
            "        [0.3092, 0.3006, 0.3902],\n",
            "        [0.2730, 0.4370, 0.2899],\n",
            "        [0.2374, 0.2751, 0.4875],\n",
            "        [0.1855, 0.3467, 0.4678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2935, 0.4440, 0.2625],\n",
            "        [0.0727, 0.3888, 0.5386],\n",
            "        [0.1366, 0.3339, 0.5295],\n",
            "        [0.4089, 0.2566, 0.3345],\n",
            "        [0.3092, 0.3006, 0.3902],\n",
            "        [0.2730, 0.4370, 0.2899],\n",
            "        [0.2374, 0.2751, 0.4875],\n",
            "        [0.1855, 0.3467, 0.4678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 0, 2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 0, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/63 [00:03<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1558, 0.4145, 0.4297],\n",
            "        [0.1676, 0.6246, 0.2079],\n",
            "        [0.3158, 0.3493, 0.3349],\n",
            "        [0.2001, 0.2837, 0.5162],\n",
            "        [0.1825, 0.4925, 0.3251],\n",
            "        [0.3268, 0.3931, 0.2801],\n",
            "        [0.1764, 0.5720, 0.2516],\n",
            "        [0.2295, 0.1719, 0.5985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1558, 0.4145, 0.4297],\n",
            "        [0.1676, 0.6246, 0.2079],\n",
            "        [0.3158, 0.3493, 0.3349],\n",
            "        [0.2001, 0.2837, 0.5162],\n",
            "        [0.1825, 0.4925, 0.3251],\n",
            "        [0.3268, 0.3931, 0.2801],\n",
            "        [0.1764, 0.5720, 0.2516],\n",
            "        [0.2295, 0.1719, 0.5985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 2, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 0, 2, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 6/63 [00:04<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2851, 0.4074, 0.3075],\n",
            "        [0.1698, 0.5671, 0.2632],\n",
            "        [0.4137, 0.3168, 0.2696],\n",
            "        [0.1611, 0.3761, 0.4628],\n",
            "        [0.1094, 0.4138, 0.4768],\n",
            "        [0.2850, 0.4769, 0.2381],\n",
            "        [0.2922, 0.4135, 0.2943],\n",
            "        [0.1974, 0.4625, 0.3402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2851, 0.4074, 0.3075],\n",
            "        [0.1698, 0.5671, 0.2632],\n",
            "        [0.4137, 0.3168, 0.2696],\n",
            "        [0.1611, 0.3761, 0.4628],\n",
            "        [0.1094, 0.4138, 0.4768],\n",
            "        [0.2850, 0.4769, 0.2381],\n",
            "        [0.2922, 0.4135, 0.2943],\n",
            "        [0.1974, 0.4625, 0.3402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 2, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 0, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/63 [00:04<00:37,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1783, 0.5399, 0.2818],\n",
            "        [0.2414, 0.3066, 0.4520],\n",
            "        [0.2738, 0.3107, 0.4155],\n",
            "        [0.4191, 0.3766, 0.2042],\n",
            "        [0.3277, 0.3435, 0.3288],\n",
            "        [0.2028, 0.2762, 0.5210],\n",
            "        [0.3466, 0.2472, 0.4061],\n",
            "        [0.2050, 0.3411, 0.4539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1783, 0.5399, 0.2818],\n",
            "        [0.2414, 0.3066, 0.4520],\n",
            "        [0.2738, 0.3107, 0.4155],\n",
            "        [0.4191, 0.3766, 0.2042],\n",
            "        [0.3277, 0.3435, 0.3288],\n",
            "        [0.2028, 0.2762, 0.5210],\n",
            "        [0.3466, 0.2472, 0.4061],\n",
            "        [0.2050, 0.3411, 0.4539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 0, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 1, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/63 [00:05<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4247, 0.4496, 0.1257],\n",
            "        [0.4084, 0.3257, 0.2660],\n",
            "        [0.1273, 0.6413, 0.2314],\n",
            "        [0.2961, 0.3239, 0.3800],\n",
            "        [0.1253, 0.4092, 0.4654],\n",
            "        [0.3306, 0.3122, 0.3572],\n",
            "        [0.1319, 0.2917, 0.5764],\n",
            "        [0.1406, 0.5126, 0.3468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4247, 0.4496, 0.1257],\n",
            "        [0.4084, 0.3257, 0.2660],\n",
            "        [0.1273, 0.6413, 0.2314],\n",
            "        [0.2961, 0.3239, 0.3800],\n",
            "        [0.1253, 0.4092, 0.4654],\n",
            "        [0.3306, 0.3122, 0.3572],\n",
            "        [0.1319, 0.2917, 0.5764],\n",
            "        [0.1406, 0.5126, 0.3468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 2, 2, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 0, 1, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/63 [00:06<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2966, 0.4448, 0.2586],\n",
            "        [0.2690, 0.3331, 0.3979],\n",
            "        [0.1902, 0.3147, 0.4951],\n",
            "        [0.5621, 0.2353, 0.2026],\n",
            "        [0.5515, 0.2164, 0.2321],\n",
            "        [0.0887, 0.5276, 0.3837],\n",
            "        [0.3304, 0.3002, 0.3694],\n",
            "        [0.2917, 0.3465, 0.3618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2966, 0.4448, 0.2586],\n",
            "        [0.2690, 0.3331, 0.3979],\n",
            "        [0.1902, 0.3147, 0.4951],\n",
            "        [0.5621, 0.2353, 0.2026],\n",
            "        [0.5515, 0.2164, 0.2321],\n",
            "        [0.0887, 0.5276, 0.3837],\n",
            "        [0.3304, 0.3002, 0.3694],\n",
            "        [0.2917, 0.3465, 0.3618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 0, 0, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 1, 0, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/63 [00:06<00:35,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1110, 0.5341, 0.3549],\n",
            "        [0.1990, 0.6539, 0.1470],\n",
            "        [0.2829, 0.2539, 0.4633],\n",
            "        [0.1331, 0.2502, 0.6167],\n",
            "        [0.2021, 0.3148, 0.4831],\n",
            "        [0.3945, 0.4932, 0.1123],\n",
            "        [0.1627, 0.2597, 0.5775],\n",
            "        [0.1949, 0.2610, 0.5441]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1110, 0.5341, 0.3549],\n",
            "        [0.1990, 0.6539, 0.1470],\n",
            "        [0.2829, 0.2539, 0.4633],\n",
            "        [0.1331, 0.2502, 0.6167],\n",
            "        [0.2021, 0.3148, 0.4831],\n",
            "        [0.3945, 0.4932, 0.1123],\n",
            "        [0.1627, 0.2597, 0.5775],\n",
            "        [0.1949, 0.2610, 0.5441]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 2, 2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 0, 1, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/63 [00:07<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1431, 0.4225, 0.4344],\n",
            "        [0.0899, 0.2583, 0.6517],\n",
            "        [0.1249, 0.5266, 0.3485],\n",
            "        [0.1586, 0.4736, 0.3678],\n",
            "        [0.1515, 0.3047, 0.5438],\n",
            "        [0.1709, 0.4511, 0.3780],\n",
            "        [0.2403, 0.3703, 0.3894],\n",
            "        [0.7026, 0.1504, 0.1470]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1431, 0.4225, 0.4344],\n",
            "        [0.0899, 0.2583, 0.6517],\n",
            "        [0.1249, 0.5266, 0.3485],\n",
            "        [0.1586, 0.4736, 0.3678],\n",
            "        [0.1515, 0.3047, 0.5438],\n",
            "        [0.1709, 0.4511, 0.3780],\n",
            "        [0.2403, 0.3703, 0.3894],\n",
            "        [0.7026, 0.1504, 0.1470]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 2, 1, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/63 [00:08<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2148, 0.5094, 0.2758],\n",
            "        [0.2794, 0.3260, 0.3946],\n",
            "        [0.1479, 0.5873, 0.2648],\n",
            "        [0.1067, 0.3434, 0.5499],\n",
            "        [0.4411, 0.3181, 0.2407],\n",
            "        [0.3489, 0.3594, 0.2917],\n",
            "        [0.4395, 0.1767, 0.3838],\n",
            "        [0.3697, 0.4169, 0.2134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2148, 0.5094, 0.2758],\n",
            "        [0.2794, 0.3260, 0.3946],\n",
            "        [0.1479, 0.5873, 0.2648],\n",
            "        [0.1067, 0.3434, 0.5499],\n",
            "        [0.4411, 0.3181, 0.2407],\n",
            "        [0.3489, 0.3594, 0.2917],\n",
            "        [0.4395, 0.1767, 0.3838],\n",
            "        [0.3697, 0.4169, 0.2134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 1, 1, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 13/63 [00:08<00:33,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4481, 0.3870, 0.1650],\n",
            "        [0.2856, 0.5279, 0.1864],\n",
            "        [0.2220, 0.5803, 0.1977],\n",
            "        [0.2859, 0.4349, 0.2792],\n",
            "        [0.1606, 0.5847, 0.2547],\n",
            "        [0.2785, 0.5300, 0.1915],\n",
            "        [0.3466, 0.2193, 0.4341],\n",
            "        [0.1385, 0.5706, 0.2909]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4481, 0.3870, 0.1650],\n",
            "        [0.2856, 0.5279, 0.1864],\n",
            "        [0.2220, 0.5803, 0.1977],\n",
            "        [0.2859, 0.4349, 0.2792],\n",
            "        [0.1606, 0.5847, 0.2547],\n",
            "        [0.2785, 0.5300, 0.1915],\n",
            "        [0.3466, 0.2193, 0.4341],\n",
            "        [0.1385, 0.5706, 0.2909]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 1, 1, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 2, 1, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/63 [00:09<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2451, 0.6069, 0.1481],\n",
            "        [0.1940, 0.4893, 0.3167],\n",
            "        [0.1997, 0.2132, 0.5871],\n",
            "        [0.4577, 0.2715, 0.2708],\n",
            "        [0.3451, 0.3855, 0.2695],\n",
            "        [0.3629, 0.3354, 0.3017],\n",
            "        [0.5093, 0.3365, 0.1542],\n",
            "        [0.3451, 0.4408, 0.2141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2451, 0.6069, 0.1481],\n",
            "        [0.1940, 0.4893, 0.3167],\n",
            "        [0.1997, 0.2132, 0.5871],\n",
            "        [0.4577, 0.2715, 0.2708],\n",
            "        [0.3451, 0.3855, 0.2695],\n",
            "        [0.3629, 0.3354, 0.3017],\n",
            "        [0.5093, 0.3365, 0.1542],\n",
            "        [0.3451, 0.4408, 0.2141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 0, 1, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 1, 2, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 15/63 [00:10<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2111, 0.6036, 0.1853],\n",
            "        [0.3061, 0.4024, 0.2915],\n",
            "        [0.2009, 0.4606, 0.3386],\n",
            "        [0.3790, 0.4875, 0.1335],\n",
            "        [0.0506, 0.5663, 0.3831],\n",
            "        [0.1592, 0.6521, 0.1887],\n",
            "        [0.2801, 0.5204, 0.1995],\n",
            "        [0.4547, 0.3523, 0.1929]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2111, 0.6036, 0.1853],\n",
            "        [0.3061, 0.4024, 0.2915],\n",
            "        [0.2009, 0.4606, 0.3386],\n",
            "        [0.3790, 0.4875, 0.1335],\n",
            "        [0.0506, 0.5663, 0.3831],\n",
            "        [0.1592, 0.6521, 0.1887],\n",
            "        [0.2801, 0.5204, 0.1995],\n",
            "        [0.4547, 0.3523, 0.1929]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 1, 2, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/63 [00:10<00:31,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3463, 0.4141, 0.2397],\n",
            "        [0.2386, 0.2819, 0.4796],\n",
            "        [0.1248, 0.4219, 0.4533],\n",
            "        [0.1086, 0.6264, 0.2650],\n",
            "        [0.2225, 0.3898, 0.3877],\n",
            "        [0.2374, 0.2408, 0.5218],\n",
            "        [0.2566, 0.1268, 0.6167],\n",
            "        [0.1648, 0.4284, 0.4068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3463, 0.4141, 0.2397],\n",
            "        [0.2386, 0.2819, 0.4796],\n",
            "        [0.1248, 0.4219, 0.4533],\n",
            "        [0.1086, 0.6264, 0.2650],\n",
            "        [0.2225, 0.3898, 0.3877],\n",
            "        [0.2374, 0.2408, 0.5218],\n",
            "        [0.2566, 0.1268, 0.6167],\n",
            "        [0.1648, 0.4284, 0.4068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 1, 1, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 0, 1, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/63 [00:11<00:31,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3253, 0.3104, 0.3643],\n",
            "        [0.2435, 0.4731, 0.2834],\n",
            "        [0.1467, 0.2889, 0.5645],\n",
            "        [0.2468, 0.1858, 0.5674],\n",
            "        [0.1911, 0.3974, 0.4115],\n",
            "        [0.3242, 0.3650, 0.3108],\n",
            "        [0.1538, 0.4038, 0.4424],\n",
            "        [0.5442, 0.2765, 0.1794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3253, 0.3104, 0.3643],\n",
            "        [0.2435, 0.4731, 0.2834],\n",
            "        [0.1467, 0.2889, 0.5645],\n",
            "        [0.2468, 0.1858, 0.5674],\n",
            "        [0.1911, 0.3974, 0.4115],\n",
            "        [0.3242, 0.3650, 0.3108],\n",
            "        [0.1538, 0.4038, 0.4424],\n",
            "        [0.5442, 0.2765, 0.1794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 2, 2, 1, 2, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 2, 1, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 18/63 [00:12<00:30,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2558, 0.2713, 0.4728],\n",
            "        [0.2174, 0.2876, 0.4950],\n",
            "        [0.1975, 0.2885, 0.5140],\n",
            "        [0.2650, 0.3220, 0.4130],\n",
            "        [0.4190, 0.4139, 0.1671],\n",
            "        [0.3442, 0.2568, 0.3989],\n",
            "        [0.0783, 0.5468, 0.3750],\n",
            "        [0.2851, 0.4599, 0.2550]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2558, 0.2713, 0.4728],\n",
            "        [0.2174, 0.2876, 0.4950],\n",
            "        [0.1975, 0.2885, 0.5140],\n",
            "        [0.2650, 0.3220, 0.4130],\n",
            "        [0.4190, 0.4139, 0.1671],\n",
            "        [0.3442, 0.2568, 0.3989],\n",
            "        [0.0783, 0.5468, 0.3750],\n",
            "        [0.2851, 0.4599, 0.2550]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 0, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 1, 1, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 19/63 [00:12<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2801, 0.4390, 0.2809],\n",
            "        [0.1876, 0.3692, 0.4432],\n",
            "        [0.4022, 0.4097, 0.1882],\n",
            "        [0.2151, 0.4425, 0.3424],\n",
            "        [0.2752, 0.5712, 0.1537],\n",
            "        [0.1290, 0.5550, 0.3160],\n",
            "        [0.2164, 0.5452, 0.2383],\n",
            "        [0.2554, 0.2934, 0.4512]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2801, 0.4390, 0.2809],\n",
            "        [0.1876, 0.3692, 0.4432],\n",
            "        [0.4022, 0.4097, 0.1882],\n",
            "        [0.2151, 0.4425, 0.3424],\n",
            "        [0.2752, 0.5712, 0.1537],\n",
            "        [0.1290, 0.5550, 0.3160],\n",
            "        [0.2164, 0.5452, 0.2383],\n",
            "        [0.2554, 0.2934, 0.4512]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 2, 0, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 20/63 [00:13<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2585, 0.3919, 0.3496],\n",
            "        [0.1505, 0.5320, 0.3176],\n",
            "        [0.1824, 0.2813, 0.5363],\n",
            "        [0.1773, 0.5007, 0.3220],\n",
            "        [0.3208, 0.5799, 0.0993],\n",
            "        [0.1972, 0.3323, 0.4705],\n",
            "        [0.1792, 0.6038, 0.2169],\n",
            "        [0.3127, 0.4243, 0.2630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2585, 0.3919, 0.3496],\n",
            "        [0.1505, 0.5320, 0.3176],\n",
            "        [0.1824, 0.2813, 0.5363],\n",
            "        [0.1773, 0.5007, 0.3220],\n",
            "        [0.3208, 0.5799, 0.0993],\n",
            "        [0.1972, 0.3323, 0.4705],\n",
            "        [0.1792, 0.6038, 0.2169],\n",
            "        [0.3127, 0.4243, 0.2630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 1, 1, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/63 [00:14<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2877, 0.1576, 0.5547],\n",
            "        [0.1690, 0.3692, 0.4618],\n",
            "        [0.3264, 0.3082, 0.3654],\n",
            "        [0.3786, 0.2235, 0.3979],\n",
            "        [0.1806, 0.5861, 0.2333],\n",
            "        [0.2368, 0.5214, 0.2418],\n",
            "        [0.2251, 0.6106, 0.1643],\n",
            "        [0.1309, 0.5657, 0.3034]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2877, 0.1576, 0.5547],\n",
            "        [0.1690, 0.3692, 0.4618],\n",
            "        [0.3264, 0.3082, 0.3654],\n",
            "        [0.3786, 0.2235, 0.3979],\n",
            "        [0.1806, 0.5861, 0.2333],\n",
            "        [0.2368, 0.5214, 0.2418],\n",
            "        [0.2251, 0.6106, 0.1643],\n",
            "        [0.1309, 0.5657, 0.3034]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 1, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 22/63 [00:14<00:27,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0936, 0.5161, 0.3903],\n",
            "        [0.1095, 0.4087, 0.4818],\n",
            "        [0.1099, 0.3707, 0.5194],\n",
            "        [0.4637, 0.3901, 0.1462],\n",
            "        [0.2029, 0.1739, 0.6232],\n",
            "        [0.2546, 0.5229, 0.2225],\n",
            "        [0.1572, 0.6786, 0.1642],\n",
            "        [0.2215, 0.5403, 0.2382]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0936, 0.5161, 0.3903],\n",
            "        [0.1095, 0.4087, 0.4818],\n",
            "        [0.1099, 0.3707, 0.5194],\n",
            "        [0.4637, 0.3901, 0.1462],\n",
            "        [0.2029, 0.1739, 0.6232],\n",
            "        [0.2546, 0.5229, 0.2225],\n",
            "        [0.1572, 0.6786, 0.1642],\n",
            "        [0.2215, 0.5403, 0.2382]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 0, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 1, 1, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 23/63 [00:15<00:27,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3301, 0.1531, 0.5168],\n",
            "        [0.1710, 0.3720, 0.4571],\n",
            "        [0.1195, 0.7550, 0.1255],\n",
            "        [0.1789, 0.2286, 0.5925],\n",
            "        [0.3581, 0.3896, 0.2523],\n",
            "        [0.0567, 0.5316, 0.4117],\n",
            "        [0.0907, 0.3382, 0.5711],\n",
            "        [0.2090, 0.4056, 0.3854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3301, 0.1531, 0.5168],\n",
            "        [0.1710, 0.3720, 0.4571],\n",
            "        [0.1195, 0.7550, 0.1255],\n",
            "        [0.1789, 0.2286, 0.5925],\n",
            "        [0.3581, 0.3896, 0.2523],\n",
            "        [0.0567, 0.5316, 0.4117],\n",
            "        [0.0907, 0.3382, 0.5711],\n",
            "        [0.2090, 0.4056, 0.3854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 2, 1, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 2, 2, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/63 [00:16<00:26,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3056, 0.3550, 0.3394],\n",
            "        [0.4642, 0.2636, 0.2722],\n",
            "        [0.2137, 0.4531, 0.3332],\n",
            "        [0.3341, 0.2624, 0.4035],\n",
            "        [0.2117, 0.4854, 0.3029],\n",
            "        [0.1490, 0.6703, 0.1807],\n",
            "        [0.4947, 0.2721, 0.2332],\n",
            "        [0.1136, 0.1576, 0.7288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3056, 0.3550, 0.3394],\n",
            "        [0.4642, 0.2636, 0.2722],\n",
            "        [0.2137, 0.4531, 0.3332],\n",
            "        [0.3341, 0.2624, 0.4035],\n",
            "        [0.2117, 0.4854, 0.3029],\n",
            "        [0.1490, 0.6703, 0.1807],\n",
            "        [0.4947, 0.2721, 0.2332],\n",
            "        [0.1136, 0.1576, 0.7288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 2, 1, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 0, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 25/63 [00:16<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2403, 0.3819, 0.3778],\n",
            "        [0.4285, 0.3399, 0.2316],\n",
            "        [0.4592, 0.2380, 0.3028],\n",
            "        [0.2937, 0.5988, 0.1075],\n",
            "        [0.4475, 0.2243, 0.3282],\n",
            "        [0.1288, 0.6170, 0.2542],\n",
            "        [0.0986, 0.4841, 0.4173],\n",
            "        [0.1744, 0.2643, 0.5613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2403, 0.3819, 0.3778],\n",
            "        [0.4285, 0.3399, 0.2316],\n",
            "        [0.4592, 0.2380, 0.3028],\n",
            "        [0.2937, 0.5988, 0.1075],\n",
            "        [0.4475, 0.2243, 0.3282],\n",
            "        [0.1288, 0.6170, 0.2542],\n",
            "        [0.0986, 0.4841, 0.4173],\n",
            "        [0.1744, 0.2643, 0.5613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 1, 0, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 2, 1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 26/63 [00:17<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1273, 0.5300, 0.3427],\n",
            "        [0.3475, 0.4090, 0.2436],\n",
            "        [0.2271, 0.6234, 0.1495],\n",
            "        [0.0947, 0.2261, 0.6791],\n",
            "        [0.4334, 0.2995, 0.2670],\n",
            "        [0.1401, 0.3612, 0.4987],\n",
            "        [0.1150, 0.3191, 0.5659],\n",
            "        [0.1244, 0.3092, 0.5665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1273, 0.5300, 0.3427],\n",
            "        [0.3475, 0.4090, 0.2436],\n",
            "        [0.2271, 0.6234, 0.1495],\n",
            "        [0.0947, 0.2261, 0.6791],\n",
            "        [0.4334, 0.2995, 0.2670],\n",
            "        [0.1401, 0.3612, 0.4987],\n",
            "        [0.1150, 0.3191, 0.5659],\n",
            "        [0.1244, 0.3092, 0.5665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 0, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 1, 0, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 27/63 [00:18<00:24,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1337, 0.6141, 0.2522],\n",
            "        [0.1898, 0.4279, 0.3823],\n",
            "        [0.2797, 0.3907, 0.3295],\n",
            "        [0.2234, 0.3856, 0.3911],\n",
            "        [0.1952, 0.1761, 0.6288],\n",
            "        [0.3207, 0.2911, 0.3882],\n",
            "        [0.2741, 0.4561, 0.2697],\n",
            "        [0.2147, 0.3268, 0.4586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1337, 0.6141, 0.2522],\n",
            "        [0.1898, 0.4279, 0.3823],\n",
            "        [0.2797, 0.3907, 0.3295],\n",
            "        [0.2234, 0.3856, 0.3911],\n",
            "        [0.1952, 0.1761, 0.6288],\n",
            "        [0.3207, 0.2911, 0.3882],\n",
            "        [0.2741, 0.4561, 0.2697],\n",
            "        [0.2147, 0.3268, 0.4586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 1, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/63 [00:18<00:23,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4378, 0.4057, 0.1565],\n",
            "        [0.3975, 0.3200, 0.2825],\n",
            "        [0.1530, 0.1775, 0.6696],\n",
            "        [0.1660, 0.3549, 0.4791],\n",
            "        [0.0996, 0.3537, 0.5466],\n",
            "        [0.1482, 0.3995, 0.4523],\n",
            "        [0.3034, 0.3507, 0.3459],\n",
            "        [0.3251, 0.3590, 0.3159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4378, 0.4057, 0.1565],\n",
            "        [0.3975, 0.3200, 0.2825],\n",
            "        [0.1530, 0.1775, 0.6696],\n",
            "        [0.1660, 0.3549, 0.4791],\n",
            "        [0.0996, 0.3537, 0.5466],\n",
            "        [0.1482, 0.3995, 0.4523],\n",
            "        [0.3034, 0.3507, 0.3459],\n",
            "        [0.3251, 0.3590, 0.3159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 2, 2, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 2, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 29/63 [00:19<00:23,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3303, 0.3777, 0.2920],\n",
            "        [0.1620, 0.1765, 0.6615],\n",
            "        [0.2512, 0.4919, 0.2570],\n",
            "        [0.2507, 0.3564, 0.3929],\n",
            "        [0.1364, 0.3153, 0.5483],\n",
            "        [0.3686, 0.3982, 0.2331],\n",
            "        [0.1645, 0.2774, 0.5581],\n",
            "        [0.1848, 0.3452, 0.4699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3303, 0.3777, 0.2920],\n",
            "        [0.1620, 0.1765, 0.6615],\n",
            "        [0.2512, 0.4919, 0.2570],\n",
            "        [0.2507, 0.3564, 0.3929],\n",
            "        [0.1364, 0.3153, 0.5483],\n",
            "        [0.3686, 0.3982, 0.2331],\n",
            "        [0.1645, 0.2774, 0.5581],\n",
            "        [0.1848, 0.3452, 0.4699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 1, 1, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 30/63 [00:20<00:22,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2319, 0.4858, 0.2823],\n",
            "        [0.3550, 0.2069, 0.4381],\n",
            "        [0.2594, 0.3790, 0.3616],\n",
            "        [0.3005, 0.3979, 0.3016],\n",
            "        [0.0832, 0.5563, 0.3605],\n",
            "        [0.1389, 0.6086, 0.2525],\n",
            "        [0.2789, 0.2776, 0.4435],\n",
            "        [0.2147, 0.4700, 0.3154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2319, 0.4858, 0.2823],\n",
            "        [0.3550, 0.2069, 0.4381],\n",
            "        [0.2594, 0.3790, 0.3616],\n",
            "        [0.3005, 0.3979, 0.3016],\n",
            "        [0.0832, 0.5563, 0.3605],\n",
            "        [0.1389, 0.6086, 0.2525],\n",
            "        [0.2789, 0.2776, 0.4435],\n",
            "        [0.2147, 0.4700, 0.3154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 1, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 2, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 31/63 [00:20<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1411, 0.4291, 0.4298],\n",
            "        [0.1572, 0.5308, 0.3121],\n",
            "        [0.2251, 0.3926, 0.3823],\n",
            "        [0.3130, 0.4298, 0.2571],\n",
            "        [0.3290, 0.3413, 0.3297],\n",
            "        [0.2941, 0.3503, 0.3556],\n",
            "        [0.4591, 0.4247, 0.1162],\n",
            "        [0.1127, 0.2468, 0.6404]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1411, 0.4291, 0.4298],\n",
            "        [0.1572, 0.5308, 0.3121],\n",
            "        [0.2251, 0.3926, 0.3823],\n",
            "        [0.3130, 0.4298, 0.2571],\n",
            "        [0.3290, 0.3413, 0.3297],\n",
            "        [0.2941, 0.3503, 0.3556],\n",
            "        [0.4591, 0.4247, 0.1162],\n",
            "        [0.1127, 0.2468, 0.6404]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 1, 1, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 2, 2, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 32/63 [00:21<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2374, 0.5745, 0.1882],\n",
            "        [0.2496, 0.3816, 0.3688],\n",
            "        [0.2598, 0.4185, 0.3217],\n",
            "        [0.1611, 0.3106, 0.5283],\n",
            "        [0.1256, 0.2087, 0.6657],\n",
            "        [0.4932, 0.3009, 0.2059],\n",
            "        [0.2894, 0.4551, 0.2556],\n",
            "        [0.4460, 0.4060, 0.1479]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2374, 0.5745, 0.1882],\n",
            "        [0.2496, 0.3816, 0.3688],\n",
            "        [0.2598, 0.4185, 0.3217],\n",
            "        [0.1611, 0.3106, 0.5283],\n",
            "        [0.1256, 0.2087, 0.6657],\n",
            "        [0.4932, 0.3009, 0.2059],\n",
            "        [0.2894, 0.4551, 0.2556],\n",
            "        [0.4460, 0.4060, 0.1479]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 2, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 1, 2, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/63 [00:22<00:20,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3700, 0.2274, 0.4026],\n",
            "        [0.2228, 0.2556, 0.5216],\n",
            "        [0.3322, 0.2366, 0.4312],\n",
            "        [0.2560, 0.2982, 0.4459],\n",
            "        [0.1418, 0.1604, 0.6978],\n",
            "        [0.5294, 0.2357, 0.2349],\n",
            "        [0.1399, 0.5736, 0.2865],\n",
            "        [0.3218, 0.5220, 0.1561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3700, 0.2274, 0.4026],\n",
            "        [0.2228, 0.2556, 0.5216],\n",
            "        [0.3322, 0.2366, 0.4312],\n",
            "        [0.2560, 0.2982, 0.4459],\n",
            "        [0.1418, 0.1604, 0.6978],\n",
            "        [0.5294, 0.2357, 0.2349],\n",
            "        [0.1399, 0.5736, 0.2865],\n",
            "        [0.3218, 0.5220, 0.1561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 2, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 0, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 34/63 [00:23<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0955, 0.7705, 0.1340],\n",
            "        [0.2458, 0.5042, 0.2500],\n",
            "        [0.0859, 0.5739, 0.3402],\n",
            "        [0.1070, 0.2065, 0.6865],\n",
            "        [0.1223, 0.3145, 0.5632],\n",
            "        [0.1569, 0.6834, 0.1598],\n",
            "        [0.1564, 0.3025, 0.5411],\n",
            "        [0.2543, 0.3639, 0.3818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0955, 0.7705, 0.1340],\n",
            "        [0.2458, 0.5042, 0.2500],\n",
            "        [0.0859, 0.5739, 0.3402],\n",
            "        [0.1070, 0.2065, 0.6865],\n",
            "        [0.1223, 0.3145, 0.5632],\n",
            "        [0.1569, 0.6834, 0.1598],\n",
            "        [0.1564, 0.3025, 0.5411],\n",
            "        [0.2543, 0.3639, 0.3818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 0, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 35/63 [00:23<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0478, 0.6624, 0.2898],\n",
            "        [0.1615, 0.4173, 0.4212],\n",
            "        [0.2658, 0.4091, 0.3251],\n",
            "        [0.3624, 0.1327, 0.5050],\n",
            "        [0.1621, 0.4192, 0.4187],\n",
            "        [0.4158, 0.3403, 0.2439],\n",
            "        [0.2607, 0.3448, 0.3945],\n",
            "        [0.2602, 0.3993, 0.3405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0478, 0.6624, 0.2898],\n",
            "        [0.1615, 0.4173, 0.4212],\n",
            "        [0.2658, 0.4091, 0.3251],\n",
            "        [0.3624, 0.1327, 0.5050],\n",
            "        [0.1621, 0.4192, 0.4187],\n",
            "        [0.4158, 0.3403, 0.2439],\n",
            "        [0.2607, 0.3448, 0.3945],\n",
            "        [0.2602, 0.3993, 0.3405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 1, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 0, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 36/63 [00:24<00:18,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1580, 0.2883, 0.5537],\n",
            "        [0.1185, 0.7142, 0.1673],\n",
            "        [0.1302, 0.6337, 0.2361],\n",
            "        [0.1386, 0.3973, 0.4641],\n",
            "        [0.0961, 0.7241, 0.1798],\n",
            "        [0.0718, 0.7398, 0.1884],\n",
            "        [0.1608, 0.5678, 0.2714],\n",
            "        [0.3932, 0.0977, 0.5091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1580, 0.2883, 0.5537],\n",
            "        [0.1185, 0.7142, 0.1673],\n",
            "        [0.1302, 0.6337, 0.2361],\n",
            "        [0.1386, 0.3973, 0.4641],\n",
            "        [0.0961, 0.7241, 0.1798],\n",
            "        [0.0718, 0.7398, 0.1884],\n",
            "        [0.1608, 0.5678, 0.2714],\n",
            "        [0.3932, 0.0977, 0.5091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 2, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 2, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 37/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2885, 0.5289, 0.1826],\n",
            "        [0.2020, 0.2169, 0.5811],\n",
            "        [0.3974, 0.3581, 0.2445],\n",
            "        [0.5573, 0.2177, 0.2250],\n",
            "        [0.0763, 0.7836, 0.1402],\n",
            "        [0.2889, 0.2933, 0.4178],\n",
            "        [0.3370, 0.4879, 0.1751],\n",
            "        [0.2896, 0.3233, 0.3871]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2885, 0.5289, 0.1826],\n",
            "        [0.2020, 0.2169, 0.5811],\n",
            "        [0.3974, 0.3581, 0.2445],\n",
            "        [0.5573, 0.2177, 0.2250],\n",
            "        [0.0763, 0.7836, 0.1402],\n",
            "        [0.2889, 0.2933, 0.4178],\n",
            "        [0.3370, 0.4879, 0.1751],\n",
            "        [0.2896, 0.3233, 0.3871]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 0, 0, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 38/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2909, 0.5725, 0.1366],\n",
            "        [0.2906, 0.1921, 0.5172],\n",
            "        [0.1566, 0.5977, 0.2457],\n",
            "        [0.4690, 0.1566, 0.3744],\n",
            "        [0.2193, 0.5900, 0.1907],\n",
            "        [0.4243, 0.2341, 0.3417],\n",
            "        [0.2190, 0.2384, 0.5426],\n",
            "        [0.1427, 0.6544, 0.2029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2909, 0.5725, 0.1366],\n",
            "        [0.2906, 0.1921, 0.5172],\n",
            "        [0.1566, 0.5977, 0.2457],\n",
            "        [0.4690, 0.1566, 0.3744],\n",
            "        [0.2193, 0.5900, 0.1907],\n",
            "        [0.4243, 0.2341, 0.3417],\n",
            "        [0.2190, 0.2384, 0.5426],\n",
            "        [0.1427, 0.6544, 0.2029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 0, 1, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 39/63 [00:26<00:16,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2473, 0.3010, 0.4517],\n",
            "        [0.3202, 0.1803, 0.4995],\n",
            "        [0.2524, 0.4163, 0.3313],\n",
            "        [0.3619, 0.4688, 0.1693],\n",
            "        [0.3397, 0.3788, 0.2815],\n",
            "        [0.0903, 0.1366, 0.7731],\n",
            "        [0.1637, 0.3953, 0.4410],\n",
            "        [0.2656, 0.3032, 0.4312]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2473, 0.3010, 0.4517],\n",
            "        [0.3202, 0.1803, 0.4995],\n",
            "        [0.2524, 0.4163, 0.3313],\n",
            "        [0.3619, 0.4688, 0.1693],\n",
            "        [0.3397, 0.3788, 0.2815],\n",
            "        [0.0903, 0.1366, 0.7731],\n",
            "        [0.1637, 0.3953, 0.4410],\n",
            "        [0.2656, 0.3032, 0.4312]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 0, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 40/63 [00:27<00:15,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1494, 0.5060, 0.3446],\n",
            "        [0.1901, 0.4087, 0.4012],\n",
            "        [0.2825, 0.4427, 0.2748],\n",
            "        [0.3082, 0.2041, 0.4877],\n",
            "        [0.4204, 0.2305, 0.3491],\n",
            "        [0.2038, 0.5267, 0.2694],\n",
            "        [0.4357, 0.2196, 0.3447],\n",
            "        [0.6194, 0.1469, 0.2337]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1494, 0.5060, 0.3446],\n",
            "        [0.1901, 0.4087, 0.4012],\n",
            "        [0.2825, 0.4427, 0.2748],\n",
            "        [0.3082, 0.2041, 0.4877],\n",
            "        [0.4204, 0.2305, 0.3491],\n",
            "        [0.2038, 0.5267, 0.2694],\n",
            "        [0.4357, 0.2196, 0.3447],\n",
            "        [0.6194, 0.1469, 0.2337]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 0, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 41/63 [00:27<00:15,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1460, 0.2656, 0.5884],\n",
            "        [0.4051, 0.2660, 0.3289],\n",
            "        [0.1416, 0.4329, 0.4255],\n",
            "        [0.1112, 0.1421, 0.7467],\n",
            "        [0.3019, 0.4372, 0.2608],\n",
            "        [0.3640, 0.2246, 0.4114],\n",
            "        [0.2049, 0.1705, 0.6245],\n",
            "        [0.4716, 0.2668, 0.2616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1460, 0.2656, 0.5884],\n",
            "        [0.4051, 0.2660, 0.3289],\n",
            "        [0.1416, 0.4329, 0.4255],\n",
            "        [0.1112, 0.1421, 0.7467],\n",
            "        [0.3019, 0.4372, 0.2608],\n",
            "        [0.3640, 0.2246, 0.4114],\n",
            "        [0.2049, 0.1705, 0.6245],\n",
            "        [0.4716, 0.2668, 0.2616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 2, 1, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 1, 2, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 42/63 [00:28<00:14,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4420, 0.2139, 0.3441],\n",
            "        [0.2360, 0.4967, 0.2673],\n",
            "        [0.3201, 0.3048, 0.3751],\n",
            "        [0.2026, 0.6433, 0.1541],\n",
            "        [0.2201, 0.3668, 0.4131],\n",
            "        [0.1434, 0.6894, 0.1672],\n",
            "        [0.1562, 0.6954, 0.1484],\n",
            "        [0.3165, 0.4395, 0.2440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4420, 0.2139, 0.3441],\n",
            "        [0.2360, 0.4967, 0.2673],\n",
            "        [0.3201, 0.3048, 0.3751],\n",
            "        [0.2026, 0.6433, 0.1541],\n",
            "        [0.2201, 0.3668, 0.4131],\n",
            "        [0.1434, 0.6894, 0.1672],\n",
            "        [0.1562, 0.6954, 0.1484],\n",
            "        [0.3165, 0.4395, 0.2440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 1, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 2, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 43/63 [00:29<00:13,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1285, 0.4499, 0.4216],\n",
            "        [0.2003, 0.4496, 0.3500],\n",
            "        [0.3924, 0.4028, 0.2048],\n",
            "        [0.0884, 0.4025, 0.5091],\n",
            "        [0.0834, 0.4674, 0.4492],\n",
            "        [0.2222, 0.5086, 0.2692],\n",
            "        [0.1760, 0.4493, 0.3748],\n",
            "        [0.4812, 0.2320, 0.2869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1285, 0.4499, 0.4216],\n",
            "        [0.2003, 0.4496, 0.3500],\n",
            "        [0.3924, 0.4028, 0.2048],\n",
            "        [0.0884, 0.4025, 0.5091],\n",
            "        [0.0834, 0.4674, 0.4492],\n",
            "        [0.2222, 0.5086, 0.2692],\n",
            "        [0.1760, 0.4493, 0.3748],\n",
            "        [0.4812, 0.2320, 0.2869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 1, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 0, 1, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 44/63 [00:29<00:13,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4810, 0.3552, 0.1639],\n",
            "        [0.5178, 0.1986, 0.2837],\n",
            "        [0.5760, 0.2595, 0.1645],\n",
            "        [0.1869, 0.6284, 0.1847],\n",
            "        [0.2068, 0.5223, 0.2709],\n",
            "        [0.2860, 0.3293, 0.3847],\n",
            "        [0.2377, 0.5333, 0.2289],\n",
            "        [0.3597, 0.2982, 0.3421]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4810, 0.3552, 0.1639],\n",
            "        [0.5178, 0.1986, 0.2837],\n",
            "        [0.5760, 0.2595, 0.1645],\n",
            "        [0.1869, 0.6284, 0.1847],\n",
            "        [0.2068, 0.5223, 0.2709],\n",
            "        [0.2860, 0.3293, 0.3847],\n",
            "        [0.2377, 0.5333, 0.2289],\n",
            "        [0.3597, 0.2982, 0.3421]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 1, 1, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 2, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 45/63 [00:30<00:12,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1606, 0.6783, 0.1611],\n",
            "        [0.3457, 0.2441, 0.4102],\n",
            "        [0.2094, 0.3630, 0.4276],\n",
            "        [0.3442, 0.3298, 0.3261],\n",
            "        [0.3874, 0.3784, 0.2343],\n",
            "        [0.3065, 0.2482, 0.4453],\n",
            "        [0.2595, 0.3118, 0.4287],\n",
            "        [0.2792, 0.3788, 0.3419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1606, 0.6783, 0.1611],\n",
            "        [0.3457, 0.2441, 0.4102],\n",
            "        [0.2094, 0.3630, 0.4276],\n",
            "        [0.3442, 0.3298, 0.3261],\n",
            "        [0.3874, 0.3784, 0.2343],\n",
            "        [0.3065, 0.2482, 0.4453],\n",
            "        [0.2595, 0.3118, 0.4287],\n",
            "        [0.2792, 0.3788, 0.3419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 0, 0, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 0, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 46/63 [00:31<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1973, 0.5049, 0.2977],\n",
            "        [0.2290, 0.4454, 0.3255],\n",
            "        [0.2514, 0.3846, 0.3641],\n",
            "        [0.4980, 0.2314, 0.2706],\n",
            "        [0.4074, 0.3307, 0.2619],\n",
            "        [0.3366, 0.4693, 0.1941],\n",
            "        [0.2528, 0.4555, 0.2916],\n",
            "        [0.3822, 0.2709, 0.3469]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1973, 0.5049, 0.2977],\n",
            "        [0.2290, 0.4454, 0.3255],\n",
            "        [0.2514, 0.3846, 0.3641],\n",
            "        [0.4980, 0.2314, 0.2706],\n",
            "        [0.4074, 0.3307, 0.2619],\n",
            "        [0.3366, 0.4693, 0.1941],\n",
            "        [0.2528, 0.4555, 0.2916],\n",
            "        [0.3822, 0.2709, 0.3469]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 0, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 47/63 [00:32<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3313, 0.5209, 0.1477],\n",
            "        [0.2025, 0.5495, 0.2480],\n",
            "        [0.1373, 0.5543, 0.3084],\n",
            "        [0.1402, 0.4424, 0.4174],\n",
            "        [0.1343, 0.5684, 0.2973],\n",
            "        [0.1049, 0.5583, 0.3368],\n",
            "        [0.4367, 0.3626, 0.2008],\n",
            "        [0.2152, 0.3693, 0.4155]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3313, 0.5209, 0.1477],\n",
            "        [0.2025, 0.5495, 0.2480],\n",
            "        [0.1373, 0.5543, 0.3084],\n",
            "        [0.1402, 0.4424, 0.4174],\n",
            "        [0.1343, 0.5684, 0.2973],\n",
            "        [0.1049, 0.5583, 0.3368],\n",
            "        [0.4367, 0.3626, 0.2008],\n",
            "        [0.2152, 0.3693, 0.4155]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 1, 1, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 0, 0, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 48/63 [00:32<00:10,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2038, 0.4315, 0.3647],\n",
            "        [0.1296, 0.5578, 0.3126],\n",
            "        [0.1937, 0.5470, 0.2593],\n",
            "        [0.3722, 0.2687, 0.3592],\n",
            "        [0.5328, 0.1994, 0.2678],\n",
            "        [0.1869, 0.2712, 0.5419],\n",
            "        [0.2858, 0.3466, 0.3676],\n",
            "        [0.2633, 0.6301, 0.1065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2038, 0.4315, 0.3647],\n",
            "        [0.1296, 0.5578, 0.3126],\n",
            "        [0.1937, 0.5470, 0.2593],\n",
            "        [0.3722, 0.2687, 0.3592],\n",
            "        [0.5328, 0.1994, 0.2678],\n",
            "        [0.1869, 0.2712, 0.5419],\n",
            "        [0.2858, 0.3466, 0.3676],\n",
            "        [0.2633, 0.6301, 0.1065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 0, 0, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 0, 1, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 49/63 [00:33<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2005, 0.3413, 0.4582],\n",
            "        [0.2292, 0.5318, 0.2389],\n",
            "        [0.1722, 0.2227, 0.6051],\n",
            "        [0.4446, 0.3302, 0.2252],\n",
            "        [0.1214, 0.1888, 0.6898],\n",
            "        [0.1725, 0.4319, 0.3956],\n",
            "        [0.1733, 0.4288, 0.3979],\n",
            "        [0.2631, 0.2845, 0.4525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2005, 0.3413, 0.4582],\n",
            "        [0.2292, 0.5318, 0.2389],\n",
            "        [0.1722, 0.2227, 0.6051],\n",
            "        [0.4446, 0.3302, 0.2252],\n",
            "        [0.1214, 0.1888, 0.6898],\n",
            "        [0.1725, 0.4319, 0.3956],\n",
            "        [0.1733, 0.4288, 0.3979],\n",
            "        [0.2631, 0.2845, 0.4525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 0, 2, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 0, 2, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 50/63 [00:34<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3880, 0.3907, 0.2213],\n",
            "        [0.2578, 0.6119, 0.1303],\n",
            "        [0.4507, 0.3484, 0.2009],\n",
            "        [0.3079, 0.3293, 0.3628],\n",
            "        [0.1015, 0.2023, 0.6962],\n",
            "        [0.1996, 0.2432, 0.5571],\n",
            "        [0.2334, 0.4235, 0.3430],\n",
            "        [0.2618, 0.2774, 0.4608]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3880, 0.3907, 0.2213],\n",
            "        [0.2578, 0.6119, 0.1303],\n",
            "        [0.4507, 0.3484, 0.2009],\n",
            "        [0.3079, 0.3293, 0.3628],\n",
            "        [0.1015, 0.2023, 0.6962],\n",
            "        [0.1996, 0.2432, 0.5571],\n",
            "        [0.2334, 0.4235, 0.3430],\n",
            "        [0.2618, 0.2774, 0.4608]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 0, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 51/63 [00:34<00:08,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3421, 0.3797, 0.2781],\n",
            "        [0.2587, 0.3186, 0.4227],\n",
            "        [0.1927, 0.2501, 0.5572],\n",
            "        [0.1189, 0.5805, 0.3005],\n",
            "        [0.2881, 0.2471, 0.4648],\n",
            "        [0.4731, 0.3400, 0.1869],\n",
            "        [0.3229, 0.3805, 0.2966],\n",
            "        [0.3467, 0.2945, 0.3589]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3421, 0.3797, 0.2781],\n",
            "        [0.2587, 0.3186, 0.4227],\n",
            "        [0.1927, 0.2501, 0.5572],\n",
            "        [0.1189, 0.5805, 0.3005],\n",
            "        [0.2881, 0.2471, 0.4648],\n",
            "        [0.4731, 0.3400, 0.1869],\n",
            "        [0.3229, 0.3805, 0.2966],\n",
            "        [0.3467, 0.2945, 0.3589]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 1, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 2, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 52/63 [00:35<00:07,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4079, 0.2829, 0.3092],\n",
            "        [0.2850, 0.3564, 0.3586],\n",
            "        [0.2749, 0.2216, 0.5035],\n",
            "        [0.2866, 0.4106, 0.3028],\n",
            "        [0.3054, 0.4217, 0.2728],\n",
            "        [0.2262, 0.4606, 0.3131],\n",
            "        [0.3595, 0.3192, 0.3213],\n",
            "        [0.2362, 0.3089, 0.4549]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4079, 0.2829, 0.3092],\n",
            "        [0.2850, 0.3564, 0.3586],\n",
            "        [0.2749, 0.2216, 0.5035],\n",
            "        [0.2866, 0.4106, 0.3028],\n",
            "        [0.3054, 0.4217, 0.2728],\n",
            "        [0.2262, 0.4606, 0.3131],\n",
            "        [0.3595, 0.3192, 0.3213],\n",
            "        [0.2362, 0.3089, 0.4549]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 1, 1, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 0, 2, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 53/63 [00:36<00:06,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3165, 0.4950, 0.1884],\n",
            "        [0.4924, 0.3047, 0.2029],\n",
            "        [0.3032, 0.2240, 0.4728],\n",
            "        [0.3340, 0.3145, 0.3515],\n",
            "        [0.2818, 0.3579, 0.3603],\n",
            "        [0.1820, 0.3134, 0.5046],\n",
            "        [0.2286, 0.4109, 0.3605],\n",
            "        [0.1655, 0.5958, 0.2387]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3165, 0.4950, 0.1884],\n",
            "        [0.4924, 0.3047, 0.2029],\n",
            "        [0.3032, 0.2240, 0.4728],\n",
            "        [0.3340, 0.3145, 0.3515],\n",
            "        [0.2818, 0.3579, 0.3603],\n",
            "        [0.1820, 0.3134, 0.5046],\n",
            "        [0.2286, 0.4109, 0.3605],\n",
            "        [0.1655, 0.5958, 0.2387]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 2, 2, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 1, 1, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 54/63 [00:36<00:06,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2889, 0.5289, 0.1822],\n",
            "        [0.2873, 0.2438, 0.4689],\n",
            "        [0.4466, 0.2685, 0.2849],\n",
            "        [0.4935, 0.3314, 0.1751],\n",
            "        [0.4199, 0.3140, 0.2661],\n",
            "        [0.4543, 0.2196, 0.3261],\n",
            "        [0.2208, 0.3737, 0.4056],\n",
            "        [0.2550, 0.4333, 0.3117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2889, 0.5289, 0.1822],\n",
            "        [0.2873, 0.2438, 0.4689],\n",
            "        [0.4466, 0.2685, 0.2849],\n",
            "        [0.4935, 0.3314, 0.1751],\n",
            "        [0.4199, 0.3140, 0.2661],\n",
            "        [0.4543, 0.2196, 0.3261],\n",
            "        [0.2208, 0.3737, 0.4056],\n",
            "        [0.2550, 0.4333, 0.3117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 2, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 55/63 [00:37<00:05,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3970, 0.1875, 0.4155],\n",
            "        [0.4557, 0.1981, 0.3462],\n",
            "        [0.5600, 0.2906, 0.1495],\n",
            "        [0.5846, 0.2596, 0.1558],\n",
            "        [0.3632, 0.2929, 0.3439],\n",
            "        [0.2339, 0.3382, 0.4279],\n",
            "        [0.3042, 0.3199, 0.3759],\n",
            "        [0.1277, 0.6124, 0.2599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3970, 0.1875, 0.4155],\n",
            "        [0.4557, 0.1981, 0.3462],\n",
            "        [0.5600, 0.2906, 0.1495],\n",
            "        [0.5846, 0.2596, 0.1558],\n",
            "        [0.3632, 0.2929, 0.3439],\n",
            "        [0.2339, 0.3382, 0.4279],\n",
            "        [0.3042, 0.3199, 0.3759],\n",
            "        [0.1277, 0.6124, 0.2599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 1, 2, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 56/63 [00:38<00:04,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2326, 0.4432, 0.3241],\n",
            "        [0.1793, 0.4042, 0.4165],\n",
            "        [0.1434, 0.4947, 0.3619],\n",
            "        [0.5796, 0.3092, 0.1112],\n",
            "        [0.1628, 0.4407, 0.3965],\n",
            "        [0.2087, 0.4718, 0.3195],\n",
            "        [0.2065, 0.2106, 0.5829],\n",
            "        [0.4474, 0.4023, 0.1503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2326, 0.4432, 0.3241],\n",
            "        [0.1793, 0.4042, 0.4165],\n",
            "        [0.1434, 0.4947, 0.3619],\n",
            "        [0.5796, 0.3092, 0.1112],\n",
            "        [0.1628, 0.4407, 0.3965],\n",
            "        [0.2087, 0.4718, 0.3195],\n",
            "        [0.2065, 0.2106, 0.5829],\n",
            "        [0.4474, 0.4023, 0.1503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 0, 1, 1, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 1, 1, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 57/63 [00:38<00:04,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2277, 0.6471, 0.1252],\n",
            "        [0.3089, 0.3475, 0.3436],\n",
            "        [0.5347, 0.2664, 0.1989],\n",
            "        [0.3014, 0.5147, 0.1839],\n",
            "        [0.4113, 0.4402, 0.1485],\n",
            "        [0.2501, 0.3487, 0.4012],\n",
            "        [0.2441, 0.3604, 0.3956],\n",
            "        [0.1739, 0.5000, 0.3261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2277, 0.6471, 0.1252],\n",
            "        [0.3089, 0.3475, 0.3436],\n",
            "        [0.5347, 0.2664, 0.1989],\n",
            "        [0.3014, 0.5147, 0.1839],\n",
            "        [0.4113, 0.4402, 0.1485],\n",
            "        [0.2501, 0.3487, 0.4012],\n",
            "        [0.2441, 0.3604, 0.3956],\n",
            "        [0.1739, 0.5000, 0.3261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 1, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 58/63 [00:39<00:03,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3128, 0.1813, 0.5058],\n",
            "        [0.3530, 0.3728, 0.2741],\n",
            "        [0.2030, 0.3921, 0.4049],\n",
            "        [0.2107, 0.1795, 0.6099],\n",
            "        [0.2743, 0.2591, 0.4666],\n",
            "        [0.3522, 0.1671, 0.4806],\n",
            "        [0.2220, 0.3893, 0.3887],\n",
            "        [0.2895, 0.2416, 0.4689]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3128, 0.1813, 0.5058],\n",
            "        [0.3530, 0.3728, 0.2741],\n",
            "        [0.2030, 0.3921, 0.4049],\n",
            "        [0.2107, 0.1795, 0.6099],\n",
            "        [0.2743, 0.2591, 0.4666],\n",
            "        [0.3522, 0.1671, 0.4806],\n",
            "        [0.2220, 0.3893, 0.3887],\n",
            "        [0.2895, 0.2416, 0.4689]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 1, 2, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 59/63 [00:40<00:02,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4470, 0.2780, 0.2750],\n",
            "        [0.1171, 0.5287, 0.3542],\n",
            "        [0.1488, 0.2183, 0.6330],\n",
            "        [0.2180, 0.2553, 0.5268],\n",
            "        [0.6725, 0.2287, 0.0988],\n",
            "        [0.3840, 0.3849, 0.2311],\n",
            "        [0.3717, 0.3707, 0.2576],\n",
            "        [0.3497, 0.4810, 0.1693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4470, 0.2780, 0.2750],\n",
            "        [0.1171, 0.5287, 0.3542],\n",
            "        [0.1488, 0.2183, 0.6330],\n",
            "        [0.2180, 0.2553, 0.5268],\n",
            "        [0.6725, 0.2287, 0.0988],\n",
            "        [0.3840, 0.3849, 0.2311],\n",
            "        [0.3717, 0.3707, 0.2576],\n",
            "        [0.3497, 0.4810, 0.1693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 2, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 1, 1, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 60/63 [00:41<00:02,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1751, 0.5752, 0.2497],\n",
            "        [0.2290, 0.4054, 0.3655],\n",
            "        [0.2143, 0.5378, 0.2479],\n",
            "        [0.4397, 0.4324, 0.1279],\n",
            "        [0.3109, 0.4918, 0.1973],\n",
            "        [0.2920, 0.2831, 0.4249],\n",
            "        [0.2825, 0.3386, 0.3789],\n",
            "        [0.1451, 0.6560, 0.1989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1751, 0.5752, 0.2497],\n",
            "        [0.2290, 0.4054, 0.3655],\n",
            "        [0.2143, 0.5378, 0.2479],\n",
            "        [0.4397, 0.4324, 0.1279],\n",
            "        [0.3109, 0.4918, 0.1973],\n",
            "        [0.2920, 0.2831, 0.4249],\n",
            "        [0.2825, 0.3386, 0.3789],\n",
            "        [0.1451, 0.6560, 0.1989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 0, 1, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 2, 0, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 61/63 [00:41<00:01,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2802, 0.3240, 0.3958],\n",
            "        [0.3940, 0.3519, 0.2541],\n",
            "        [0.2871, 0.2205, 0.4923],\n",
            "        [0.3003, 0.2227, 0.4770],\n",
            "        [0.2157, 0.2461, 0.5382],\n",
            "        [0.5179, 0.2629, 0.2192],\n",
            "        [0.2788, 0.3774, 0.3437],\n",
            "        [0.3385, 0.3330, 0.3285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2802, 0.3240, 0.3958],\n",
            "        [0.3940, 0.3519, 0.2541],\n",
            "        [0.2871, 0.2205, 0.4923],\n",
            "        [0.3003, 0.2227, 0.4770],\n",
            "        [0.2157, 0.2461, 0.5382],\n",
            "        [0.5179, 0.2629, 0.2192],\n",
            "        [0.2788, 0.3774, 0.3437],\n",
            "        [0.3385, 0.3330, 0.3285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 2, 2, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 2, 2, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 62/63 [00:42<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3757, 0.2757, 0.3485],\n",
            "        [0.3150, 0.3142, 0.3709],\n",
            "        [0.3484, 0.3833, 0.2683],\n",
            "        [0.1456, 0.1366, 0.7178]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3757, 0.2757, 0.3485],\n",
            "        [0.3150, 0.3142, 0.3709],\n",
            "        [0.3484, 0.3833, 0.2683],\n",
            "        [0.1456, 0.1366, 0.7178]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.3170, 0.3297, 0.3533],\n",
            "        [0.5094, 0.1476, 0.3431],\n",
            "        [0.2083, 0.2350, 0.5567],\n",
            "        [0.2214, 0.3390, 0.4396],\n",
            "        [0.2671, 0.3925, 0.3404],\n",
            "        [0.5205, 0.2090, 0.2705],\n",
            "        [0.3479, 0.2829, 0.3692],\n",
            "        [0.1263, 0.6826, 0.1911]], device='cuda:0')\n",
            "prediction: tensor([2, 0, 2, 2, 1, 0, 2, 1], device='cuda:0')\n",
            "tensor([[0.3170, 0.3297, 0.3533],\n",
            "        [0.5094, 0.1476, 0.3431],\n",
            "        [0.2083, 0.2350, 0.5567],\n",
            "        [0.2214, 0.3390, 0.4396],\n",
            "        [0.2671, 0.3925, 0.3404],\n",
            "        [0.5205, 0.2090, 0.2705],\n",
            "        [0.3479, 0.2829, 0.3692],\n",
            "        [0.1263, 0.6826, 0.1911]], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2743, 0.3383, 0.3874],\n",
            "        [0.1386, 0.3566, 0.5047],\n",
            "        [0.1867, 0.3637, 0.4496],\n",
            "        [0.2259, 0.5675, 0.2066],\n",
            "        [0.2715, 0.4601, 0.2683],\n",
            "        [0.3375, 0.4798, 0.1826],\n",
            "        [0.2202, 0.5016, 0.2782],\n",
            "        [0.2855, 0.1515, 0.5630]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 2, 1, 1, 1, 1, 2], device='cuda:0')\n",
            "tensor([[0.2743, 0.3383, 0.3874],\n",
            "        [0.1386, 0.3566, 0.5047],\n",
            "        [0.1867, 0.3637, 0.4496],\n",
            "        [0.2259, 0.5675, 0.2066],\n",
            "        [0.2715, 0.4601, 0.2683],\n",
            "        [0.3375, 0.4798, 0.1826],\n",
            "        [0.2202, 0.5016, 0.2782],\n",
            "        [0.2855, 0.1515, 0.5630]], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.2202, 0.3176, 0.4622],\n",
            "        [0.2559, 0.5634, 0.1807],\n",
            "        [0.4859, 0.2549, 0.2592],\n",
            "        [0.2018, 0.4771, 0.3212],\n",
            "        [0.1337, 0.5305, 0.3358],\n",
            "        [0.3109, 0.4251, 0.2640],\n",
            "        [0.1062, 0.2639, 0.6298],\n",
            "        [0.4451, 0.3203, 0.2346]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 1, 1, 1, 2, 0], device='cuda:0')\n",
            "tensor([[0.2202, 0.3176, 0.4622],\n",
            "        [0.2559, 0.5634, 0.1807],\n",
            "        [0.4859, 0.2549, 0.2592],\n",
            "        [0.2018, 0.4771, 0.3212],\n",
            "        [0.1337, 0.5305, 0.3358],\n",
            "        [0.3109, 0.4251, 0.2640],\n",
            "        [0.1062, 0.2639, 0.6298],\n",
            "        [0.4451, 0.3203, 0.2346]], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.1408, 0.4876, 0.3716],\n",
            "        [0.4413, 0.3336, 0.2251],\n",
            "        [0.0849, 0.1873, 0.7278],\n",
            "        [0.5513, 0.2283, 0.2203],\n",
            "        [0.5113, 0.1664, 0.3222],\n",
            "        [0.3167, 0.3444, 0.3389],\n",
            "        [0.5097, 0.2565, 0.2339],\n",
            "        [0.4285, 0.1601, 0.4113]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 0, 0, 1, 0, 0], device='cuda:0')\n",
            "tensor([[0.1408, 0.4876, 0.3716],\n",
            "        [0.4413, 0.3336, 0.2251],\n",
            "        [0.0849, 0.1873, 0.7278],\n",
            "        [0.5513, 0.2283, 0.2203],\n",
            "        [0.5113, 0.1664, 0.3222],\n",
            "        [0.3167, 0.3444, 0.3389],\n",
            "        [0.5097, 0.2565, 0.2339],\n",
            "        [0.4285, 0.1601, 0.4113]], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2198, 0.4903, 0.2899],\n",
            "        [0.4023, 0.3252, 0.2725],\n",
            "        [0.2195, 0.4116, 0.3689],\n",
            "        [0.3720, 0.4136, 0.2144],\n",
            "        [0.2538, 0.4188, 0.3274],\n",
            "        [0.1953, 0.2026, 0.6021],\n",
            "        [0.2604, 0.4319, 0.3076],\n",
            "        [0.2817, 0.4130, 0.3053]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 1, 1, 1, 2, 1, 1], device='cuda:0')\n",
            "tensor([[0.2198, 0.4903, 0.2899],\n",
            "        [0.4023, 0.3252, 0.2725],\n",
            "        [0.2195, 0.4116, 0.3689],\n",
            "        [0.3720, 0.4136, 0.2144],\n",
            "        [0.2538, 0.4188, 0.3274],\n",
            "        [0.1953, 0.2026, 0.6021],\n",
            "        [0.2604, 0.4319, 0.3076],\n",
            "        [0.2817, 0.4130, 0.3053]], device='cuda:0')\n",
            "tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.3510, 0.3721, 0.2769],\n",
            "        [0.2762, 0.2260, 0.4978],\n",
            "        [0.1104, 0.3939, 0.4957],\n",
            "        [0.2595, 0.2591, 0.4814],\n",
            "        [0.3635, 0.4084, 0.2282],\n",
            "        [0.3182, 0.3347, 0.3470],\n",
            "        [0.3362, 0.4442, 0.2195],\n",
            "        [0.5986, 0.3187, 0.0827]], device='cuda:0')\n",
            "prediction: tensor([1, 2, 2, 2, 1, 2, 1, 0], device='cuda:0')\n",
            "tensor([[0.3510, 0.3721, 0.2769],\n",
            "        [0.2762, 0.2260, 0.4978],\n",
            "        [0.1104, 0.3939, 0.4957],\n",
            "        [0.2595, 0.2591, 0.4814],\n",
            "        [0.3635, 0.4084, 0.2282],\n",
            "        [0.3182, 0.3347, 0.3470],\n",
            "        [0.3362, 0.4442, 0.2195],\n",
            "        [0.5986, 0.3187, 0.0827]], device='cuda:0')\n",
            "tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2240, 0.2328, 0.5433],\n",
            "        [0.2654, 0.1952, 0.5394],\n",
            "        [0.2497, 0.5433, 0.2070],\n",
            "        [0.2796, 0.3484, 0.3720],\n",
            "        [0.2951, 0.5849, 0.1200],\n",
            "        [0.3410, 0.3412, 0.3177],\n",
            "        [0.3017, 0.2564, 0.4420],\n",
            "        [0.3546, 0.4812, 0.1642]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 2, 1, 1, 2, 1], device='cuda:0')\n",
            "tensor([[0.2240, 0.2328, 0.5433],\n",
            "        [0.2654, 0.1952, 0.5394],\n",
            "        [0.2497, 0.5433, 0.2070],\n",
            "        [0.2796, 0.3484, 0.3720],\n",
            "        [0.2951, 0.5849, 0.1200],\n",
            "        [0.3410, 0.3412, 0.3177],\n",
            "        [0.3017, 0.2564, 0.4420],\n",
            "        [0.3546, 0.4812, 0.1642]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.3801, 0.2523, 0.3676],\n",
            "        [0.3497, 0.3375, 0.3127],\n",
            "        [0.2378, 0.5142, 0.2480],\n",
            "        [0.4100, 0.2840, 0.3060],\n",
            "        [0.3622, 0.3652, 0.2726],\n",
            "        [0.3517, 0.2261, 0.4222],\n",
            "        [0.4353, 0.4125, 0.1523],\n",
            "        [0.5239, 0.2764, 0.1997]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 1, 0, 1, 2, 0, 0], device='cuda:0')\n",
            "tensor([[0.3801, 0.2523, 0.3676],\n",
            "        [0.3497, 0.3375, 0.3127],\n",
            "        [0.2378, 0.5142, 0.2480],\n",
            "        [0.4100, 0.2840, 0.3060],\n",
            "        [0.3622, 0.3652, 0.2726],\n",
            "        [0.3517, 0.2261, 0.4222],\n",
            "        [0.4353, 0.4125, 0.1523],\n",
            "        [0.5239, 0.2764, 0.1997]], device='cuda:0')\n",
            "tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.3309, 0.4211, 0.2480],\n",
            "        [0.2431, 0.4299, 0.3270],\n",
            "        [0.2242, 0.2046, 0.5711],\n",
            "        [0.2064, 0.4639, 0.3297],\n",
            "        [0.4687, 0.3313, 0.2000],\n",
            "        [0.1513, 0.4458, 0.4029],\n",
            "        [0.4966, 0.1948, 0.3086],\n",
            "        [0.2480, 0.4729, 0.2791]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 1, 0, 1, 0, 1], device='cuda:0')\n",
            "tensor([[0.3309, 0.4211, 0.2480],\n",
            "        [0.2431, 0.4299, 0.3270],\n",
            "        [0.2242, 0.2046, 0.5711],\n",
            "        [0.2064, 0.4639, 0.3297],\n",
            "        [0.4687, 0.3313, 0.2000],\n",
            "        [0.1513, 0.4458, 0.4029],\n",
            "        [0.4966, 0.1948, 0.3086],\n",
            "        [0.2480, 0.4729, 0.2791]], device='cuda:0')\n",
            "tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.2120, 0.5535, 0.2345],\n",
            "        [0.2572, 0.5510, 0.1918],\n",
            "        [0.2412, 0.3868, 0.3720],\n",
            "        [0.2927, 0.3905, 0.3168],\n",
            "        [0.3715, 0.2546, 0.3739],\n",
            "        [0.2714, 0.5080, 0.2206],\n",
            "        [0.3597, 0.4817, 0.1586],\n",
            "        [0.4196, 0.4275, 0.1530]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 1, 1, 2, 1, 1, 1], device='cuda:0')\n",
            "tensor([[0.2120, 0.5535, 0.2345],\n",
            "        [0.2572, 0.5510, 0.1918],\n",
            "        [0.2412, 0.3868, 0.3720],\n",
            "        [0.2927, 0.3905, 0.3168],\n",
            "        [0.3715, 0.2546, 0.3739],\n",
            "        [0.2714, 0.5080, 0.2206],\n",
            "        [0.3597, 0.4817, 0.1586],\n",
            "        [0.4196, 0.4275, 0.1530]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.3752, 0.2416, 0.3832],\n",
            "        [0.2446, 0.6039, 0.1515],\n",
            "        [0.4308, 0.2839, 0.2853],\n",
            "        [0.5158, 0.3234, 0.1607],\n",
            "        [0.3204, 0.3572, 0.3225],\n",
            "        [0.4407, 0.3116, 0.2477],\n",
            "        [0.3829, 0.3145, 0.3026],\n",
            "        [0.2999, 0.3612, 0.3389]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
            "tensor([[0.3752, 0.2416, 0.3832],\n",
            "        [0.2446, 0.6039, 0.1515],\n",
            "        [0.4308, 0.2839, 0.2853],\n",
            "        [0.5158, 0.3234, 0.1607],\n",
            "        [0.3204, 0.3572, 0.3225],\n",
            "        [0.4407, 0.3116, 0.2477],\n",
            "        [0.3829, 0.3145, 0.3026],\n",
            "        [0.2999, 0.3612, 0.3389]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2005, 0.4489, 0.3506],\n",
            "        [0.2659, 0.4862, 0.2480],\n",
            "        [0.2946, 0.2855, 0.4199],\n",
            "        [0.4012, 0.2363, 0.3625],\n",
            "        [0.1470, 0.5455, 0.3075],\n",
            "        [0.4754, 0.2838, 0.2408],\n",
            "        [0.1038, 0.4839, 0.4122],\n",
            "        [0.3548, 0.3749, 0.2702]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 0, 1, 0, 1, 1], device='cuda:0')\n",
            "tensor([[0.2005, 0.4489, 0.3506],\n",
            "        [0.2659, 0.4862, 0.2480],\n",
            "        [0.2946, 0.2855, 0.4199],\n",
            "        [0.4012, 0.2363, 0.3625],\n",
            "        [0.1470, 0.5455, 0.3075],\n",
            "        [0.4754, 0.2838, 0.2408],\n",
            "        [0.1038, 0.4839, 0.4122],\n",
            "        [0.3548, 0.3749, 0.2702]], device='cuda:0')\n",
            "tensor([0, 2, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.2227, 0.3575, 0.4199],\n",
            "        [0.4278, 0.3648, 0.2074],\n",
            "        [0.3332, 0.2857, 0.3810],\n",
            "        [0.4618, 0.2884, 0.2499]], device='cuda:0')\n",
            "prediction: tensor([2, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.2227, 0.3575, 0.4199],\n",
            "        [0.4278, 0.3648, 0.2074],\n",
            "        [0.3332, 0.2857, 0.3810],\n",
            "        [0.4618, 0.2884, 0.2499]], device='cuda:0')\n",
            "Epochs: 2 | Train Loss:  0.138             | Train Accuracy:  0.352             | Val Loss:  0.144             | Val Accuracy:  0.330\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3622, 0.3720, 0.2658],\n",
            "        [0.2027, 0.4621, 0.3352],\n",
            "        [0.1385, 0.2840, 0.5775],\n",
            "        [0.3573, 0.3661, 0.2766],\n",
            "        [0.2362, 0.4314, 0.3324],\n",
            "        [0.2582, 0.1861, 0.5557],\n",
            "        [0.2581, 0.3429, 0.3990],\n",
            "        [0.5776, 0.1762, 0.2462]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3622, 0.3720, 0.2658],\n",
            "        [0.2027, 0.4621, 0.3352],\n",
            "        [0.1385, 0.2840, 0.5775],\n",
            "        [0.3573, 0.3661, 0.2766],\n",
            "        [0.2362, 0.4314, 0.3324],\n",
            "        [0.2582, 0.1861, 0.5557],\n",
            "        [0.2581, 0.3429, 0.3990],\n",
            "        [0.5776, 0.1762, 0.2462]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 1, 1, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 0, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/63 [00:00<00:44,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1292, 0.7637, 0.1070],\n",
            "        [0.0921, 0.3404, 0.5675],\n",
            "        [0.5049, 0.1461, 0.3490],\n",
            "        [0.1087, 0.7228, 0.1684],\n",
            "        [0.4716, 0.2809, 0.2475],\n",
            "        [0.1079, 0.5750, 0.3171],\n",
            "        [0.4333, 0.1830, 0.3837],\n",
            "        [0.4174, 0.3798, 0.2028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1292, 0.7637, 0.1070],\n",
            "        [0.0921, 0.3404, 0.5675],\n",
            "        [0.5049, 0.1461, 0.3490],\n",
            "        [0.1087, 0.7228, 0.1684],\n",
            "        [0.4716, 0.2809, 0.2475],\n",
            "        [0.1079, 0.5750, 0.3171],\n",
            "        [0.4333, 0.1830, 0.3837],\n",
            "        [0.4174, 0.3798, 0.2028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 1, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/63 [00:01<00:41,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3418, 0.3880, 0.2702],\n",
            "        [0.1797, 0.2751, 0.5452],\n",
            "        [0.4644, 0.1757, 0.3600],\n",
            "        [0.3283, 0.1978, 0.4739],\n",
            "        [0.4715, 0.2509, 0.2776],\n",
            "        [0.1973, 0.3715, 0.4313],\n",
            "        [0.5162, 0.3353, 0.1485],\n",
            "        [0.4646, 0.1605, 0.3748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3418, 0.3880, 0.2702],\n",
            "        [0.1797, 0.2751, 0.5452],\n",
            "        [0.4644, 0.1757, 0.3600],\n",
            "        [0.3283, 0.1978, 0.4739],\n",
            "        [0.4715, 0.2509, 0.2776],\n",
            "        [0.1973, 0.3715, 0.4313],\n",
            "        [0.5162, 0.3353, 0.1485],\n",
            "        [0.4646, 0.1605, 0.3748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 2, 0, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 2, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/63 [00:02<00:40,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3919, 0.2424, 0.3657],\n",
            "        [0.4853, 0.3487, 0.1661],\n",
            "        [0.4347, 0.3418, 0.2235],\n",
            "        [0.1611, 0.3476, 0.4914],\n",
            "        [0.2179, 0.2600, 0.5221],\n",
            "        [0.2211, 0.4013, 0.3776],\n",
            "        [0.3785, 0.2516, 0.3700],\n",
            "        [0.4609, 0.2123, 0.3268]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3919, 0.2424, 0.3657],\n",
            "        [0.4853, 0.3487, 0.1661],\n",
            "        [0.4347, 0.3418, 0.2235],\n",
            "        [0.1611, 0.3476, 0.4914],\n",
            "        [0.2179, 0.2600, 0.5221],\n",
            "        [0.2211, 0.4013, 0.3776],\n",
            "        [0.3785, 0.2516, 0.3700],\n",
            "        [0.4609, 0.2123, 0.3268]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 2, 2, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 1, 1, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/63 [00:02<00:39,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3062, 0.3880, 0.3058],\n",
            "        [0.5336, 0.2587, 0.2077],\n",
            "        [0.2931, 0.3718, 0.3351],\n",
            "        [0.2190, 0.4745, 0.3065],\n",
            "        [0.3227, 0.1101, 0.5672],\n",
            "        [0.2323, 0.5436, 0.2242],\n",
            "        [0.5006, 0.2936, 0.2057],\n",
            "        [0.1554, 0.1821, 0.6625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3062, 0.3880, 0.3058],\n",
            "        [0.5336, 0.2587, 0.2077],\n",
            "        [0.2931, 0.3718, 0.3351],\n",
            "        [0.2190, 0.4745, 0.3065],\n",
            "        [0.3227, 0.1101, 0.5672],\n",
            "        [0.2323, 0.5436, 0.2242],\n",
            "        [0.5006, 0.2936, 0.2057],\n",
            "        [0.1554, 0.1821, 0.6625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 1, 2, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 2, 1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/63 [00:03<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1794, 0.2157, 0.6048],\n",
            "        [0.1549, 0.5980, 0.2471],\n",
            "        [0.3028, 0.4420, 0.2552],\n",
            "        [0.2513, 0.2037, 0.5450],\n",
            "        [0.2638, 0.4088, 0.3274],\n",
            "        [0.3085, 0.1650, 0.5266],\n",
            "        [0.1644, 0.2969, 0.5387],\n",
            "        [0.2742, 0.1737, 0.5521]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1794, 0.2157, 0.6048],\n",
            "        [0.1549, 0.5980, 0.2471],\n",
            "        [0.3028, 0.4420, 0.2552],\n",
            "        [0.2513, 0.2037, 0.5450],\n",
            "        [0.2638, 0.4088, 0.3274],\n",
            "        [0.3085, 0.1650, 0.5266],\n",
            "        [0.1644, 0.2969, 0.5387],\n",
            "        [0.2742, 0.1737, 0.5521]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 2, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 1, 1, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 6/63 [00:04<00:37,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3125, 0.3468, 0.3407],\n",
            "        [0.3696, 0.2321, 0.3983],\n",
            "        [0.3395, 0.4249, 0.2356],\n",
            "        [0.1775, 0.2090, 0.6135],\n",
            "        [0.5843, 0.2173, 0.1984],\n",
            "        [0.3069, 0.3873, 0.3058],\n",
            "        [0.2372, 0.2665, 0.4963],\n",
            "        [0.1663, 0.5134, 0.3203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3125, 0.3468, 0.3407],\n",
            "        [0.3696, 0.2321, 0.3983],\n",
            "        [0.3395, 0.4249, 0.2356],\n",
            "        [0.1775, 0.2090, 0.6135],\n",
            "        [0.5843, 0.2173, 0.1984],\n",
            "        [0.3069, 0.3873, 0.3058],\n",
            "        [0.2372, 0.2665, 0.4963],\n",
            "        [0.1663, 0.5134, 0.3203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 0, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 0, 1, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/63 [00:04<00:37,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2397, 0.3217, 0.4386],\n",
            "        [0.7034, 0.1850, 0.1116],\n",
            "        [0.1697, 0.3854, 0.4449],\n",
            "        [0.3467, 0.1715, 0.4819],\n",
            "        [0.3092, 0.3104, 0.3803],\n",
            "        [0.3689, 0.3005, 0.3306],\n",
            "        [0.2044, 0.2858, 0.5098],\n",
            "        [0.0735, 0.2296, 0.6970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2397, 0.3217, 0.4386],\n",
            "        [0.7034, 0.1850, 0.1116],\n",
            "        [0.1697, 0.3854, 0.4449],\n",
            "        [0.3467, 0.1715, 0.4819],\n",
            "        [0.3092, 0.3104, 0.3803],\n",
            "        [0.3689, 0.3005, 0.3306],\n",
            "        [0.2044, 0.2858, 0.5098],\n",
            "        [0.0735, 0.2296, 0.6970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 2, 2, 0, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/63 [00:05<00:36,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5174, 0.1813, 0.3013],\n",
            "        [0.4567, 0.2360, 0.3073],\n",
            "        [0.3201, 0.3487, 0.3312],\n",
            "        [0.1814, 0.5982, 0.2204],\n",
            "        [0.2215, 0.5500, 0.2285],\n",
            "        [0.3543, 0.4946, 0.1511],\n",
            "        [0.2868, 0.3733, 0.3399],\n",
            "        [0.3127, 0.1886, 0.4987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5174, 0.1813, 0.3013],\n",
            "        [0.4567, 0.2360, 0.3073],\n",
            "        [0.3201, 0.3487, 0.3312],\n",
            "        [0.1814, 0.5982, 0.2204],\n",
            "        [0.2215, 0.5500, 0.2285],\n",
            "        [0.3543, 0.4946, 0.1511],\n",
            "        [0.2868, 0.3733, 0.3399],\n",
            "        [0.3127, 0.1886, 0.4987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 1, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 1, 0, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/63 [00:06<00:36,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4110, 0.2855, 0.3035],\n",
            "        [0.3483, 0.2846, 0.3670],\n",
            "        [0.2556, 0.2482, 0.4962],\n",
            "        [0.2080, 0.1302, 0.6619],\n",
            "        [0.4446, 0.3399, 0.2154],\n",
            "        [0.3167, 0.3158, 0.3675],\n",
            "        [0.2858, 0.4317, 0.2825],\n",
            "        [0.4738, 0.2602, 0.2659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4110, 0.2855, 0.3035],\n",
            "        [0.3483, 0.2846, 0.3670],\n",
            "        [0.2556, 0.2482, 0.4962],\n",
            "        [0.2080, 0.1302, 0.6619],\n",
            "        [0.4446, 0.3399, 0.2154],\n",
            "        [0.3167, 0.3158, 0.3675],\n",
            "        [0.2858, 0.4317, 0.2825],\n",
            "        [0.4738, 0.2602, 0.2659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 2, 0, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 0, 1, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/63 [00:06<00:35,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3826, 0.2563, 0.3610],\n",
            "        [0.2456, 0.3261, 0.4283],\n",
            "        [0.2730, 0.2914, 0.4356],\n",
            "        [0.4333, 0.3707, 0.1960],\n",
            "        [0.3235, 0.2927, 0.3838],\n",
            "        [0.3587, 0.1973, 0.4440],\n",
            "        [0.3167, 0.3269, 0.3564],\n",
            "        [0.2831, 0.3113, 0.4055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3826, 0.2563, 0.3610],\n",
            "        [0.2456, 0.3261, 0.4283],\n",
            "        [0.2730, 0.2914, 0.4356],\n",
            "        [0.4333, 0.3707, 0.1960],\n",
            "        [0.3235, 0.2927, 0.3838],\n",
            "        [0.3587, 0.1973, 0.4440],\n",
            "        [0.3167, 0.3269, 0.3564],\n",
            "        [0.2831, 0.3113, 0.4055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 0, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/63 [00:07<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3903, 0.1914, 0.4183],\n",
            "        [0.2292, 0.2804, 0.4904],\n",
            "        [0.3559, 0.2058, 0.4383],\n",
            "        [0.4424, 0.2876, 0.2701],\n",
            "        [0.2726, 0.3267, 0.4007],\n",
            "        [0.4433, 0.3437, 0.2129],\n",
            "        [0.2794, 0.2450, 0.4756],\n",
            "        [0.3944, 0.3190, 0.2866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3903, 0.1914, 0.4183],\n",
            "        [0.2292, 0.2804, 0.4904],\n",
            "        [0.3559, 0.2058, 0.4383],\n",
            "        [0.4424, 0.2876, 0.2701],\n",
            "        [0.2726, 0.3267, 0.4007],\n",
            "        [0.4433, 0.3437, 0.2129],\n",
            "        [0.2794, 0.2450, 0.4756],\n",
            "        [0.3944, 0.3190, 0.2866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 0, 2, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 1, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/63 [00:08<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2118, 0.3585, 0.4297],\n",
            "        [0.3239, 0.2874, 0.3888],\n",
            "        [0.4185, 0.3545, 0.2270],\n",
            "        [0.2188, 0.2025, 0.5787],\n",
            "        [0.4615, 0.3080, 0.2305],\n",
            "        [0.3369, 0.1987, 0.4644],\n",
            "        [0.4730, 0.2490, 0.2781],\n",
            "        [0.4753, 0.1539, 0.3708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2118, 0.3585, 0.4297],\n",
            "        [0.3239, 0.2874, 0.3888],\n",
            "        [0.4185, 0.3545, 0.2270],\n",
            "        [0.2188, 0.2025, 0.5787],\n",
            "        [0.4615, 0.3080, 0.2305],\n",
            "        [0.3369, 0.1987, 0.4644],\n",
            "        [0.4730, 0.2490, 0.2781],\n",
            "        [0.4753, 0.1539, 0.3708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 2, 0, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 2, 2, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 13/63 [00:08<00:33,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4477, 0.2417, 0.3106],\n",
            "        [0.3532, 0.3764, 0.2704],\n",
            "        [0.3139, 0.4335, 0.2525],\n",
            "        [0.2710, 0.4906, 0.2384],\n",
            "        [0.2249, 0.2052, 0.5700],\n",
            "        [0.4521, 0.3016, 0.2464],\n",
            "        [0.4200, 0.1740, 0.4059],\n",
            "        [0.7115, 0.1592, 0.1293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4477, 0.2417, 0.3106],\n",
            "        [0.3532, 0.3764, 0.2704],\n",
            "        [0.3139, 0.4335, 0.2525],\n",
            "        [0.2710, 0.4906, 0.2384],\n",
            "        [0.2249, 0.2052, 0.5700],\n",
            "        [0.4521, 0.3016, 0.2464],\n",
            "        [0.4200, 0.1740, 0.4059],\n",
            "        [0.7115, 0.1592, 0.1293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 1, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 1, 2, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/63 [00:09<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1429, 0.3477, 0.5093],\n",
            "        [0.1739, 0.1749, 0.6512],\n",
            "        [0.3884, 0.3727, 0.2389],\n",
            "        [0.4108, 0.3417, 0.2475],\n",
            "        [0.2676, 0.2240, 0.5084],\n",
            "        [0.3975, 0.2203, 0.3822],\n",
            "        [0.2479, 0.3062, 0.4459],\n",
            "        [0.2215, 0.3445, 0.4340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1429, 0.3477, 0.5093],\n",
            "        [0.1739, 0.1749, 0.6512],\n",
            "        [0.3884, 0.3727, 0.2389],\n",
            "        [0.4108, 0.3417, 0.2475],\n",
            "        [0.2676, 0.2240, 0.5084],\n",
            "        [0.3975, 0.2203, 0.3822],\n",
            "        [0.2479, 0.3062, 0.4459],\n",
            "        [0.2215, 0.3445, 0.4340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 0, 2, 0, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 1, 0, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 15/63 [00:10<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2446, 0.5210, 0.2344],\n",
            "        [0.4234, 0.3066, 0.2700],\n",
            "        [0.3048, 0.3439, 0.3513],\n",
            "        [0.2807, 0.2625, 0.4568],\n",
            "        [0.4580, 0.3215, 0.2205],\n",
            "        [0.3196, 0.2358, 0.4447],\n",
            "        [0.4035, 0.4776, 0.1189],\n",
            "        [0.1560, 0.2026, 0.6414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2446, 0.5210, 0.2344],\n",
            "        [0.4234, 0.3066, 0.2700],\n",
            "        [0.3048, 0.3439, 0.3513],\n",
            "        [0.2807, 0.2625, 0.4568],\n",
            "        [0.4580, 0.3215, 0.2205],\n",
            "        [0.3196, 0.2358, 0.4447],\n",
            "        [0.4035, 0.4776, 0.1189],\n",
            "        [0.1560, 0.2026, 0.6414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 2, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 2, 1, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/63 [00:10<00:31,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2395, 0.3518, 0.4087],\n",
            "        [0.3973, 0.2199, 0.3828],\n",
            "        [0.4183, 0.1780, 0.4037],\n",
            "        [0.1090, 0.1741, 0.7169],\n",
            "        [0.2624, 0.2508, 0.4867],\n",
            "        [0.2801, 0.4543, 0.2656],\n",
            "        [0.1344, 0.1922, 0.6734],\n",
            "        [0.4883, 0.2846, 0.2271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2395, 0.3518, 0.4087],\n",
            "        [0.3973, 0.2199, 0.3828],\n",
            "        [0.4183, 0.1780, 0.4037],\n",
            "        [0.1090, 0.1741, 0.7169],\n",
            "        [0.2624, 0.2508, 0.4867],\n",
            "        [0.2801, 0.4543, 0.2656],\n",
            "        [0.1344, 0.1922, 0.6734],\n",
            "        [0.4883, 0.2846, 0.2271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 2, 2, 1, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 2, 1, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/63 [00:11<00:30,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2363, 0.1514, 0.6122],\n",
            "        [0.1812, 0.3172, 0.5016],\n",
            "        [0.2129, 0.4124, 0.3747],\n",
            "        [0.2731, 0.4358, 0.2911],\n",
            "        [0.2798, 0.1753, 0.5448],\n",
            "        [0.2112, 0.1534, 0.6354],\n",
            "        [0.4000, 0.2985, 0.3015],\n",
            "        [0.4169, 0.2432, 0.3400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2363, 0.1514, 0.6122],\n",
            "        [0.1812, 0.3172, 0.5016],\n",
            "        [0.2129, 0.4124, 0.3747],\n",
            "        [0.2731, 0.4358, 0.2911],\n",
            "        [0.2798, 0.1753, 0.5448],\n",
            "        [0.2112, 0.1534, 0.6354],\n",
            "        [0.4000, 0.2985, 0.3015],\n",
            "        [0.4169, 0.2432, 0.3400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 2, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 1, 0, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 18/63 [00:12<00:30,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2529, 0.2649, 0.4821],\n",
            "        [0.5754, 0.2210, 0.2036],\n",
            "        [0.4890, 0.2663, 0.2446],\n",
            "        [0.3289, 0.2282, 0.4429],\n",
            "        [0.2714, 0.2577, 0.4709],\n",
            "        [0.3352, 0.2238, 0.4410],\n",
            "        [0.2603, 0.1453, 0.5944],\n",
            "        [0.6281, 0.1667, 0.2052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2529, 0.2649, 0.4821],\n",
            "        [0.5754, 0.2210, 0.2036],\n",
            "        [0.4890, 0.2663, 0.2446],\n",
            "        [0.3289, 0.2282, 0.4429],\n",
            "        [0.2714, 0.2577, 0.4709],\n",
            "        [0.3352, 0.2238, 0.4410],\n",
            "        [0.2603, 0.1453, 0.5944],\n",
            "        [0.6281, 0.1667, 0.2052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 2, 2, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 2, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 19/63 [00:12<00:29,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4195, 0.1963, 0.3842],\n",
            "        [0.3095, 0.3700, 0.3206],\n",
            "        [0.1942, 0.3312, 0.4746],\n",
            "        [0.2691, 0.2159, 0.5150],\n",
            "        [0.4652, 0.2339, 0.3009],\n",
            "        [0.2134, 0.2700, 0.5167],\n",
            "        [0.3167, 0.3305, 0.3528],\n",
            "        [0.3665, 0.1643, 0.4692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4195, 0.1963, 0.3842],\n",
            "        [0.3095, 0.3700, 0.3206],\n",
            "        [0.1942, 0.3312, 0.4746],\n",
            "        [0.2691, 0.2159, 0.5150],\n",
            "        [0.4652, 0.2339, 0.3009],\n",
            "        [0.2134, 0.2700, 0.5167],\n",
            "        [0.3167, 0.3305, 0.3528],\n",
            "        [0.3665, 0.1643, 0.4692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 2, 0, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 2, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 20/63 [00:13<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3308, 0.3050, 0.3641],\n",
            "        [0.4206, 0.3208, 0.2585],\n",
            "        [0.4394, 0.2729, 0.2878],\n",
            "        [0.5351, 0.2070, 0.2578],\n",
            "        [0.3912, 0.2839, 0.3249],\n",
            "        [0.3158, 0.4429, 0.2412],\n",
            "        [0.1969, 0.2428, 0.5602],\n",
            "        [0.3250, 0.3076, 0.3674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3308, 0.3050, 0.3641],\n",
            "        [0.4206, 0.3208, 0.2585],\n",
            "        [0.4394, 0.2729, 0.2878],\n",
            "        [0.5351, 0.2070, 0.2578],\n",
            "        [0.3912, 0.2839, 0.3249],\n",
            "        [0.3158, 0.4429, 0.2412],\n",
            "        [0.1969, 0.2428, 0.5602],\n",
            "        [0.3250, 0.3076, 0.3674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 1, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/63 [00:14<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5276, 0.1568, 0.3156],\n",
            "        [0.4138, 0.3407, 0.2456],\n",
            "        [0.1982, 0.3483, 0.4535],\n",
            "        [0.2100, 0.1981, 0.5919],\n",
            "        [0.3281, 0.1451, 0.5268],\n",
            "        [0.3441, 0.3207, 0.3353],\n",
            "        [0.4000, 0.2168, 0.3832],\n",
            "        [0.3970, 0.1780, 0.4250]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5276, 0.1568, 0.3156],\n",
            "        [0.4138, 0.3407, 0.2456],\n",
            "        [0.1982, 0.3483, 0.4535],\n",
            "        [0.2100, 0.1981, 0.5919],\n",
            "        [0.3281, 0.1451, 0.5268],\n",
            "        [0.3441, 0.3207, 0.3353],\n",
            "        [0.4000, 0.2168, 0.3832],\n",
            "        [0.3970, 0.1780, 0.4250]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 2, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 2, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 22/63 [00:14<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3909, 0.2755, 0.3336],\n",
            "        [0.4077, 0.2366, 0.3557],\n",
            "        [0.4772, 0.2719, 0.2509],\n",
            "        [0.4633, 0.1942, 0.3426],\n",
            "        [0.3693, 0.2358, 0.3950],\n",
            "        [0.3377, 0.1182, 0.5441],\n",
            "        [0.3275, 0.1537, 0.5188],\n",
            "        [0.4284, 0.0694, 0.5022]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3909, 0.2755, 0.3336],\n",
            "        [0.4077, 0.2366, 0.3557],\n",
            "        [0.4772, 0.2719, 0.2509],\n",
            "        [0.4633, 0.1942, 0.3426],\n",
            "        [0.3693, 0.2358, 0.3950],\n",
            "        [0.3377, 0.1182, 0.5441],\n",
            "        [0.3275, 0.1537, 0.5188],\n",
            "        [0.4284, 0.0694, 0.5022]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 1, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 23/63 [00:15<00:26,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1615, 0.2798, 0.5587],\n",
            "        [0.2034, 0.2091, 0.5875],\n",
            "        [0.4312, 0.2938, 0.2749],\n",
            "        [0.3635, 0.4146, 0.2219],\n",
            "        [0.3194, 0.4069, 0.2737],\n",
            "        [0.5901, 0.2822, 0.1276],\n",
            "        [0.2454, 0.2442, 0.5104],\n",
            "        [0.3371, 0.3321, 0.3308]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1615, 0.2798, 0.5587],\n",
            "        [0.2034, 0.2091, 0.5875],\n",
            "        [0.4312, 0.2938, 0.2749],\n",
            "        [0.3635, 0.4146, 0.2219],\n",
            "        [0.3194, 0.4069, 0.2737],\n",
            "        [0.5901, 0.2822, 0.1276],\n",
            "        [0.2454, 0.2442, 0.5104],\n",
            "        [0.3371, 0.3321, 0.3308]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 1, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 0, 2, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/63 [00:16<00:26,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2096, 0.1542, 0.6361],\n",
            "        [0.2806, 0.2321, 0.4873],\n",
            "        [0.6210, 0.1562, 0.2228],\n",
            "        [0.2904, 0.4423, 0.2674],\n",
            "        [0.3307, 0.1160, 0.5533],\n",
            "        [0.2905, 0.2072, 0.5023],\n",
            "        [0.2813, 0.3487, 0.3699],\n",
            "        [0.2357, 0.3389, 0.4254]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2096, 0.1542, 0.6361],\n",
            "        [0.2806, 0.2321, 0.4873],\n",
            "        [0.6210, 0.1562, 0.2228],\n",
            "        [0.2904, 0.4423, 0.2674],\n",
            "        [0.3307, 0.1160, 0.5533],\n",
            "        [0.2905, 0.2072, 0.5023],\n",
            "        [0.2813, 0.3487, 0.3699],\n",
            "        [0.2357, 0.3389, 0.4254]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 2, 1, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 25/63 [00:16<00:25,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1459, 0.3190, 0.5351],\n",
            "        [0.3741, 0.3526, 0.2733],\n",
            "        [0.4340, 0.1913, 0.3747],\n",
            "        [0.5259, 0.0975, 0.3766],\n",
            "        [0.5603, 0.1029, 0.3368],\n",
            "        [0.2215, 0.1446, 0.6340],\n",
            "        [0.3591, 0.1212, 0.5197],\n",
            "        [0.3308, 0.2158, 0.4534]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1459, 0.3190, 0.5351],\n",
            "        [0.3741, 0.3526, 0.2733],\n",
            "        [0.4340, 0.1913, 0.3747],\n",
            "        [0.5259, 0.0975, 0.3766],\n",
            "        [0.5603, 0.1029, 0.3368],\n",
            "        [0.2215, 0.1446, 0.6340],\n",
            "        [0.3591, 0.1212, 0.5197],\n",
            "        [0.3308, 0.2158, 0.4534]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 0, 1, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 26/63 [00:17<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4054, 0.2355, 0.3591],\n",
            "        [0.4233, 0.1832, 0.3935],\n",
            "        [0.5391, 0.1074, 0.3535],\n",
            "        [0.3514, 0.1752, 0.4734],\n",
            "        [0.2853, 0.3844, 0.3303],\n",
            "        [0.4117, 0.2809, 0.3074],\n",
            "        [0.4577, 0.2092, 0.3331],\n",
            "        [0.4664, 0.2650, 0.2685]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4054, 0.2355, 0.3591],\n",
            "        [0.4233, 0.1832, 0.3935],\n",
            "        [0.5391, 0.1074, 0.3535],\n",
            "        [0.3514, 0.1752, 0.4734],\n",
            "        [0.2853, 0.3844, 0.3303],\n",
            "        [0.4117, 0.2809, 0.3074],\n",
            "        [0.4577, 0.2092, 0.3331],\n",
            "        [0.4664, 0.2650, 0.2685]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 2, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 2, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 27/63 [00:18<00:24,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1714, 0.3212, 0.5074],\n",
            "        [0.4259, 0.1019, 0.4723],\n",
            "        [0.4870, 0.2123, 0.3007],\n",
            "        [0.5060, 0.2868, 0.2072],\n",
            "        [0.3281, 0.2245, 0.4474],\n",
            "        [0.2183, 0.1517, 0.6300],\n",
            "        [0.4516, 0.1867, 0.3618],\n",
            "        [0.3847, 0.2025, 0.4127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1714, 0.3212, 0.5074],\n",
            "        [0.4259, 0.1019, 0.4723],\n",
            "        [0.4870, 0.2123, 0.3007],\n",
            "        [0.5060, 0.2868, 0.2072],\n",
            "        [0.3281, 0.2245, 0.4474],\n",
            "        [0.2183, 0.1517, 0.6300],\n",
            "        [0.4516, 0.1867, 0.3618],\n",
            "        [0.3847, 0.2025, 0.4127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 0, 2, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/63 [00:18<00:23,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2258, 0.3154, 0.4588],\n",
            "        [0.3394, 0.0949, 0.5657],\n",
            "        [0.5442, 0.1244, 0.3314],\n",
            "        [0.2346, 0.4410, 0.3243],\n",
            "        [0.3757, 0.1351, 0.4892],\n",
            "        [0.2564, 0.3700, 0.3737],\n",
            "        [0.2324, 0.1963, 0.5713],\n",
            "        [0.5224, 0.1669, 0.3107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2258, 0.3154, 0.4588],\n",
            "        [0.3394, 0.0949, 0.5657],\n",
            "        [0.5442, 0.1244, 0.3314],\n",
            "        [0.2346, 0.4410, 0.3243],\n",
            "        [0.3757, 0.1351, 0.4892],\n",
            "        [0.2564, 0.3700, 0.3737],\n",
            "        [0.2324, 0.1963, 0.5713],\n",
            "        [0.5224, 0.1669, 0.3107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 2, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 29/63 [00:19<00:23,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4534, 0.1700, 0.3766],\n",
            "        [0.2385, 0.2196, 0.5419],\n",
            "        [0.2179, 0.2291, 0.5530],\n",
            "        [0.3722, 0.2265, 0.4013],\n",
            "        [0.4655, 0.1794, 0.3551],\n",
            "        [0.5012, 0.2391, 0.2597],\n",
            "        [0.4359, 0.2610, 0.3031],\n",
            "        [0.5389, 0.1926, 0.2686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4534, 0.1700, 0.3766],\n",
            "        [0.2385, 0.2196, 0.5419],\n",
            "        [0.2179, 0.2291, 0.5530],\n",
            "        [0.3722, 0.2265, 0.4013],\n",
            "        [0.4655, 0.1794, 0.3551],\n",
            "        [0.5012, 0.2391, 0.2597],\n",
            "        [0.4359, 0.2610, 0.3031],\n",
            "        [0.5389, 0.1926, 0.2686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 2, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 0, 1, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 30/63 [00:20<00:22,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4469, 0.2150, 0.3381],\n",
            "        [0.2182, 0.3009, 0.4809],\n",
            "        [0.6228, 0.1351, 0.2421],\n",
            "        [0.2278, 0.2845, 0.4877],\n",
            "        [0.2757, 0.2617, 0.4626],\n",
            "        [0.5412, 0.1959, 0.2628],\n",
            "        [0.4850, 0.2506, 0.2644],\n",
            "        [0.3623, 0.2147, 0.4230]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4469, 0.2150, 0.3381],\n",
            "        [0.2182, 0.3009, 0.4809],\n",
            "        [0.6228, 0.1351, 0.2421],\n",
            "        [0.2278, 0.2845, 0.4877],\n",
            "        [0.2757, 0.2617, 0.4626],\n",
            "        [0.5412, 0.1959, 0.2628],\n",
            "        [0.4850, 0.2506, 0.2644],\n",
            "        [0.3623, 0.2147, 0.4230]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 2, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 2, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 31/63 [00:20<00:21,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3973, 0.1087, 0.4940],\n",
            "        [0.6800, 0.1293, 0.1906],\n",
            "        [0.4655, 0.3270, 0.2075],\n",
            "        [0.3521, 0.3178, 0.3301],\n",
            "        [0.3951, 0.2866, 0.3183],\n",
            "        [0.4012, 0.2088, 0.3900],\n",
            "        [0.4200, 0.3561, 0.2239],\n",
            "        [0.5705, 0.1620, 0.2675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3973, 0.1087, 0.4940],\n",
            "        [0.6800, 0.1293, 0.1906],\n",
            "        [0.4655, 0.3270, 0.2075],\n",
            "        [0.3521, 0.3178, 0.3301],\n",
            "        [0.3951, 0.2866, 0.3183],\n",
            "        [0.4012, 0.2088, 0.3900],\n",
            "        [0.4200, 0.3561, 0.2239],\n",
            "        [0.5705, 0.1620, 0.2675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 1, 2, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 32/63 [00:21<00:21,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3710, 0.2016, 0.4275],\n",
            "        [0.3977, 0.3046, 0.2977],\n",
            "        [0.4949, 0.1373, 0.3677],\n",
            "        [0.2531, 0.1807, 0.5663],\n",
            "        [0.3115, 0.2306, 0.4579],\n",
            "        [0.5173, 0.1767, 0.3060],\n",
            "        [0.4661, 0.1862, 0.3477],\n",
            "        [0.5401, 0.1594, 0.3004]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3710, 0.2016, 0.4275],\n",
            "        [0.3977, 0.3046, 0.2977],\n",
            "        [0.4949, 0.1373, 0.3677],\n",
            "        [0.2531, 0.1807, 0.5663],\n",
            "        [0.3115, 0.2306, 0.4579],\n",
            "        [0.5173, 0.1767, 0.3060],\n",
            "        [0.4661, 0.1862, 0.3477],\n",
            "        [0.5401, 0.1594, 0.3004]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 2, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 2, 1, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/63 [00:22<00:20,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4742, 0.2290, 0.2969],\n",
            "        [0.3758, 0.2412, 0.3830],\n",
            "        [0.6439, 0.1143, 0.2418],\n",
            "        [0.5224, 0.2689, 0.2087],\n",
            "        [0.2998, 0.2441, 0.4561],\n",
            "        [0.3915, 0.4081, 0.2005],\n",
            "        [0.4984, 0.1960, 0.3057],\n",
            "        [0.5453, 0.1924, 0.2623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4742, 0.2290, 0.2969],\n",
            "        [0.3758, 0.2412, 0.3830],\n",
            "        [0.6439, 0.1143, 0.2418],\n",
            "        [0.5224, 0.2689, 0.2087],\n",
            "        [0.2998, 0.2441, 0.4561],\n",
            "        [0.3915, 0.4081, 0.2005],\n",
            "        [0.4984, 0.1960, 0.3057],\n",
            "        [0.5453, 0.1924, 0.2623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 2, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 2, 0, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 34/63 [00:22<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6566, 0.0854, 0.2580],\n",
            "        [0.4803, 0.3569, 0.1628],\n",
            "        [0.4110, 0.2224, 0.3666],\n",
            "        [0.3927, 0.1361, 0.4713],\n",
            "        [0.4694, 0.1468, 0.3838],\n",
            "        [0.3174, 0.2417, 0.4408],\n",
            "        [0.5711, 0.1451, 0.2838],\n",
            "        [0.3033, 0.0898, 0.6070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6566, 0.0854, 0.2580],\n",
            "        [0.4803, 0.3569, 0.1628],\n",
            "        [0.4110, 0.2224, 0.3666],\n",
            "        [0.3927, 0.1361, 0.4713],\n",
            "        [0.4694, 0.1468, 0.3838],\n",
            "        [0.3174, 0.2417, 0.4408],\n",
            "        [0.5711, 0.1451, 0.2838],\n",
            "        [0.3033, 0.0898, 0.6070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 2, 0, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 1, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 35/63 [00:23<00:19,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3306, 0.2668, 0.4026],\n",
            "        [0.1996, 0.2535, 0.5469],\n",
            "        [0.5790, 0.1564, 0.2646],\n",
            "        [0.4404, 0.1287, 0.4309],\n",
            "        [0.3694, 0.2051, 0.4254],\n",
            "        [0.4099, 0.2257, 0.3644],\n",
            "        [0.3466, 0.2321, 0.4213],\n",
            "        [0.5396, 0.2764, 0.1840]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3306, 0.2668, 0.4026],\n",
            "        [0.1996, 0.2535, 0.5469],\n",
            "        [0.5790, 0.1564, 0.2646],\n",
            "        [0.4404, 0.1287, 0.4309],\n",
            "        [0.3694, 0.2051, 0.4254],\n",
            "        [0.4099, 0.2257, 0.3644],\n",
            "        [0.3466, 0.2321, 0.4213],\n",
            "        [0.5396, 0.2764, 0.1840]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 0, 2, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 1, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 36/63 [00:24<00:18,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6086, 0.1712, 0.2202],\n",
            "        [0.3100, 0.2812, 0.4088],\n",
            "        [0.3647, 0.2820, 0.3534],\n",
            "        [0.6070, 0.2137, 0.1794],\n",
            "        [0.3255, 0.2349, 0.4396],\n",
            "        [0.2528, 0.1488, 0.5984],\n",
            "        [0.4958, 0.2223, 0.2819],\n",
            "        [0.4253, 0.2626, 0.3121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6086, 0.1712, 0.2202],\n",
            "        [0.3100, 0.2812, 0.4088],\n",
            "        [0.3647, 0.2820, 0.3534],\n",
            "        [0.6070, 0.2137, 0.1794],\n",
            "        [0.3255, 0.2349, 0.4396],\n",
            "        [0.2528, 0.1488, 0.5984],\n",
            "        [0.4958, 0.2223, 0.2819],\n",
            "        [0.4253, 0.2626, 0.3121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 2, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 37/63 [00:25<00:17,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3304, 0.4464, 0.2232],\n",
            "        [0.4248, 0.3854, 0.1898],\n",
            "        [0.4972, 0.1827, 0.3202],\n",
            "        [0.2595, 0.2618, 0.4787],\n",
            "        [0.7617, 0.1253, 0.1130],\n",
            "        [0.3886, 0.3219, 0.2895],\n",
            "        [0.4092, 0.3445, 0.2462],\n",
            "        [0.3924, 0.2371, 0.3706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3304, 0.4464, 0.2232],\n",
            "        [0.4248, 0.3854, 0.1898],\n",
            "        [0.4972, 0.1827, 0.3202],\n",
            "        [0.2595, 0.2618, 0.4787],\n",
            "        [0.7617, 0.1253, 0.1130],\n",
            "        [0.3886, 0.3219, 0.2895],\n",
            "        [0.4092, 0.3445, 0.2462],\n",
            "        [0.3924, 0.2371, 0.3706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 2, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 2, 0, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 38/63 [00:25<00:17,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3945, 0.1965, 0.4090],\n",
            "        [0.5988, 0.2284, 0.1728],\n",
            "        [0.2903, 0.2243, 0.4854],\n",
            "        [0.3671, 0.3856, 0.2473],\n",
            "        [0.6632, 0.1145, 0.2223],\n",
            "        [0.5317, 0.2798, 0.1885],\n",
            "        [0.6047, 0.2303, 0.1650],\n",
            "        [0.4711, 0.1870, 0.3419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3945, 0.1965, 0.4090],\n",
            "        [0.5988, 0.2284, 0.1728],\n",
            "        [0.2903, 0.2243, 0.4854],\n",
            "        [0.3671, 0.3856, 0.2473],\n",
            "        [0.6632, 0.1145, 0.2223],\n",
            "        [0.5317, 0.2798, 0.1885],\n",
            "        [0.6047, 0.2303, 0.1650],\n",
            "        [0.4711, 0.1870, 0.3419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 1, 1, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 39/63 [00:26<00:16,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5870, 0.2695, 0.1435],\n",
            "        [0.4656, 0.2445, 0.2899],\n",
            "        [0.2893, 0.1805, 0.5302],\n",
            "        [0.4911, 0.3446, 0.1643],\n",
            "        [0.4372, 0.3181, 0.2448],\n",
            "        [0.5768, 0.1797, 0.2435],\n",
            "        [0.4088, 0.3392, 0.2521],\n",
            "        [0.3880, 0.3958, 0.2162]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5870, 0.2695, 0.1435],\n",
            "        [0.4656, 0.2445, 0.2899],\n",
            "        [0.2893, 0.1805, 0.5302],\n",
            "        [0.4911, 0.3446, 0.1643],\n",
            "        [0.4372, 0.3181, 0.2448],\n",
            "        [0.5768, 0.1797, 0.2435],\n",
            "        [0.4088, 0.3392, 0.2521],\n",
            "        [0.3880, 0.3958, 0.2162]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 2, 1, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 40/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4809, 0.2206, 0.2984],\n",
            "        [0.6930, 0.1344, 0.1725],\n",
            "        [0.1831, 0.4103, 0.4066],\n",
            "        [0.3197, 0.1905, 0.4898],\n",
            "        [0.3161, 0.3759, 0.3080],\n",
            "        [0.4351, 0.3026, 0.2623],\n",
            "        [0.0832, 0.6944, 0.2224],\n",
            "        [0.4658, 0.2682, 0.2659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4809, 0.2206, 0.2984],\n",
            "        [0.6930, 0.1344, 0.1725],\n",
            "        [0.1831, 0.4103, 0.4066],\n",
            "        [0.3197, 0.1905, 0.4898],\n",
            "        [0.3161, 0.3759, 0.3080],\n",
            "        [0.4351, 0.3026, 0.2623],\n",
            "        [0.0832, 0.6944, 0.2224],\n",
            "        [0.4658, 0.2682, 0.2659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 2, 2, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 41/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3154, 0.2542, 0.4304],\n",
            "        [0.2277, 0.2488, 0.5235],\n",
            "        [0.4758, 0.2014, 0.3228],\n",
            "        [0.6638, 0.1431, 0.1931],\n",
            "        [0.2390, 0.2904, 0.4706],\n",
            "        [0.1336, 0.2973, 0.5692],\n",
            "        [0.2666, 0.4219, 0.3115],\n",
            "        [0.4781, 0.3245, 0.1973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3154, 0.2542, 0.4304],\n",
            "        [0.2277, 0.2488, 0.5235],\n",
            "        [0.4758, 0.2014, 0.3228],\n",
            "        [0.6638, 0.1431, 0.1931],\n",
            "        [0.2390, 0.2904, 0.4706],\n",
            "        [0.1336, 0.2973, 0.5692],\n",
            "        [0.2666, 0.4219, 0.3115],\n",
            "        [0.4781, 0.3245, 0.1973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 0, 2, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 0, 2, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 42/63 [00:28<00:14,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5399, 0.1196, 0.3405],\n",
            "        [0.1635, 0.3967, 0.4398],\n",
            "        [0.1203, 0.3119, 0.5677],\n",
            "        [0.3062, 0.3348, 0.3591],\n",
            "        [0.3818, 0.2020, 0.4161],\n",
            "        [0.4214, 0.3062, 0.2724],\n",
            "        [0.1701, 0.4475, 0.3824],\n",
            "        [0.4030, 0.1837, 0.4133]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5399, 0.1196, 0.3405],\n",
            "        [0.1635, 0.3967, 0.4398],\n",
            "        [0.1203, 0.3119, 0.5677],\n",
            "        [0.3062, 0.3348, 0.3591],\n",
            "        [0.3818, 0.2020, 0.4161],\n",
            "        [0.4214, 0.3062, 0.2724],\n",
            "        [0.1701, 0.4475, 0.3824],\n",
            "        [0.4030, 0.1837, 0.4133]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 2, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 43/63 [00:29<00:13,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4913, 0.3841, 0.1245],\n",
            "        [0.3122, 0.2834, 0.4043],\n",
            "        [0.3956, 0.1973, 0.4071],\n",
            "        [0.3037, 0.4220, 0.2744],\n",
            "        [0.2038, 0.4591, 0.3371],\n",
            "        [0.2898, 0.2643, 0.4459],\n",
            "        [0.2338, 0.3486, 0.4176],\n",
            "        [0.3038, 0.3106, 0.3855]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4913, 0.3841, 0.1245],\n",
            "        [0.3122, 0.2834, 0.4043],\n",
            "        [0.3956, 0.1973, 0.4071],\n",
            "        [0.3037, 0.4220, 0.2744],\n",
            "        [0.2038, 0.4591, 0.3371],\n",
            "        [0.2898, 0.2643, 0.4459],\n",
            "        [0.2338, 0.3486, 0.4176],\n",
            "        [0.3038, 0.3106, 0.3855]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 0, 0, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 44/63 [00:29<00:13,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2210, 0.4699, 0.3091],\n",
            "        [0.2700, 0.2863, 0.4436],\n",
            "        [0.3060, 0.2920, 0.4019],\n",
            "        [0.2273, 0.3096, 0.4631],\n",
            "        [0.6256, 0.2157, 0.1587],\n",
            "        [0.1711, 0.5517, 0.2772],\n",
            "        [0.3140, 0.3051, 0.3809],\n",
            "        [0.3670, 0.2554, 0.3775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2210, 0.4699, 0.3091],\n",
            "        [0.2700, 0.2863, 0.4436],\n",
            "        [0.3060, 0.2920, 0.4019],\n",
            "        [0.2273, 0.3096, 0.4631],\n",
            "        [0.6256, 0.2157, 0.1587],\n",
            "        [0.1711, 0.5517, 0.2772],\n",
            "        [0.3140, 0.3051, 0.3809],\n",
            "        [0.3670, 0.2554, 0.3775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 2, 0, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 0, 0, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 45/63 [00:30<00:12,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3291, 0.1819, 0.4890],\n",
            "        [0.4461, 0.2530, 0.3009],\n",
            "        [0.3278, 0.1962, 0.4759],\n",
            "        [0.4329, 0.1886, 0.3784],\n",
            "        [0.4103, 0.3357, 0.2540],\n",
            "        [0.2779, 0.4194, 0.3027],\n",
            "        [0.2120, 0.3416, 0.4464],\n",
            "        [0.3967, 0.2045, 0.3987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3291, 0.1819, 0.4890],\n",
            "        [0.4461, 0.2530, 0.3009],\n",
            "        [0.3278, 0.1962, 0.4759],\n",
            "        [0.4329, 0.1886, 0.3784],\n",
            "        [0.4103, 0.3357, 0.2540],\n",
            "        [0.2779, 0.4194, 0.3027],\n",
            "        [0.2120, 0.3416, 0.4464],\n",
            "        [0.3967, 0.2045, 0.3987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 0, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 2, 2, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 46/63 [00:31<00:11,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3902, 0.3844, 0.2254],\n",
            "        [0.7031, 0.1566, 0.1403],\n",
            "        [0.2493, 0.4311, 0.3197],\n",
            "        [0.3631, 0.2637, 0.3732],\n",
            "        [0.3405, 0.3295, 0.3300],\n",
            "        [0.1998, 0.1988, 0.6015],\n",
            "        [0.2917, 0.2584, 0.4500],\n",
            "        [0.2686, 0.3356, 0.3958]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3902, 0.3844, 0.2254],\n",
            "        [0.7031, 0.1566, 0.1403],\n",
            "        [0.2493, 0.4311, 0.3197],\n",
            "        [0.3631, 0.2637, 0.3732],\n",
            "        [0.3405, 0.3295, 0.3300],\n",
            "        [0.1998, 0.1988, 0.6015],\n",
            "        [0.2917, 0.2584, 0.4500],\n",
            "        [0.2686, 0.3356, 0.3958]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 2, 0, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 1, 0, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 47/63 [00:31<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2985, 0.2544, 0.4471],\n",
            "        [0.3739, 0.3414, 0.2847],\n",
            "        [0.2892, 0.4937, 0.2171],\n",
            "        [0.2514, 0.3773, 0.3713],\n",
            "        [0.3687, 0.4141, 0.2172],\n",
            "        [0.3729, 0.2408, 0.3862],\n",
            "        [0.2721, 0.3053, 0.4226],\n",
            "        [0.3062, 0.2290, 0.4648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2985, 0.2544, 0.4471],\n",
            "        [0.3739, 0.3414, 0.2847],\n",
            "        [0.2892, 0.4937, 0.2171],\n",
            "        [0.2514, 0.3773, 0.3713],\n",
            "        [0.3687, 0.4141, 0.2172],\n",
            "        [0.3729, 0.2408, 0.3862],\n",
            "        [0.2721, 0.3053, 0.4226],\n",
            "        [0.3062, 0.2290, 0.4648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 1, 0, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 48/63 [00:32<00:10,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1780, 0.3071, 0.5149],\n",
            "        [0.4045, 0.3930, 0.2025],\n",
            "        [0.4366, 0.2014, 0.3620],\n",
            "        [0.2422, 0.4428, 0.3151],\n",
            "        [0.3588, 0.4059, 0.2353],\n",
            "        [0.1290, 0.5378, 0.3333],\n",
            "        [0.3829, 0.2414, 0.3756],\n",
            "        [0.1832, 0.2058, 0.6110]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1780, 0.3071, 0.5149],\n",
            "        [0.4045, 0.3930, 0.2025],\n",
            "        [0.4366, 0.2014, 0.3620],\n",
            "        [0.2422, 0.4428, 0.3151],\n",
            "        [0.3588, 0.4059, 0.2353],\n",
            "        [0.1290, 0.5378, 0.3333],\n",
            "        [0.3829, 0.2414, 0.3756],\n",
            "        [0.1832, 0.2058, 0.6110]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 1, 1, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 0, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 49/63 [00:33<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3906, 0.2760, 0.3334],\n",
            "        [0.3142, 0.4168, 0.2691],\n",
            "        [0.3785, 0.3000, 0.3215],\n",
            "        [0.6130, 0.1696, 0.2175],\n",
            "        [0.5652, 0.2449, 0.1899],\n",
            "        [0.2535, 0.5505, 0.1960],\n",
            "        [0.3827, 0.2942, 0.3231],\n",
            "        [0.5872, 0.1675, 0.2453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3906, 0.2760, 0.3334],\n",
            "        [0.3142, 0.4168, 0.2691],\n",
            "        [0.3785, 0.3000, 0.3215],\n",
            "        [0.6130, 0.1696, 0.2175],\n",
            "        [0.5652, 0.2449, 0.1899],\n",
            "        [0.2535, 0.5505, 0.1960],\n",
            "        [0.3827, 0.2942, 0.3231],\n",
            "        [0.5872, 0.1675, 0.2453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 2, 2, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 50/63 [00:34<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4446, 0.1814, 0.3740],\n",
            "        [0.4059, 0.2502, 0.3439],\n",
            "        [0.5094, 0.2830, 0.2076],\n",
            "        [0.2617, 0.0845, 0.6538],\n",
            "        [0.3438, 0.2470, 0.4092],\n",
            "        [0.2216, 0.5305, 0.2479],\n",
            "        [0.2368, 0.3635, 0.3997],\n",
            "        [0.1237, 0.3681, 0.5082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4446, 0.1814, 0.3740],\n",
            "        [0.4059, 0.2502, 0.3439],\n",
            "        [0.5094, 0.2830, 0.2076],\n",
            "        [0.2617, 0.0845, 0.6538],\n",
            "        [0.3438, 0.2470, 0.4092],\n",
            "        [0.2216, 0.5305, 0.2479],\n",
            "        [0.2368, 0.3635, 0.3997],\n",
            "        [0.1237, 0.3681, 0.5082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 2, 2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 0, 1, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 51/63 [00:34<00:08,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4689, 0.3074, 0.2237],\n",
            "        [0.5499, 0.3151, 0.1350],\n",
            "        [0.3214, 0.2625, 0.4160],\n",
            "        [0.7682, 0.1502, 0.0816],\n",
            "        [0.3543, 0.3879, 0.2578],\n",
            "        [0.4395, 0.3277, 0.2328],\n",
            "        [0.3911, 0.2811, 0.3278],\n",
            "        [0.4345, 0.2572, 0.3083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4689, 0.3074, 0.2237],\n",
            "        [0.5499, 0.3151, 0.1350],\n",
            "        [0.3214, 0.2625, 0.4160],\n",
            "        [0.7682, 0.1502, 0.0816],\n",
            "        [0.3543, 0.3879, 0.2578],\n",
            "        [0.4395, 0.3277, 0.2328],\n",
            "        [0.3911, 0.2811, 0.3278],\n",
            "        [0.4345, 0.2572, 0.3083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 0, 2, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 52/63 [00:35<00:07,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5552, 0.1757, 0.2691],\n",
            "        [0.5450, 0.2347, 0.2202],\n",
            "        [0.5376, 0.1253, 0.3371],\n",
            "        [0.4253, 0.3623, 0.2125],\n",
            "        [0.3348, 0.3336, 0.3315],\n",
            "        [0.1391, 0.2471, 0.6138],\n",
            "        [0.4226, 0.3307, 0.2467],\n",
            "        [0.3784, 0.2845, 0.3371]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5552, 0.1757, 0.2691],\n",
            "        [0.5450, 0.2347, 0.2202],\n",
            "        [0.5376, 0.1253, 0.3371],\n",
            "        [0.4253, 0.3623, 0.2125],\n",
            "        [0.3348, 0.3336, 0.3315],\n",
            "        [0.1391, 0.2471, 0.6138],\n",
            "        [0.4226, 0.3307, 0.2467],\n",
            "        [0.3784, 0.2845, 0.3371]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 0, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 0, 0, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 53/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1533, 0.4537, 0.3931],\n",
            "        [0.4107, 0.1877, 0.4016],\n",
            "        [0.4054, 0.3450, 0.2496],\n",
            "        [0.3019, 0.3990, 0.2991],\n",
            "        [0.4082, 0.4041, 0.1877],\n",
            "        [0.3444, 0.3042, 0.3514],\n",
            "        [0.3255, 0.3010, 0.3735],\n",
            "        [0.3448, 0.4317, 0.2234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1533, 0.4537, 0.3931],\n",
            "        [0.4107, 0.1877, 0.4016],\n",
            "        [0.4054, 0.3450, 0.2496],\n",
            "        [0.3019, 0.3990, 0.2991],\n",
            "        [0.4082, 0.4041, 0.1877],\n",
            "        [0.3444, 0.3042, 0.3514],\n",
            "        [0.3255, 0.3010, 0.3735],\n",
            "        [0.3448, 0.4317, 0.2234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 1, 0, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 54/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2870, 0.1362, 0.5768],\n",
            "        [0.1769, 0.4516, 0.3715],\n",
            "        [0.4911, 0.3153, 0.1936],\n",
            "        [0.1967, 0.3322, 0.4711],\n",
            "        [0.1752, 0.3348, 0.4900],\n",
            "        [0.4574, 0.3779, 0.1648],\n",
            "        [0.2966, 0.4081, 0.2953],\n",
            "        [0.4495, 0.1676, 0.3829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2870, 0.1362, 0.5768],\n",
            "        [0.1769, 0.4516, 0.3715],\n",
            "        [0.4911, 0.3153, 0.1936],\n",
            "        [0.1967, 0.3322, 0.4711],\n",
            "        [0.1752, 0.3348, 0.4900],\n",
            "        [0.4574, 0.3779, 0.1648],\n",
            "        [0.2966, 0.4081, 0.2953],\n",
            "        [0.4495, 0.1676, 0.3829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 2, 2, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 0, 0, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 55/63 [00:37<00:05,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3665, 0.2947, 0.3389],\n",
            "        [0.3735, 0.3944, 0.2321],\n",
            "        [0.3098, 0.2838, 0.4063],\n",
            "        [0.3944, 0.2818, 0.3239],\n",
            "        [0.4139, 0.2274, 0.3587],\n",
            "        [0.2941, 0.3812, 0.3247],\n",
            "        [0.2968, 0.4276, 0.2756],\n",
            "        [0.3425, 0.2152, 0.4423]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3665, 0.2947, 0.3389],\n",
            "        [0.3735, 0.3944, 0.2321],\n",
            "        [0.3098, 0.2838, 0.4063],\n",
            "        [0.3944, 0.2818, 0.3239],\n",
            "        [0.4139, 0.2274, 0.3587],\n",
            "        [0.2941, 0.3812, 0.3247],\n",
            "        [0.2968, 0.4276, 0.2756],\n",
            "        [0.3425, 0.2152, 0.4423]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 0, 0, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 1, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 56/63 [00:38<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2686, 0.5145, 0.2169],\n",
            "        [0.0966, 0.6512, 0.2522],\n",
            "        [0.3162, 0.2975, 0.3863],\n",
            "        [0.2376, 0.4271, 0.3353],\n",
            "        [0.4050, 0.3462, 0.2488],\n",
            "        [0.2926, 0.2800, 0.4274],\n",
            "        [0.1731, 0.4463, 0.3806],\n",
            "        [0.2406, 0.3253, 0.4342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2686, 0.5145, 0.2169],\n",
            "        [0.0966, 0.6512, 0.2522],\n",
            "        [0.3162, 0.2975, 0.3863],\n",
            "        [0.2376, 0.4271, 0.3353],\n",
            "        [0.4050, 0.3462, 0.2488],\n",
            "        [0.2926, 0.2800, 0.4274],\n",
            "        [0.1731, 0.4463, 0.3806],\n",
            "        [0.2406, 0.3253, 0.4342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 0, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 57/63 [00:38<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5292, 0.1790, 0.2917],\n",
            "        [0.3271, 0.3791, 0.2938],\n",
            "        [0.3476, 0.4019, 0.2505],\n",
            "        [0.3582, 0.2757, 0.3662],\n",
            "        [0.4428, 0.3816, 0.1756],\n",
            "        [0.6447, 0.1932, 0.1621],\n",
            "        [0.2870, 0.5101, 0.2029],\n",
            "        [0.5064, 0.3128, 0.1808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5292, 0.1790, 0.2917],\n",
            "        [0.3271, 0.3791, 0.2938],\n",
            "        [0.3476, 0.4019, 0.2505],\n",
            "        [0.3582, 0.2757, 0.3662],\n",
            "        [0.4428, 0.3816, 0.1756],\n",
            "        [0.6447, 0.1932, 0.1621],\n",
            "        [0.2870, 0.5101, 0.2029],\n",
            "        [0.5064, 0.3128, 0.1808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 2, 0, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 0, 1, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 58/63 [00:39<00:03,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3795, 0.3797, 0.2408],\n",
            "        [0.5815, 0.2220, 0.1965],\n",
            "        [0.3132, 0.2910, 0.3958],\n",
            "        [0.3806, 0.2353, 0.3842],\n",
            "        [0.1016, 0.4253, 0.4731],\n",
            "        [0.3462, 0.3676, 0.2862],\n",
            "        [0.7227, 0.1365, 0.1408],\n",
            "        [0.3072, 0.3940, 0.2988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3795, 0.3797, 0.2408],\n",
            "        [0.5815, 0.2220, 0.1965],\n",
            "        [0.3132, 0.2910, 0.3958],\n",
            "        [0.3806, 0.2353, 0.3842],\n",
            "        [0.1016, 0.4253, 0.4731],\n",
            "        [0.3462, 0.3676, 0.2862],\n",
            "        [0.7227, 0.1365, 0.1408],\n",
            "        [0.3072, 0.3940, 0.2988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 2, 2, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 0, 1, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 59/63 [00:40<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3644, 0.4594, 0.1761],\n",
            "        [0.6641, 0.1730, 0.1629],\n",
            "        [0.8201, 0.0915, 0.0883],\n",
            "        [0.4932, 0.2609, 0.2459],\n",
            "        [0.3818, 0.4192, 0.1990],\n",
            "        [0.4865, 0.2408, 0.2728],\n",
            "        [0.6840, 0.1914, 0.1247],\n",
            "        [0.4621, 0.2102, 0.3277]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3644, 0.4594, 0.1761],\n",
            "        [0.6641, 0.1730, 0.1629],\n",
            "        [0.8201, 0.0915, 0.0883],\n",
            "        [0.4932, 0.2609, 0.2459],\n",
            "        [0.3818, 0.4192, 0.1990],\n",
            "        [0.4865, 0.2408, 0.2728],\n",
            "        [0.6840, 0.1914, 0.1247],\n",
            "        [0.4621, 0.2102, 0.3277]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 2, 2, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 60/63 [00:40<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3666, 0.5113, 0.1221],\n",
            "        [0.3464, 0.2885, 0.3652],\n",
            "        [0.4176, 0.4017, 0.1807],\n",
            "        [0.6019, 0.2000, 0.1981],\n",
            "        [0.1529, 0.4671, 0.3801],\n",
            "        [0.3286, 0.4147, 0.2566],\n",
            "        [0.5874, 0.2362, 0.1764],\n",
            "        [0.2453, 0.4627, 0.2920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3666, 0.5113, 0.1221],\n",
            "        [0.3464, 0.2885, 0.3652],\n",
            "        [0.4176, 0.4017, 0.1807],\n",
            "        [0.6019, 0.2000, 0.1981],\n",
            "        [0.1529, 0.4671, 0.3801],\n",
            "        [0.3286, 0.4147, 0.2566],\n",
            "        [0.5874, 0.2362, 0.1764],\n",
            "        [0.2453, 0.4627, 0.2920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 0, 1, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 61/63 [00:41<00:01,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5431, 0.1764, 0.2805],\n",
            "        [0.3319, 0.4940, 0.1741],\n",
            "        [0.2923, 0.4952, 0.2125],\n",
            "        [0.4590, 0.3132, 0.2278],\n",
            "        [0.2007, 0.3129, 0.4864],\n",
            "        [0.3886, 0.2928, 0.3186],\n",
            "        [0.3697, 0.2935, 0.3367],\n",
            "        [0.2948, 0.3165, 0.3886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5431, 0.1764, 0.2805],\n",
            "        [0.3319, 0.4940, 0.1741],\n",
            "        [0.2923, 0.4952, 0.2125],\n",
            "        [0.4590, 0.3132, 0.2278],\n",
            "        [0.2007, 0.3129, 0.4864],\n",
            "        [0.3886, 0.2928, 0.3186],\n",
            "        [0.3697, 0.2935, 0.3367],\n",
            "        [0.2948, 0.3165, 0.3886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 0, 1, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 62/63 [00:42<00:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1840, 0.4885, 0.3275],\n",
            "        [0.3745, 0.2368, 0.3887],\n",
            "        [0.3679, 0.3085, 0.3236],\n",
            "        [0.6662, 0.1623, 0.1715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1840, 0.4885, 0.3275],\n",
            "        [0.3745, 0.2368, 0.3887],\n",
            "        [0.3679, 0.3085, 0.3236],\n",
            "        [0.6662, 0.1623, 0.1715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:42<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.6853, 0.1153, 0.1994],\n",
            "        [0.3551, 0.4276, 0.2173],\n",
            "        [0.7813, 0.1203, 0.0984],\n",
            "        [0.4372, 0.2385, 0.3243],\n",
            "        [0.4458, 0.2911, 0.2630],\n",
            "        [0.4499, 0.3064, 0.2436],\n",
            "        [0.2919, 0.2996, 0.4085],\n",
            "        [0.3375, 0.3338, 0.3287]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 0, 0, 0, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.6853, 0.1153, 0.1994],\n",
            "        [0.3551, 0.4276, 0.2173],\n",
            "        [0.7813, 0.1203, 0.0984],\n",
            "        [0.4372, 0.2385, 0.3243],\n",
            "        [0.4458, 0.2911, 0.2630],\n",
            "        [0.4499, 0.3064, 0.2436],\n",
            "        [0.2919, 0.2996, 0.4085],\n",
            "        [0.3375, 0.3338, 0.3287]], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.3053, 0.3939, 0.3008],\n",
            "        [0.3407, 0.2219, 0.4374],\n",
            "        [0.3313, 0.4192, 0.2496],\n",
            "        [0.7139, 0.1940, 0.0920],\n",
            "        [0.2723, 0.3409, 0.3868],\n",
            "        [0.3077, 0.5032, 0.1890],\n",
            "        [0.5978, 0.2105, 0.1916],\n",
            "        [0.2392, 0.3369, 0.4239]], device='cuda:0')\n",
            "prediction: tensor([1, 2, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "tensor([[0.3053, 0.3939, 0.3008],\n",
            "        [0.3407, 0.2219, 0.4374],\n",
            "        [0.3313, 0.4192, 0.2496],\n",
            "        [0.7139, 0.1940, 0.0920],\n",
            "        [0.2723, 0.3409, 0.3868],\n",
            "        [0.3077, 0.5032, 0.1890],\n",
            "        [0.5978, 0.2105, 0.1916],\n",
            "        [0.2392, 0.3369, 0.4239]], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.1630, 0.3392, 0.4979],\n",
            "        [0.3103, 0.3109, 0.3788],\n",
            "        [0.7417, 0.0923, 0.1660],\n",
            "        [0.3898, 0.3838, 0.2263],\n",
            "        [0.3836, 0.2989, 0.3175],\n",
            "        [0.5786, 0.1876, 0.2338],\n",
            "        [0.2909, 0.3315, 0.3776],\n",
            "        [0.6668, 0.1867, 0.1465]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 0, 0, 0, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.1630, 0.3392, 0.4979],\n",
            "        [0.3103, 0.3109, 0.3788],\n",
            "        [0.7417, 0.0923, 0.1660],\n",
            "        [0.3898, 0.3838, 0.2263],\n",
            "        [0.3836, 0.2989, 0.3175],\n",
            "        [0.5786, 0.1876, 0.2338],\n",
            "        [0.2909, 0.3315, 0.3776],\n",
            "        [0.6668, 0.1867, 0.1465]], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.1076, 0.2830, 0.6094],\n",
            "        [0.4059, 0.4362, 0.1579],\n",
            "        [0.2534, 0.3700, 0.3766],\n",
            "        [0.3509, 0.3872, 0.2619],\n",
            "        [0.3791, 0.3439, 0.2770],\n",
            "        [0.6613, 0.1398, 0.1989],\n",
            "        [0.5311, 0.1835, 0.2854],\n",
            "        [0.5561, 0.1334, 0.3105]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 2, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([[0.1076, 0.2830, 0.6094],\n",
            "        [0.4059, 0.4362, 0.1579],\n",
            "        [0.2534, 0.3700, 0.3766],\n",
            "        [0.3509, 0.3872, 0.2619],\n",
            "        [0.3791, 0.3439, 0.2770],\n",
            "        [0.6613, 0.1398, 0.1989],\n",
            "        [0.5311, 0.1835, 0.2854],\n",
            "        [0.5561, 0.1334, 0.3105]], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.3038, 0.4734, 0.2227],\n",
            "        [0.3342, 0.4612, 0.2046],\n",
            "        [0.5636, 0.2081, 0.2283],\n",
            "        [0.6089, 0.1954, 0.1957],\n",
            "        [0.4108, 0.3316, 0.2576],\n",
            "        [0.6072, 0.1333, 0.2595],\n",
            "        [0.3917, 0.3221, 0.2861],\n",
            "        [0.2550, 0.4275, 0.3175]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "tensor([[0.3038, 0.4734, 0.2227],\n",
            "        [0.3342, 0.4612, 0.2046],\n",
            "        [0.5636, 0.2081, 0.2283],\n",
            "        [0.6089, 0.1954, 0.1957],\n",
            "        [0.4108, 0.3316, 0.2576],\n",
            "        [0.6072, 0.1333, 0.2595],\n",
            "        [0.3917, 0.3221, 0.2861],\n",
            "        [0.2550, 0.4275, 0.3175]], device='cuda:0')\n",
            "tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.3842, 0.3767, 0.2391],\n",
            "        [0.3195, 0.4003, 0.2802],\n",
            "        [0.6888, 0.1544, 0.1568],\n",
            "        [0.7116, 0.1558, 0.1326],\n",
            "        [0.8152, 0.0688, 0.1160],\n",
            "        [0.6196, 0.1852, 0.1952],\n",
            "        [0.3905, 0.2138, 0.3957],\n",
            "        [0.4457, 0.2829, 0.2714]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 0, 0, 0, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.3842, 0.3767, 0.2391],\n",
            "        [0.3195, 0.4003, 0.2802],\n",
            "        [0.6888, 0.1544, 0.1568],\n",
            "        [0.7116, 0.1558, 0.1326],\n",
            "        [0.8152, 0.0688, 0.1160],\n",
            "        [0.6196, 0.1852, 0.1952],\n",
            "        [0.3905, 0.2138, 0.3957],\n",
            "        [0.4457, 0.2829, 0.2714]], device='cuda:0')\n",
            "tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.1945, 0.4149, 0.3906],\n",
            "        [0.5007, 0.2506, 0.2487],\n",
            "        [0.2852, 0.3648, 0.3500],\n",
            "        [0.1559, 0.3496, 0.4945],\n",
            "        [0.1697, 0.5249, 0.3053],\n",
            "        [0.2714, 0.3852, 0.3434],\n",
            "        [0.3634, 0.3004, 0.3362],\n",
            "        [0.4718, 0.2797, 0.2485]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 1, 2, 1, 1, 0, 0], device='cuda:0')\n",
            "tensor([[0.1945, 0.4149, 0.3906],\n",
            "        [0.5007, 0.2506, 0.2487],\n",
            "        [0.2852, 0.3648, 0.3500],\n",
            "        [0.1559, 0.3496, 0.4945],\n",
            "        [0.1697, 0.5249, 0.3053],\n",
            "        [0.2714, 0.3852, 0.3434],\n",
            "        [0.3634, 0.3004, 0.3362],\n",
            "        [0.4718, 0.2797, 0.2485]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.5276, 0.2745, 0.1979],\n",
            "        [0.5876, 0.1895, 0.2229],\n",
            "        [0.6375, 0.2069, 0.1556],\n",
            "        [0.4762, 0.1958, 0.3280],\n",
            "        [0.5342, 0.2250, 0.2408],\n",
            "        [0.5571, 0.3142, 0.1287],\n",
            "        [0.5762, 0.1956, 0.2283],\n",
            "        [0.5860, 0.0955, 0.3185]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([[0.5276, 0.2745, 0.1979],\n",
            "        [0.5876, 0.1895, 0.2229],\n",
            "        [0.6375, 0.2069, 0.1556],\n",
            "        [0.4762, 0.1958, 0.3280],\n",
            "        [0.5342, 0.2250, 0.2408],\n",
            "        [0.5571, 0.3142, 0.1287],\n",
            "        [0.5762, 0.1956, 0.2283],\n",
            "        [0.5860, 0.0955, 0.3185]], device='cuda:0')\n",
            "tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.3974, 0.3316, 0.2711],\n",
            "        [0.3712, 0.4143, 0.2145],\n",
            "        [0.5157, 0.2538, 0.2304],\n",
            "        [0.5853, 0.1846, 0.2301],\n",
            "        [0.5426, 0.3102, 0.1472],\n",
            "        [0.3674, 0.3553, 0.2773],\n",
            "        [0.4589, 0.3385, 0.2025],\n",
            "        [0.3150, 0.3505, 0.3345]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "tensor([[0.3974, 0.3316, 0.2711],\n",
            "        [0.3712, 0.4143, 0.2145],\n",
            "        [0.5157, 0.2538, 0.2304],\n",
            "        [0.5853, 0.1846, 0.2301],\n",
            "        [0.5426, 0.3102, 0.1472],\n",
            "        [0.3674, 0.3553, 0.2773],\n",
            "        [0.4589, 0.3385, 0.2025],\n",
            "        [0.3150, 0.3505, 0.3345]], device='cuda:0')\n",
            "tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.7280, 0.1138, 0.1582],\n",
            "        [0.4045, 0.4258, 0.1698],\n",
            "        [0.4174, 0.1610, 0.4216],\n",
            "        [0.2277, 0.4241, 0.3482],\n",
            "        [0.3947, 0.3078, 0.2975],\n",
            "        [0.3963, 0.3286, 0.2751],\n",
            "        [0.5157, 0.2264, 0.2579],\n",
            "        [0.6085, 0.1897, 0.2018]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 2, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([[0.7280, 0.1138, 0.1582],\n",
            "        [0.4045, 0.4258, 0.1698],\n",
            "        [0.4174, 0.1610, 0.4216],\n",
            "        [0.2277, 0.4241, 0.3482],\n",
            "        [0.3947, 0.3078, 0.2975],\n",
            "        [0.3963, 0.3286, 0.2751],\n",
            "        [0.5157, 0.2264, 0.2579],\n",
            "        [0.6085, 0.1897, 0.2018]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.4264, 0.2406, 0.3330],\n",
            "        [0.4777, 0.3147, 0.2076],\n",
            "        [0.2829, 0.3551, 0.3620],\n",
            "        [0.4103, 0.2800, 0.3097],\n",
            "        [0.4517, 0.3429, 0.2054],\n",
            "        [0.2283, 0.5027, 0.2690],\n",
            "        [0.3036, 0.2662, 0.4302],\n",
            "        [0.2925, 0.5547, 0.1528]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 2, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "tensor([[0.4264, 0.2406, 0.3330],\n",
            "        [0.4777, 0.3147, 0.2076],\n",
            "        [0.2829, 0.3551, 0.3620],\n",
            "        [0.4103, 0.2800, 0.3097],\n",
            "        [0.4517, 0.3429, 0.2054],\n",
            "        [0.2283, 0.5027, 0.2690],\n",
            "        [0.3036, 0.2662, 0.4302],\n",
            "        [0.2925, 0.5547, 0.1528]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.6543, 0.1746, 0.1711],\n",
            "        [0.3509, 0.3403, 0.3088],\n",
            "        [0.5404, 0.2733, 0.1862],\n",
            "        [0.6199, 0.1953, 0.1849],\n",
            "        [0.1612, 0.5039, 0.3348],\n",
            "        [0.3299, 0.2959, 0.3742],\n",
            "        [0.2510, 0.4475, 0.3015],\n",
            "        [0.2043, 0.5339, 0.2619]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 0, 0, 1, 2, 1, 1], device='cuda:0')\n",
            "tensor([[0.6543, 0.1746, 0.1711],\n",
            "        [0.3509, 0.3403, 0.3088],\n",
            "        [0.5404, 0.2733, 0.1862],\n",
            "        [0.6199, 0.1953, 0.1849],\n",
            "        [0.1612, 0.5039, 0.3348],\n",
            "        [0.3299, 0.2959, 0.3742],\n",
            "        [0.2510, 0.4475, 0.3015],\n",
            "        [0.2043, 0.5339, 0.2619]], device='cuda:0')\n",
            "tensor([0, 2, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.7483, 0.1064, 0.1453],\n",
            "        [0.5307, 0.1627, 0.3066],\n",
            "        [0.2039, 0.2375, 0.5586],\n",
            "        [0.6608, 0.1053, 0.2339]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.7483, 0.1064, 0.1453],\n",
            "        [0.5307, 0.1627, 0.3066],\n",
            "        [0.2039, 0.2375, 0.5586],\n",
            "        [0.6608, 0.1053, 0.2339]], device='cuda:0')\n",
            "Epochs: 3 | Train Loss:  0.138             | Train Accuracy:  0.378             | Val Loss:  0.134             | Val Accuracy:  0.500\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2259, 0.5393, 0.2347],\n",
            "        [0.6760, 0.2157, 0.1083],\n",
            "        [0.6947, 0.1412, 0.1642],\n",
            "        [0.5112, 0.1916, 0.2973],\n",
            "        [0.4283, 0.2999, 0.2718],\n",
            "        [0.4738, 0.1960, 0.3302],\n",
            "        [0.6794, 0.1226, 0.1980],\n",
            "        [0.3785, 0.3797, 0.2418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2259, 0.5393, 0.2347],\n",
            "        [0.6760, 0.2157, 0.1083],\n",
            "        [0.6947, 0.1412, 0.1642],\n",
            "        [0.5112, 0.1916, 0.2973],\n",
            "        [0.4283, 0.2999, 0.2718],\n",
            "        [0.4738, 0.1960, 0.3302],\n",
            "        [0.6794, 0.1226, 0.1980],\n",
            "        [0.3785, 0.3797, 0.2418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 2, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/63 [00:00<00:45,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1748, 0.3844, 0.4408],\n",
            "        [0.7843, 0.0808, 0.1349],\n",
            "        [0.5187, 0.1667, 0.3146],\n",
            "        [0.4498, 0.3719, 0.1783],\n",
            "        [0.4867, 0.2297, 0.2836],\n",
            "        [0.4451, 0.4055, 0.1494],\n",
            "        [0.6076, 0.2401, 0.1524],\n",
            "        [0.2967, 0.4781, 0.2252]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1748, 0.3844, 0.4408],\n",
            "        [0.7843, 0.0808, 0.1349],\n",
            "        [0.5187, 0.1667, 0.3146],\n",
            "        [0.4498, 0.3719, 0.1783],\n",
            "        [0.4867, 0.2297, 0.2836],\n",
            "        [0.4451, 0.4055, 0.1494],\n",
            "        [0.6076, 0.2401, 0.1524],\n",
            "        [0.2967, 0.4781, 0.2252]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 0, 1, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/63 [00:01<00:42,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4941, 0.1804, 0.3255],\n",
            "        [0.2168, 0.5800, 0.2032],\n",
            "        [0.5249, 0.3382, 0.1369],\n",
            "        [0.3787, 0.2351, 0.3861],\n",
            "        [0.7954, 0.0747, 0.1299],\n",
            "        [0.2559, 0.3959, 0.3482],\n",
            "        [0.4918, 0.2095, 0.2987],\n",
            "        [0.5139, 0.2060, 0.2802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4941, 0.1804, 0.3255],\n",
            "        [0.2168, 0.5800, 0.2032],\n",
            "        [0.5249, 0.3382, 0.1369],\n",
            "        [0.3787, 0.2351, 0.3861],\n",
            "        [0.7954, 0.0747, 0.1299],\n",
            "        [0.2559, 0.3959, 0.3482],\n",
            "        [0.4918, 0.2095, 0.2987],\n",
            "        [0.5139, 0.2060, 0.2802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/63 [00:02<00:40,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5885, 0.1358, 0.2757],\n",
            "        [0.5968, 0.2365, 0.1667],\n",
            "        [0.2831, 0.4695, 0.2474],\n",
            "        [0.5715, 0.3046, 0.1238],\n",
            "        [0.1177, 0.3022, 0.5801],\n",
            "        [0.3020, 0.3917, 0.3063],\n",
            "        [0.4908, 0.2356, 0.2736],\n",
            "        [0.5102, 0.3279, 0.1619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5885, 0.1358, 0.2757],\n",
            "        [0.5968, 0.2365, 0.1667],\n",
            "        [0.2831, 0.4695, 0.2474],\n",
            "        [0.5715, 0.3046, 0.1238],\n",
            "        [0.1177, 0.3022, 0.5801],\n",
            "        [0.3020, 0.3917, 0.3063],\n",
            "        [0.4908, 0.2356, 0.2736],\n",
            "        [0.5102, 0.3279, 0.1619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 2, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 1, 1, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/63 [00:02<00:39,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2546, 0.3455, 0.3999],\n",
            "        [0.1542, 0.5258, 0.3199],\n",
            "        [0.3197, 0.3505, 0.3298],\n",
            "        [0.6437, 0.1233, 0.2330],\n",
            "        [0.4212, 0.1372, 0.4416],\n",
            "        [0.1252, 0.3701, 0.5047],\n",
            "        [0.3332, 0.2380, 0.4288],\n",
            "        [0.4372, 0.2262, 0.3366]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2546, 0.3455, 0.3999],\n",
            "        [0.1542, 0.5258, 0.3199],\n",
            "        [0.3197, 0.3505, 0.3298],\n",
            "        [0.6437, 0.1233, 0.2330],\n",
            "        [0.4212, 0.1372, 0.4416],\n",
            "        [0.1252, 0.3701, 0.5047],\n",
            "        [0.3332, 0.2380, 0.4288],\n",
            "        [0.4372, 0.2262, 0.3366]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 0, 2, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 0, 2, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/63 [00:03<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5266, 0.2236, 0.2498],\n",
            "        [0.2458, 0.4658, 0.2883],\n",
            "        [0.2702, 0.4596, 0.2702],\n",
            "        [0.3012, 0.3405, 0.3583],\n",
            "        [0.1955, 0.4811, 0.3234],\n",
            "        [0.3539, 0.3317, 0.3144],\n",
            "        [0.4528, 0.3828, 0.1644],\n",
            "        [0.3146, 0.1243, 0.5611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5266, 0.2236, 0.2498],\n",
            "        [0.2458, 0.4658, 0.2883],\n",
            "        [0.2702, 0.4596, 0.2702],\n",
            "        [0.3012, 0.3405, 0.3583],\n",
            "        [0.1955, 0.4811, 0.3234],\n",
            "        [0.3539, 0.3317, 0.3144],\n",
            "        [0.4528, 0.3828, 0.1644],\n",
            "        [0.3146, 0.1243, 0.5611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 2, 1, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 2, 1, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 6/63 [00:04<00:38,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3282, 0.3517, 0.3200],\n",
            "        [0.3275, 0.3314, 0.3411],\n",
            "        [0.2530, 0.5288, 0.2182],\n",
            "        [0.4730, 0.2457, 0.2813],\n",
            "        [0.6072, 0.0890, 0.3038],\n",
            "        [0.5848, 0.2642, 0.1510],\n",
            "        [0.3444, 0.3498, 0.3058],\n",
            "        [0.4760, 0.3601, 0.1639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3282, 0.3517, 0.3200],\n",
            "        [0.3275, 0.3314, 0.3411],\n",
            "        [0.2530, 0.5288, 0.2182],\n",
            "        [0.4730, 0.2457, 0.2813],\n",
            "        [0.6072, 0.0890, 0.3038],\n",
            "        [0.5848, 0.2642, 0.1510],\n",
            "        [0.3444, 0.3498, 0.3058],\n",
            "        [0.4760, 0.3601, 0.1639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 1, 2, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/63 [00:04<00:37,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1815, 0.3303, 0.4883],\n",
            "        [0.2364, 0.1848, 0.5788],\n",
            "        [0.5834, 0.1181, 0.2985],\n",
            "        [0.1157, 0.4003, 0.4840],\n",
            "        [0.1912, 0.4931, 0.3158],\n",
            "        [0.7320, 0.1607, 0.1073],\n",
            "        [0.3449, 0.3940, 0.2612],\n",
            "        [0.3660, 0.3740, 0.2600]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1815, 0.3303, 0.4883],\n",
            "        [0.2364, 0.1848, 0.5788],\n",
            "        [0.5834, 0.1181, 0.2985],\n",
            "        [0.1157, 0.4003, 0.4840],\n",
            "        [0.1912, 0.4931, 0.3158],\n",
            "        [0.7320, 0.1607, 0.1073],\n",
            "        [0.3449, 0.3940, 0.2612],\n",
            "        [0.3660, 0.3740, 0.2600]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 2, 1, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 2, 0, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/63 [00:05<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1761, 0.5346, 0.2893],\n",
            "        [0.2233, 0.4208, 0.3558],\n",
            "        [0.3696, 0.2635, 0.3669],\n",
            "        [0.3421, 0.3017, 0.3562],\n",
            "        [0.3595, 0.2349, 0.4056],\n",
            "        [0.0862, 0.2618, 0.6520],\n",
            "        [0.4811, 0.1262, 0.3928],\n",
            "        [0.6212, 0.1313, 0.2475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1761, 0.5346, 0.2893],\n",
            "        [0.2233, 0.4208, 0.3558],\n",
            "        [0.3696, 0.2635, 0.3669],\n",
            "        [0.3421, 0.3017, 0.3562],\n",
            "        [0.3595, 0.2349, 0.4056],\n",
            "        [0.0862, 0.2618, 0.6520],\n",
            "        [0.4811, 0.1262, 0.3928],\n",
            "        [0.6212, 0.1313, 0.2475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 2, 2, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 0, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/63 [00:06<00:36,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1696, 0.2775, 0.5529],\n",
            "        [0.4932, 0.1042, 0.4027],\n",
            "        [0.3289, 0.2795, 0.3917],\n",
            "        [0.6705, 0.0770, 0.2525],\n",
            "        [0.1141, 0.4977, 0.3882],\n",
            "        [0.2403, 0.4286, 0.3311],\n",
            "        [0.3749, 0.1989, 0.4262],\n",
            "        [0.1060, 0.3577, 0.5363]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1696, 0.2775, 0.5529],\n",
            "        [0.4932, 0.1042, 0.4027],\n",
            "        [0.3289, 0.2795, 0.3917],\n",
            "        [0.6705, 0.0770, 0.2525],\n",
            "        [0.1141, 0.4977, 0.3882],\n",
            "        [0.2403, 0.4286, 0.3311],\n",
            "        [0.3749, 0.1989, 0.4262],\n",
            "        [0.1060, 0.3577, 0.5363]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 1, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 1, 1, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/63 [00:06<00:35,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4715, 0.2149, 0.3136],\n",
            "        [0.1276, 0.5007, 0.3717],\n",
            "        [0.1298, 0.4413, 0.4289],\n",
            "        [0.5183, 0.1509, 0.3309],\n",
            "        [0.2571, 0.3268, 0.4162],\n",
            "        [0.0968, 0.5916, 0.3116],\n",
            "        [0.1255, 0.6663, 0.2082],\n",
            "        [0.3103, 0.2847, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4715, 0.2149, 0.3136],\n",
            "        [0.1276, 0.5007, 0.3717],\n",
            "        [0.1298, 0.4413, 0.4289],\n",
            "        [0.5183, 0.1509, 0.3309],\n",
            "        [0.2571, 0.3268, 0.4162],\n",
            "        [0.0968, 0.5916, 0.3116],\n",
            "        [0.1255, 0.6663, 0.2082],\n",
            "        [0.3103, 0.2847, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 2, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/63 [00:07<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1640, 0.1848, 0.6513],\n",
            "        [0.2067, 0.3583, 0.4350],\n",
            "        [0.1273, 0.3472, 0.5255],\n",
            "        [0.0970, 0.4587, 0.4444],\n",
            "        [0.1482, 0.4116, 0.4403],\n",
            "        [0.0967, 0.4486, 0.4546],\n",
            "        [0.2097, 0.4343, 0.3561],\n",
            "        [0.2810, 0.3450, 0.3740]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1640, 0.1848, 0.6513],\n",
            "        [0.2067, 0.3583, 0.4350],\n",
            "        [0.1273, 0.3472, 0.5255],\n",
            "        [0.0970, 0.4587, 0.4444],\n",
            "        [0.1482, 0.4116, 0.4403],\n",
            "        [0.0967, 0.4486, 0.4546],\n",
            "        [0.2097, 0.4343, 0.3561],\n",
            "        [0.2810, 0.3450, 0.3740]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 1, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 1, 1, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/63 [00:08<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1261, 0.5314, 0.3425],\n",
            "        [0.7939, 0.0689, 0.1372],\n",
            "        [0.1415, 0.7163, 0.1422],\n",
            "        [0.1989, 0.4477, 0.3534],\n",
            "        [0.6351, 0.1144, 0.2505],\n",
            "        [0.1409, 0.4467, 0.4124],\n",
            "        [0.2419, 0.4907, 0.2674],\n",
            "        [0.8805, 0.0456, 0.0739]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1261, 0.5314, 0.3425],\n",
            "        [0.7939, 0.0689, 0.1372],\n",
            "        [0.1415, 0.7163, 0.1422],\n",
            "        [0.1989, 0.4477, 0.3534],\n",
            "        [0.6351, 0.1144, 0.2505],\n",
            "        [0.1409, 0.4467, 0.4124],\n",
            "        [0.2419, 0.4907, 0.2674],\n",
            "        [0.8805, 0.0456, 0.0739]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 13/63 [00:08<00:33,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2694, 0.3594, 0.3711],\n",
            "        [0.2882, 0.2150, 0.4968],\n",
            "        [0.2798, 0.5091, 0.2112],\n",
            "        [0.1545, 0.5416, 0.3039],\n",
            "        [0.3605, 0.2980, 0.3415],\n",
            "        [0.1998, 0.2450, 0.5551],\n",
            "        [0.2210, 0.4615, 0.3174],\n",
            "        [0.1828, 0.3174, 0.4998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2694, 0.3594, 0.3711],\n",
            "        [0.2882, 0.2150, 0.4968],\n",
            "        [0.2798, 0.5091, 0.2112],\n",
            "        [0.1545, 0.5416, 0.3039],\n",
            "        [0.3605, 0.2980, 0.3415],\n",
            "        [0.1998, 0.2450, 0.5551],\n",
            "        [0.2210, 0.4615, 0.3174],\n",
            "        [0.1828, 0.3174, 0.4998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 1, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/63 [00:09<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7418, 0.0826, 0.1756],\n",
            "        [0.2485, 0.1544, 0.5971],\n",
            "        [0.2498, 0.2735, 0.4767],\n",
            "        [0.0397, 0.3184, 0.6418],\n",
            "        [0.0875, 0.2426, 0.6699],\n",
            "        [0.1669, 0.5490, 0.2841],\n",
            "        [0.1655, 0.2712, 0.5633],\n",
            "        [0.3448, 0.4010, 0.2543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7418, 0.0826, 0.1756],\n",
            "        [0.2485, 0.1544, 0.5971],\n",
            "        [0.2498, 0.2735, 0.4767],\n",
            "        [0.0397, 0.3184, 0.6418],\n",
            "        [0.0875, 0.2426, 0.6699],\n",
            "        [0.1669, 0.5490, 0.2841],\n",
            "        [0.1655, 0.2712, 0.5633],\n",
            "        [0.3448, 0.4010, 0.2543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 2, 2, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 2, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 15/63 [00:10<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6222, 0.0714, 0.3064],\n",
            "        [0.5536, 0.1478, 0.2986],\n",
            "        [0.2576, 0.5105, 0.2319],\n",
            "        [0.1901, 0.4541, 0.3558],\n",
            "        [0.3198, 0.3143, 0.3658],\n",
            "        [0.2097, 0.4412, 0.3491],\n",
            "        [0.5917, 0.2403, 0.1680],\n",
            "        [0.1816, 0.3912, 0.4272]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6222, 0.0714, 0.3064],\n",
            "        [0.5536, 0.1478, 0.2986],\n",
            "        [0.2576, 0.5105, 0.2319],\n",
            "        [0.1901, 0.4541, 0.3558],\n",
            "        [0.3198, 0.3143, 0.3658],\n",
            "        [0.2097, 0.4412, 0.3491],\n",
            "        [0.5917, 0.2403, 0.1680],\n",
            "        [0.1816, 0.3912, 0.4272]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 1, 2, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 1, 1, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/63 [00:10<00:31,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3209, 0.4874, 0.1917],\n",
            "        [0.2017, 0.3546, 0.4437],\n",
            "        [0.3158, 0.3458, 0.3384],\n",
            "        [0.1405, 0.4934, 0.3661],\n",
            "        [0.8101, 0.0659, 0.1240],\n",
            "        [0.3192, 0.2433, 0.4375],\n",
            "        [0.1133, 0.4359, 0.4508],\n",
            "        [0.2539, 0.2532, 0.4929]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3209, 0.4874, 0.1917],\n",
            "        [0.2017, 0.3546, 0.4437],\n",
            "        [0.3158, 0.3458, 0.3384],\n",
            "        [0.1405, 0.4934, 0.3661],\n",
            "        [0.8101, 0.0659, 0.1240],\n",
            "        [0.3192, 0.2433, 0.4375],\n",
            "        [0.1133, 0.4359, 0.4508],\n",
            "        [0.2539, 0.2532, 0.4929]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 0, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 2, 0, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/63 [00:11<00:30,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7781, 0.0730, 0.1488],\n",
            "        [0.4800, 0.2399, 0.2801],\n",
            "        [0.6321, 0.1235, 0.2444],\n",
            "        [0.5768, 0.0824, 0.3408],\n",
            "        [0.1802, 0.3501, 0.4696],\n",
            "        [0.1319, 0.5690, 0.2991],\n",
            "        [0.3369, 0.4234, 0.2397],\n",
            "        [0.2533, 0.3717, 0.3750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7781, 0.0730, 0.1488],\n",
            "        [0.4800, 0.2399, 0.2801],\n",
            "        [0.6321, 0.1235, 0.2444],\n",
            "        [0.5768, 0.0824, 0.3408],\n",
            "        [0.1802, 0.3501, 0.4696],\n",
            "        [0.1319, 0.5690, 0.2991],\n",
            "        [0.3369, 0.4234, 0.2397],\n",
            "        [0.2533, 0.3717, 0.3750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 2, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 0, 2, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 18/63 [00:12<00:30,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2151, 0.4327, 0.3522],\n",
            "        [0.3918, 0.2807, 0.3275],\n",
            "        [0.3811, 0.2394, 0.3794],\n",
            "        [0.5057, 0.1209, 0.3734],\n",
            "        [0.4928, 0.2455, 0.2617],\n",
            "        [0.3915, 0.1747, 0.4338],\n",
            "        [0.5307, 0.1673, 0.3020],\n",
            "        [0.2875, 0.3466, 0.3659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2151, 0.4327, 0.3522],\n",
            "        [0.3918, 0.2807, 0.3275],\n",
            "        [0.3811, 0.2394, 0.3794],\n",
            "        [0.5057, 0.1209, 0.3734],\n",
            "        [0.4928, 0.2455, 0.2617],\n",
            "        [0.3915, 0.1747, 0.4338],\n",
            "        [0.5307, 0.1673, 0.3020],\n",
            "        [0.2875, 0.3466, 0.3659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 0, 1, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 19/63 [00:12<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7849, 0.1115, 0.1036],\n",
            "        [0.3795, 0.3852, 0.2353],\n",
            "        [0.3778, 0.2567, 0.3655],\n",
            "        [0.2035, 0.2537, 0.5428],\n",
            "        [0.5545, 0.2403, 0.2052],\n",
            "        [0.3634, 0.3269, 0.3098],\n",
            "        [0.1994, 0.2345, 0.5661],\n",
            "        [0.6507, 0.1459, 0.2033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7849, 0.1115, 0.1036],\n",
            "        [0.3795, 0.3852, 0.2353],\n",
            "        [0.3778, 0.2567, 0.3655],\n",
            "        [0.2035, 0.2537, 0.5428],\n",
            "        [0.5545, 0.2403, 0.2052],\n",
            "        [0.3634, 0.3269, 0.3098],\n",
            "        [0.1994, 0.2345, 0.5661],\n",
            "        [0.6507, 0.1459, 0.2033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 0, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 1, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 20/63 [00:13<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4424, 0.1383, 0.4193],\n",
            "        [0.0903, 0.4407, 0.4690],\n",
            "        [0.5837, 0.1956, 0.2207],\n",
            "        [0.3992, 0.0876, 0.5132],\n",
            "        [0.4431, 0.3388, 0.2181],\n",
            "        [0.7578, 0.1064, 0.1359],\n",
            "        [0.7397, 0.0778, 0.1825],\n",
            "        [0.1595, 0.4595, 0.3810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4424, 0.1383, 0.4193],\n",
            "        [0.0903, 0.4407, 0.4690],\n",
            "        [0.5837, 0.1956, 0.2207],\n",
            "        [0.3992, 0.0876, 0.5132],\n",
            "        [0.4431, 0.3388, 0.2181],\n",
            "        [0.7578, 0.1064, 0.1359],\n",
            "        [0.7397, 0.0778, 0.1825],\n",
            "        [0.1595, 0.4595, 0.3810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 2, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 2, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/63 [00:14<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2066, 0.3292, 0.4642],\n",
            "        [0.6183, 0.0655, 0.3162],\n",
            "        [0.2393, 0.4078, 0.3529],\n",
            "        [0.3610, 0.3632, 0.2757],\n",
            "        [0.0556, 0.4096, 0.5349],\n",
            "        [0.4992, 0.3534, 0.1474],\n",
            "        [0.8687, 0.0378, 0.0935],\n",
            "        [0.4986, 0.1669, 0.3346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2066, 0.3292, 0.4642],\n",
            "        [0.6183, 0.0655, 0.3162],\n",
            "        [0.2393, 0.4078, 0.3529],\n",
            "        [0.3610, 0.3632, 0.2757],\n",
            "        [0.0556, 0.4096, 0.5349],\n",
            "        [0.4992, 0.3534, 0.1474],\n",
            "        [0.8687, 0.0378, 0.0935],\n",
            "        [0.4986, 0.1669, 0.3346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 1, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 2, 2, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 22/63 [00:14<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7121, 0.1095, 0.1784],\n",
            "        [0.1103, 0.5992, 0.2905],\n",
            "        [0.7611, 0.1223, 0.1166],\n",
            "        [0.7899, 0.0570, 0.1531],\n",
            "        [0.8239, 0.0700, 0.1060],\n",
            "        [0.1213, 0.5025, 0.3762],\n",
            "        [0.8102, 0.0557, 0.1341],\n",
            "        [0.1590, 0.2476, 0.5935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7121, 0.1095, 0.1784],\n",
            "        [0.1103, 0.5992, 0.2905],\n",
            "        [0.7611, 0.1223, 0.1166],\n",
            "        [0.7899, 0.0570, 0.1531],\n",
            "        [0.8239, 0.0700, 0.1060],\n",
            "        [0.1213, 0.5025, 0.3762],\n",
            "        [0.8102, 0.0557, 0.1341],\n",
            "        [0.1590, 0.2476, 0.5935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 0, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 23/63 [00:15<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5481, 0.1520, 0.2999],\n",
            "        [0.3007, 0.3424, 0.3569],\n",
            "        [0.6976, 0.1390, 0.1633],\n",
            "        [0.6694, 0.0883, 0.2423],\n",
            "        [0.2631, 0.5535, 0.1834],\n",
            "        [0.7664, 0.0494, 0.1841],\n",
            "        [0.1823, 0.4869, 0.3308],\n",
            "        [0.7077, 0.0630, 0.2293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5481, 0.1520, 0.2999],\n",
            "        [0.3007, 0.3424, 0.3569],\n",
            "        [0.6976, 0.1390, 0.1633],\n",
            "        [0.6694, 0.0883, 0.2423],\n",
            "        [0.2631, 0.5535, 0.1834],\n",
            "        [0.7664, 0.0494, 0.1841],\n",
            "        [0.1823, 0.4869, 0.3308],\n",
            "        [0.7077, 0.0630, 0.2293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 0, 1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/63 [00:16<00:26,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3698, 0.2880, 0.3421],\n",
            "        [0.3796, 0.3881, 0.2323],\n",
            "        [0.8692, 0.0469, 0.0839],\n",
            "        [0.1411, 0.5036, 0.3553],\n",
            "        [0.4498, 0.2861, 0.2641],\n",
            "        [0.3157, 0.3285, 0.3558],\n",
            "        [0.2344, 0.5636, 0.2019],\n",
            "        [0.8604, 0.0579, 0.0817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3698, 0.2880, 0.3421],\n",
            "        [0.3796, 0.3881, 0.2323],\n",
            "        [0.8692, 0.0469, 0.0839],\n",
            "        [0.1411, 0.5036, 0.3553],\n",
            "        [0.4498, 0.2861, 0.2641],\n",
            "        [0.3157, 0.3285, 0.3558],\n",
            "        [0.2344, 0.5636, 0.2019],\n",
            "        [0.8604, 0.0579, 0.0817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 1, 0, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 1, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 25/63 [00:16<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0952, 0.6615, 0.2434],\n",
            "        [0.5002, 0.1105, 0.3893],\n",
            "        [0.1334, 0.5074, 0.3592],\n",
            "        [0.2129, 0.3013, 0.4858],\n",
            "        [0.1395, 0.3443, 0.5162],\n",
            "        [0.7245, 0.1116, 0.1639],\n",
            "        [0.2021, 0.4012, 0.3966],\n",
            "        [0.5880, 0.2017, 0.2102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0952, 0.6615, 0.2434],\n",
            "        [0.5002, 0.1105, 0.3893],\n",
            "        [0.1334, 0.5074, 0.3592],\n",
            "        [0.2129, 0.3013, 0.4858],\n",
            "        [0.1395, 0.3443, 0.5162],\n",
            "        [0.7245, 0.1116, 0.1639],\n",
            "        [0.2021, 0.4012, 0.3966],\n",
            "        [0.5880, 0.2017, 0.2102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 2, 2, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 1, 2, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 26/63 [00:17<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2588, 0.5023, 0.2389],\n",
            "        [0.2083, 0.5236, 0.2681],\n",
            "        [0.3735, 0.2958, 0.3307],\n",
            "        [0.3215, 0.3218, 0.3567],\n",
            "        [0.3137, 0.4348, 0.2515],\n",
            "        [0.0628, 0.6778, 0.2594],\n",
            "        [0.8089, 0.1178, 0.0733],\n",
            "        [0.1940, 0.3288, 0.4772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2588, 0.5023, 0.2389],\n",
            "        [0.2083, 0.5236, 0.2681],\n",
            "        [0.3735, 0.2958, 0.3307],\n",
            "        [0.3215, 0.3218, 0.3567],\n",
            "        [0.3137, 0.4348, 0.2515],\n",
            "        [0.0628, 0.6778, 0.2594],\n",
            "        [0.8089, 0.1178, 0.0733],\n",
            "        [0.1940, 0.3288, 0.4772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 2, 1, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 1, 2, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 27/63 [00:18<00:24,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8027, 0.0888, 0.1085],\n",
            "        [0.1504, 0.4966, 0.3530],\n",
            "        [0.2278, 0.2445, 0.5277],\n",
            "        [0.4075, 0.2865, 0.3060],\n",
            "        [0.9177, 0.0417, 0.0406],\n",
            "        [0.1679, 0.4791, 0.3530],\n",
            "        [0.1544, 0.1890, 0.6566],\n",
            "        [0.7626, 0.1342, 0.1032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8027, 0.0888, 0.1085],\n",
            "        [0.1504, 0.4966, 0.3530],\n",
            "        [0.2278, 0.2445, 0.5277],\n",
            "        [0.4075, 0.2865, 0.3060],\n",
            "        [0.9177, 0.0417, 0.0406],\n",
            "        [0.1679, 0.4791, 0.3530],\n",
            "        [0.1544, 0.1890, 0.6566],\n",
            "        [0.7626, 0.1342, 0.1032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 1, 0, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/63 [00:18<00:23,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1028, 0.6624, 0.2348],\n",
            "        [0.4741, 0.1924, 0.3335],\n",
            "        [0.1071, 0.5514, 0.3415],\n",
            "        [0.5261, 0.3277, 0.1462],\n",
            "        [0.0795, 0.6909, 0.2296],\n",
            "        [0.8842, 0.0605, 0.0553],\n",
            "        [0.0906, 0.5834, 0.3260],\n",
            "        [0.4597, 0.3253, 0.2151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1028, 0.6624, 0.2348],\n",
            "        [0.4741, 0.1924, 0.3335],\n",
            "        [0.1071, 0.5514, 0.3415],\n",
            "        [0.5261, 0.3277, 0.1462],\n",
            "        [0.0795, 0.6909, 0.2296],\n",
            "        [0.8842, 0.0605, 0.0553],\n",
            "        [0.0906, 0.5834, 0.3260],\n",
            "        [0.4597, 0.3253, 0.2151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 29/63 [00:19<00:23,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9021, 0.0516, 0.0463],\n",
            "        [0.2456, 0.5095, 0.2449],\n",
            "        [0.1562, 0.5746, 0.2692],\n",
            "        [0.1518, 0.5714, 0.2768],\n",
            "        [0.1617, 0.2991, 0.5392],\n",
            "        [0.0588, 0.4164, 0.5248],\n",
            "        [0.7292, 0.0728, 0.1980],\n",
            "        [0.1126, 0.7341, 0.1533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9021, 0.0516, 0.0463],\n",
            "        [0.2456, 0.5095, 0.2449],\n",
            "        [0.1562, 0.5746, 0.2692],\n",
            "        [0.1518, 0.5714, 0.2768],\n",
            "        [0.1617, 0.2991, 0.5392],\n",
            "        [0.0588, 0.4164, 0.5248],\n",
            "        [0.7292, 0.0728, 0.1980],\n",
            "        [0.1126, 0.7341, 0.1533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 1, 2, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 1, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 30/63 [00:20<00:22,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0831, 0.5863, 0.3307],\n",
            "        [0.3321, 0.2030, 0.4649],\n",
            "        [0.7983, 0.0967, 0.1050],\n",
            "        [0.4798, 0.1601, 0.3601],\n",
            "        [0.1232, 0.6310, 0.2458],\n",
            "        [0.1382, 0.5711, 0.2907],\n",
            "        [0.7852, 0.1184, 0.0964],\n",
            "        [0.0712, 0.7555, 0.1733]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0831, 0.5863, 0.3307],\n",
            "        [0.3321, 0.2030, 0.4649],\n",
            "        [0.7983, 0.0967, 0.1050],\n",
            "        [0.4798, 0.1601, 0.3601],\n",
            "        [0.1232, 0.6310, 0.2458],\n",
            "        [0.1382, 0.5711, 0.2907],\n",
            "        [0.7852, 0.1184, 0.0964],\n",
            "        [0.0712, 0.7555, 0.1733]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 31/63 [00:20<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5409, 0.3346, 0.1245],\n",
            "        [0.2102, 0.4441, 0.3456],\n",
            "        [0.1370, 0.5200, 0.3430],\n",
            "        [0.1881, 0.3319, 0.4800],\n",
            "        [0.5071, 0.3103, 0.1826],\n",
            "        [0.3617, 0.4084, 0.2299],\n",
            "        [0.3871, 0.3503, 0.2626],\n",
            "        [0.3670, 0.4950, 0.1380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5409, 0.3346, 0.1245],\n",
            "        [0.2102, 0.4441, 0.3456],\n",
            "        [0.1370, 0.5200, 0.3430],\n",
            "        [0.1881, 0.3319, 0.4800],\n",
            "        [0.5071, 0.3103, 0.1826],\n",
            "        [0.3617, 0.4084, 0.2299],\n",
            "        [0.3871, 0.3503, 0.2626],\n",
            "        [0.3670, 0.4950, 0.1380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 2, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 2, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 32/63 [00:21<00:21,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7424, 0.1046, 0.1530],\n",
            "        [0.8419, 0.0789, 0.0792],\n",
            "        [0.5534, 0.2112, 0.2353],\n",
            "        [0.2432, 0.4547, 0.3021],\n",
            "        [0.1180, 0.4494, 0.4326],\n",
            "        [0.0490, 0.7132, 0.2378],\n",
            "        [0.5426, 0.1635, 0.2939],\n",
            "        [0.2429, 0.4591, 0.2981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7424, 0.1046, 0.1530],\n",
            "        [0.8419, 0.0789, 0.0792],\n",
            "        [0.5534, 0.2112, 0.2353],\n",
            "        [0.2432, 0.4547, 0.3021],\n",
            "        [0.1180, 0.4494, 0.4326],\n",
            "        [0.0490, 0.7132, 0.2378],\n",
            "        [0.5426, 0.1635, 0.2939],\n",
            "        [0.2429, 0.4591, 0.2981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 0, 2, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/63 [00:22<00:20,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6067, 0.1198, 0.2735],\n",
            "        [0.7230, 0.1529, 0.1241],\n",
            "        [0.2625, 0.2601, 0.4774],\n",
            "        [0.8355, 0.0817, 0.0827],\n",
            "        [0.0750, 0.7084, 0.2166],\n",
            "        [0.3493, 0.3090, 0.3417],\n",
            "        [0.1362, 0.5825, 0.2813],\n",
            "        [0.2019, 0.4409, 0.3572]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6067, 0.1198, 0.2735],\n",
            "        [0.7230, 0.1529, 0.1241],\n",
            "        [0.2625, 0.2601, 0.4774],\n",
            "        [0.8355, 0.0817, 0.0827],\n",
            "        [0.0750, 0.7084, 0.2166],\n",
            "        [0.3493, 0.3090, 0.3417],\n",
            "        [0.1362, 0.5825, 0.2813],\n",
            "        [0.2019, 0.4409, 0.3572]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 1, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 0, 1, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 34/63 [00:23<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9315, 0.0392, 0.0293],\n",
            "        [0.3670, 0.4012, 0.2318],\n",
            "        [0.2717, 0.3109, 0.4174],\n",
            "        [0.1445, 0.4712, 0.3843],\n",
            "        [0.0865, 0.4377, 0.4758],\n",
            "        [0.6065, 0.1322, 0.2614],\n",
            "        [0.8290, 0.0676, 0.1034],\n",
            "        [0.1110, 0.6242, 0.2648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9315, 0.0392, 0.0293],\n",
            "        [0.3670, 0.4012, 0.2318],\n",
            "        [0.2717, 0.3109, 0.4174],\n",
            "        [0.1445, 0.4712, 0.3843],\n",
            "        [0.0865, 0.4377, 0.4758],\n",
            "        [0.6065, 0.1322, 0.2614],\n",
            "        [0.8290, 0.0676, 0.1034],\n",
            "        [0.1110, 0.6242, 0.2648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 1, 2, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 1, 2, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 35/63 [00:23<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2452, 0.5357, 0.2191],\n",
            "        [0.7732, 0.0985, 0.1283],\n",
            "        [0.6166, 0.1617, 0.2217],\n",
            "        [0.7912, 0.0555, 0.1533],\n",
            "        [0.7780, 0.0871, 0.1349],\n",
            "        [0.5257, 0.1304, 0.3439],\n",
            "        [0.5684, 0.2103, 0.2213],\n",
            "        [0.2010, 0.5896, 0.2094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2452, 0.5357, 0.2191],\n",
            "        [0.7732, 0.0985, 0.1283],\n",
            "        [0.6166, 0.1617, 0.2217],\n",
            "        [0.7912, 0.0555, 0.1533],\n",
            "        [0.7780, 0.0871, 0.1349],\n",
            "        [0.5257, 0.1304, 0.3439],\n",
            "        [0.5684, 0.2103, 0.2213],\n",
            "        [0.2010, 0.5896, 0.2094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 0, 0, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 36/63 [00:24<00:18,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0879, 0.5001, 0.4120],\n",
            "        [0.3798, 0.2051, 0.4150],\n",
            "        [0.5137, 0.2012, 0.2852],\n",
            "        [0.3303, 0.3428, 0.3269],\n",
            "        [0.3155, 0.2060, 0.4785],\n",
            "        [0.6493, 0.1823, 0.1684],\n",
            "        [0.7893, 0.1103, 0.1004],\n",
            "        [0.3473, 0.2840, 0.3688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0879, 0.5001, 0.4120],\n",
            "        [0.3798, 0.2051, 0.4150],\n",
            "        [0.5137, 0.2012, 0.2852],\n",
            "        [0.3303, 0.3428, 0.3269],\n",
            "        [0.3155, 0.2060, 0.4785],\n",
            "        [0.6493, 0.1823, 0.1684],\n",
            "        [0.7893, 0.1103, 0.1004],\n",
            "        [0.3473, 0.2840, 0.3688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 1, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 1, 1, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 37/63 [00:25<00:17,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8364, 0.0861, 0.0775],\n",
            "        [0.1288, 0.6713, 0.1999],\n",
            "        [0.6578, 0.0869, 0.2552],\n",
            "        [0.2077, 0.3721, 0.4201],\n",
            "        [0.1186, 0.6304, 0.2510],\n",
            "        [0.8407, 0.0467, 0.1126],\n",
            "        [0.0702, 0.6403, 0.2894],\n",
            "        [0.1507, 0.6988, 0.1505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8364, 0.0861, 0.0775],\n",
            "        [0.1288, 0.6713, 0.1999],\n",
            "        [0.6578, 0.0869, 0.2552],\n",
            "        [0.2077, 0.3721, 0.4201],\n",
            "        [0.1186, 0.6304, 0.2510],\n",
            "        [0.8407, 0.0467, 0.1126],\n",
            "        [0.0702, 0.6403, 0.2894],\n",
            "        [0.1507, 0.6988, 0.1505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 1, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 1, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 38/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6342, 0.2028, 0.1629],\n",
            "        [0.5960, 0.2668, 0.1372],\n",
            "        [0.0738, 0.4627, 0.4636],\n",
            "        [0.0750, 0.5977, 0.3273],\n",
            "        [0.1508, 0.3906, 0.4586],\n",
            "        [0.3584, 0.1189, 0.5227],\n",
            "        [0.7725, 0.1440, 0.0835],\n",
            "        [0.6315, 0.1034, 0.2651]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6342, 0.2028, 0.1629],\n",
            "        [0.5960, 0.2668, 0.1372],\n",
            "        [0.0738, 0.4627, 0.4636],\n",
            "        [0.0750, 0.5977, 0.3273],\n",
            "        [0.1508, 0.3906, 0.4586],\n",
            "        [0.3584, 0.1189, 0.5227],\n",
            "        [0.7725, 0.1440, 0.0835],\n",
            "        [0.6315, 0.1034, 0.2651]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 1, 2, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 1, 2, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 39/63 [00:26<00:16,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5364, 0.2817, 0.1819],\n",
            "        [0.4204, 0.2744, 0.3052],\n",
            "        [0.1111, 0.5561, 0.3328],\n",
            "        [0.9179, 0.0413, 0.0408],\n",
            "        [0.5425, 0.2523, 0.2051],\n",
            "        [0.1301, 0.5800, 0.2899],\n",
            "        [0.4050, 0.4202, 0.1748],\n",
            "        [0.0899, 0.3504, 0.5597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5364, 0.2817, 0.1819],\n",
            "        [0.4204, 0.2744, 0.3052],\n",
            "        [0.1111, 0.5561, 0.3328],\n",
            "        [0.9179, 0.0413, 0.0408],\n",
            "        [0.5425, 0.2523, 0.2051],\n",
            "        [0.1301, 0.5800, 0.2899],\n",
            "        [0.4050, 0.4202, 0.1748],\n",
            "        [0.0899, 0.3504, 0.5597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 0, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 0, 0, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 40/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8029, 0.0513, 0.1458],\n",
            "        [0.6138, 0.2042, 0.1820],\n",
            "        [0.1089, 0.6699, 0.2212],\n",
            "        [0.8126, 0.1044, 0.0830],\n",
            "        [0.3721, 0.2755, 0.3524],\n",
            "        [0.8755, 0.0745, 0.0500],\n",
            "        [0.4437, 0.2503, 0.3060],\n",
            "        [0.8341, 0.0634, 0.1025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8029, 0.0513, 0.1458],\n",
            "        [0.6138, 0.2042, 0.1820],\n",
            "        [0.1089, 0.6699, 0.2212],\n",
            "        [0.8126, 0.1044, 0.0830],\n",
            "        [0.3721, 0.2755, 0.3524],\n",
            "        [0.8755, 0.0745, 0.0500],\n",
            "        [0.4437, 0.2503, 0.3060],\n",
            "        [0.8341, 0.0634, 0.1025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 41/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7250, 0.1442, 0.1308],\n",
            "        [0.6888, 0.0648, 0.2465],\n",
            "        [0.3524, 0.3162, 0.3314],\n",
            "        [0.6302, 0.2222, 0.1476],\n",
            "        [0.0852, 0.4627, 0.4521],\n",
            "        [0.1594, 0.6717, 0.1689],\n",
            "        [0.9504, 0.0232, 0.0264],\n",
            "        [0.2177, 0.4627, 0.3196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7250, 0.1442, 0.1308],\n",
            "        [0.6888, 0.0648, 0.2465],\n",
            "        [0.3524, 0.3162, 0.3314],\n",
            "        [0.6302, 0.2222, 0.1476],\n",
            "        [0.0852, 0.4627, 0.4521],\n",
            "        [0.1594, 0.6717, 0.1689],\n",
            "        [0.9504, 0.0232, 0.0264],\n",
            "        [0.2177, 0.4627, 0.3196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 0, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 42/63 [00:28<00:14,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5442, 0.3009, 0.1549],\n",
            "        [0.1284, 0.2433, 0.6284],\n",
            "        [0.4193, 0.3312, 0.2495],\n",
            "        [0.0995, 0.7327, 0.1678],\n",
            "        [0.8810, 0.0473, 0.0717],\n",
            "        [0.6971, 0.0739, 0.2290],\n",
            "        [0.5643, 0.1910, 0.2447],\n",
            "        [0.0511, 0.7472, 0.2016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5442, 0.3009, 0.1549],\n",
            "        [0.1284, 0.2433, 0.6284],\n",
            "        [0.4193, 0.3312, 0.2495],\n",
            "        [0.0995, 0.7327, 0.1678],\n",
            "        [0.8810, 0.0473, 0.0717],\n",
            "        [0.6971, 0.0739, 0.2290],\n",
            "        [0.5643, 0.1910, 0.2447],\n",
            "        [0.0511, 0.7472, 0.2016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 0, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 43/63 [00:29<00:13,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8674, 0.0819, 0.0507],\n",
            "        [0.8680, 0.0557, 0.0762],\n",
            "        [0.2252, 0.3402, 0.4346],\n",
            "        [0.4227, 0.3398, 0.2375],\n",
            "        [0.0950, 0.5263, 0.3787],\n",
            "        [0.6283, 0.1834, 0.1883],\n",
            "        [0.7360, 0.1246, 0.1393],\n",
            "        [0.5149, 0.3018, 0.1834]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8674, 0.0819, 0.0507],\n",
            "        [0.8680, 0.0557, 0.0762],\n",
            "        [0.2252, 0.3402, 0.4346],\n",
            "        [0.4227, 0.3398, 0.2375],\n",
            "        [0.0950, 0.5263, 0.3787],\n",
            "        [0.6283, 0.1834, 0.1883],\n",
            "        [0.7360, 0.1246, 0.1393],\n",
            "        [0.5149, 0.3018, 0.1834]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 0, 1, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 44/63 [00:29<00:13,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1799, 0.5186, 0.3015],\n",
            "        [0.8617, 0.0479, 0.0904],\n",
            "        [0.8022, 0.0533, 0.1444],\n",
            "        [0.9253, 0.0384, 0.0363],\n",
            "        [0.8810, 0.0680, 0.0510],\n",
            "        [0.8739, 0.0495, 0.0766],\n",
            "        [0.3972, 0.2720, 0.3308],\n",
            "        [0.2225, 0.4951, 0.2824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1799, 0.5186, 0.3015],\n",
            "        [0.8617, 0.0479, 0.0904],\n",
            "        [0.8022, 0.0533, 0.1444],\n",
            "        [0.9253, 0.0384, 0.0363],\n",
            "        [0.8810, 0.0680, 0.0510],\n",
            "        [0.8739, 0.0495, 0.0766],\n",
            "        [0.3972, 0.2720, 0.3308],\n",
            "        [0.2225, 0.4951, 0.2824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 0, 1, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 45/63 [00:30<00:12,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9585, 0.0172, 0.0243],\n",
            "        [0.8670, 0.0480, 0.0850],\n",
            "        [0.9467, 0.0184, 0.0349],\n",
            "        [0.0809, 0.7836, 0.1356],\n",
            "        [0.1742, 0.5589, 0.2669],\n",
            "        [0.3237, 0.4379, 0.2383],\n",
            "        [0.8965, 0.0366, 0.0670],\n",
            "        [0.6137, 0.1197, 0.2666]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9585, 0.0172, 0.0243],\n",
            "        [0.8670, 0.0480, 0.0850],\n",
            "        [0.9467, 0.0184, 0.0349],\n",
            "        [0.0809, 0.7836, 0.1356],\n",
            "        [0.1742, 0.5589, 0.2669],\n",
            "        [0.3237, 0.4379, 0.2383],\n",
            "        [0.8965, 0.0366, 0.0670],\n",
            "        [0.6137, 0.1197, 0.2666]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 1, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 46/63 [00:31<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8652, 0.0400, 0.0948],\n",
            "        [0.3401, 0.3584, 0.3014],\n",
            "        [0.8276, 0.0573, 0.1151],\n",
            "        [0.0896, 0.7903, 0.1201],\n",
            "        [0.9098, 0.0449, 0.0453],\n",
            "        [0.8824, 0.0335, 0.0841],\n",
            "        [0.5735, 0.1838, 0.2426],\n",
            "        [0.5090, 0.2253, 0.2657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8652, 0.0400, 0.0948],\n",
            "        [0.3401, 0.3584, 0.3014],\n",
            "        [0.8276, 0.0573, 0.1151],\n",
            "        [0.0896, 0.7903, 0.1201],\n",
            "        [0.9098, 0.0449, 0.0453],\n",
            "        [0.8824, 0.0335, 0.0841],\n",
            "        [0.5735, 0.1838, 0.2426],\n",
            "        [0.5090, 0.2253, 0.2657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 1, 2, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 47/63 [00:31<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6439, 0.1311, 0.2250],\n",
            "        [0.8579, 0.0524, 0.0897],\n",
            "        [0.8536, 0.0454, 0.1010],\n",
            "        [0.8801, 0.0381, 0.0818],\n",
            "        [0.3267, 0.2958, 0.3775],\n",
            "        [0.5510, 0.2051, 0.2440],\n",
            "        [0.2874, 0.4680, 0.2446],\n",
            "        [0.1864, 0.1673, 0.6464]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6439, 0.1311, 0.2250],\n",
            "        [0.8579, 0.0524, 0.0897],\n",
            "        [0.8536, 0.0454, 0.1010],\n",
            "        [0.8801, 0.0381, 0.0818],\n",
            "        [0.3267, 0.2958, 0.3775],\n",
            "        [0.5510, 0.2051, 0.2440],\n",
            "        [0.2874, 0.4680, 0.2446],\n",
            "        [0.1864, 0.1673, 0.6464]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 0, 1, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 48/63 [00:32<00:10,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0524, 0.6815, 0.2661],\n",
            "        [0.9497, 0.0152, 0.0351],\n",
            "        [0.8081, 0.0705, 0.1213],\n",
            "        [0.8379, 0.0594, 0.1027],\n",
            "        [0.1118, 0.6388, 0.2494],\n",
            "        [0.4980, 0.3156, 0.1863],\n",
            "        [0.5389, 0.2326, 0.2286],\n",
            "        [0.7886, 0.0655, 0.1458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0524, 0.6815, 0.2661],\n",
            "        [0.9497, 0.0152, 0.0351],\n",
            "        [0.8081, 0.0705, 0.1213],\n",
            "        [0.8379, 0.0594, 0.1027],\n",
            "        [0.1118, 0.6388, 0.2494],\n",
            "        [0.4980, 0.3156, 0.1863],\n",
            "        [0.5389, 0.2326, 0.2286],\n",
            "        [0.7886, 0.0655, 0.1458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 2, 1, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 49/63 [00:33<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3818, 0.4433, 0.1749],\n",
            "        [0.2899, 0.3602, 0.3499],\n",
            "        [0.7921, 0.0541, 0.1539],\n",
            "        [0.9027, 0.0238, 0.0735],\n",
            "        [0.0859, 0.7268, 0.1873],\n",
            "        [0.8308, 0.0481, 0.1211],\n",
            "        [0.2678, 0.4027, 0.3296],\n",
            "        [0.8115, 0.0631, 0.1255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3818, 0.4433, 0.1749],\n",
            "        [0.2899, 0.3602, 0.3499],\n",
            "        [0.7921, 0.0541, 0.1539],\n",
            "        [0.9027, 0.0238, 0.0735],\n",
            "        [0.0859, 0.7268, 0.1873],\n",
            "        [0.8308, 0.0481, 0.1211],\n",
            "        [0.2678, 0.4027, 0.3296],\n",
            "        [0.8115, 0.0631, 0.1255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 50/63 [00:34<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8955, 0.0538, 0.0507],\n",
            "        [0.1019, 0.4275, 0.4706],\n",
            "        [0.9230, 0.0393, 0.0377],\n",
            "        [0.7897, 0.0899, 0.1203],\n",
            "        [0.1685, 0.4906, 0.3409],\n",
            "        [0.1072, 0.4428, 0.4500],\n",
            "        [0.9167, 0.0370, 0.0463],\n",
            "        [0.0942, 0.4477, 0.4581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8955, 0.0538, 0.0507],\n",
            "        [0.1019, 0.4275, 0.4706],\n",
            "        [0.9230, 0.0393, 0.0377],\n",
            "        [0.7897, 0.0899, 0.1203],\n",
            "        [0.1685, 0.4906, 0.3409],\n",
            "        [0.1072, 0.4428, 0.4500],\n",
            "        [0.9167, 0.0370, 0.0463],\n",
            "        [0.0942, 0.4477, 0.4581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 1, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 2, 1, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 51/63 [00:34<00:08,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3894, 0.1751, 0.4354],\n",
            "        [0.6369, 0.2476, 0.1154],\n",
            "        [0.0464, 0.8236, 0.1300],\n",
            "        [0.1389, 0.6644, 0.1967],\n",
            "        [0.7950, 0.0698, 0.1352],\n",
            "        [0.3402, 0.2866, 0.3732],\n",
            "        [0.0999, 0.4543, 0.4457],\n",
            "        [0.5754, 0.1252, 0.2994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3894, 0.1751, 0.4354],\n",
            "        [0.6369, 0.2476, 0.1154],\n",
            "        [0.0464, 0.8236, 0.1300],\n",
            "        [0.1389, 0.6644, 0.1967],\n",
            "        [0.7950, 0.0698, 0.1352],\n",
            "        [0.3402, 0.2866, 0.3732],\n",
            "        [0.0999, 0.4543, 0.4457],\n",
            "        [0.5754, 0.1252, 0.2994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 1, 0, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 0, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 52/63 [00:35<00:07,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8908, 0.0550, 0.0542],\n",
            "        [0.2325, 0.4873, 0.2802],\n",
            "        [0.3206, 0.2406, 0.4389],\n",
            "        [0.1592, 0.2898, 0.5509],\n",
            "        [0.2657, 0.6124, 0.1218],\n",
            "        [0.9290, 0.0343, 0.0367],\n",
            "        [0.8881, 0.0477, 0.0642],\n",
            "        [0.0631, 0.5941, 0.3427]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8908, 0.0550, 0.0542],\n",
            "        [0.2325, 0.4873, 0.2802],\n",
            "        [0.3206, 0.2406, 0.4389],\n",
            "        [0.1592, 0.2898, 0.5509],\n",
            "        [0.2657, 0.6124, 0.1218],\n",
            "        [0.9290, 0.0343, 0.0367],\n",
            "        [0.8881, 0.0477, 0.0642],\n",
            "        [0.0631, 0.5941, 0.3427]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 2, 1, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 1, 1, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 53/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0308, 0.6682, 0.3010],\n",
            "        [0.2718, 0.2426, 0.4855],\n",
            "        [0.6874, 0.2004, 0.1122],\n",
            "        [0.8574, 0.0291, 0.1135],\n",
            "        [0.1789, 0.4257, 0.3954],\n",
            "        [0.9138, 0.0477, 0.0386],\n",
            "        [0.8633, 0.0572, 0.0794],\n",
            "        [0.6063, 0.1586, 0.2351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0308, 0.6682, 0.3010],\n",
            "        [0.2718, 0.2426, 0.4855],\n",
            "        [0.6874, 0.2004, 0.1122],\n",
            "        [0.8574, 0.0291, 0.1135],\n",
            "        [0.1789, 0.4257, 0.3954],\n",
            "        [0.9138, 0.0477, 0.0386],\n",
            "        [0.8633, 0.0572, 0.0794],\n",
            "        [0.6063, 0.1586, 0.2351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 2, 2, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 54/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1756, 0.4941, 0.3302],\n",
            "        [0.0369, 0.8303, 0.1328],\n",
            "        [0.0808, 0.6964, 0.2228],\n",
            "        [0.0805, 0.7449, 0.1745],\n",
            "        [0.0650, 0.5477, 0.3874],\n",
            "        [0.6944, 0.1693, 0.1364],\n",
            "        [0.0964, 0.5835, 0.3202],\n",
            "        [0.8357, 0.0357, 0.1285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1756, 0.4941, 0.3302],\n",
            "        [0.0369, 0.8303, 0.1328],\n",
            "        [0.0808, 0.6964, 0.2228],\n",
            "        [0.0805, 0.7449, 0.1745],\n",
            "        [0.0650, 0.5477, 0.3874],\n",
            "        [0.6944, 0.1693, 0.1364],\n",
            "        [0.0964, 0.5835, 0.3202],\n",
            "        [0.8357, 0.0357, 0.1285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 1, 1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 55/63 [00:37<00:05,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5347, 0.2267, 0.2385],\n",
            "        [0.8423, 0.0677, 0.0900],\n",
            "        [0.1975, 0.4587, 0.3438],\n",
            "        [0.9035, 0.0525, 0.0440],\n",
            "        [0.0838, 0.7078, 0.2084],\n",
            "        [0.6769, 0.1814, 0.1417],\n",
            "        [0.0315, 0.7767, 0.1918],\n",
            "        [0.0985, 0.6874, 0.2141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5347, 0.2267, 0.2385],\n",
            "        [0.8423, 0.0677, 0.0900],\n",
            "        [0.1975, 0.4587, 0.3438],\n",
            "        [0.9035, 0.0525, 0.0440],\n",
            "        [0.0838, 0.7078, 0.2084],\n",
            "        [0.6769, 0.1814, 0.1417],\n",
            "        [0.0315, 0.7767, 0.1918],\n",
            "        [0.0985, 0.6874, 0.2141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 1, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 56/63 [00:38<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5397, 0.2590, 0.2013],\n",
            "        [0.1935, 0.5252, 0.2813],\n",
            "        [0.0403, 0.8244, 0.1353],\n",
            "        [0.9073, 0.0483, 0.0444],\n",
            "        [0.0320, 0.7783, 0.1896],\n",
            "        [0.1721, 0.5414, 0.2864],\n",
            "        [0.1140, 0.5972, 0.2888],\n",
            "        [0.2642, 0.4723, 0.2635]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5397, 0.2590, 0.2013],\n",
            "        [0.1935, 0.5252, 0.2813],\n",
            "        [0.0403, 0.8244, 0.1353],\n",
            "        [0.9073, 0.0483, 0.0444],\n",
            "        [0.0320, 0.7783, 0.1896],\n",
            "        [0.1721, 0.5414, 0.2864],\n",
            "        [0.1140, 0.5972, 0.2888],\n",
            "        [0.2642, 0.4723, 0.2635]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 1, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 57/63 [00:38<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0326, 0.7210, 0.2464],\n",
            "        [0.1121, 0.6188, 0.2691],\n",
            "        [0.8271, 0.0459, 0.1270],\n",
            "        [0.0528, 0.7217, 0.2255],\n",
            "        [0.3577, 0.2420, 0.4002],\n",
            "        [0.0479, 0.6626, 0.2895],\n",
            "        [0.0654, 0.5661, 0.3685],\n",
            "        [0.1641, 0.1846, 0.6513]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0326, 0.7210, 0.2464],\n",
            "        [0.1121, 0.6188, 0.2691],\n",
            "        [0.8271, 0.0459, 0.1270],\n",
            "        [0.0528, 0.7217, 0.2255],\n",
            "        [0.3577, 0.2420, 0.4002],\n",
            "        [0.0479, 0.6626, 0.2895],\n",
            "        [0.0654, 0.5661, 0.3685],\n",
            "        [0.1641, 0.1846, 0.6513]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 2, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 2, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 58/63 [00:39<00:03,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0951, 0.6237, 0.2812],\n",
            "        [0.1198, 0.7770, 0.1032],\n",
            "        [0.7356, 0.0600, 0.2044],\n",
            "        [0.8855, 0.0468, 0.0677],\n",
            "        [0.9020, 0.0191, 0.0788],\n",
            "        [0.0539, 0.7257, 0.2204],\n",
            "        [0.0931, 0.6235, 0.2834],\n",
            "        [0.0376, 0.7826, 0.1798]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0951, 0.6237, 0.2812],\n",
            "        [0.1198, 0.7770, 0.1032],\n",
            "        [0.7356, 0.0600, 0.2044],\n",
            "        [0.8855, 0.0468, 0.0677],\n",
            "        [0.9020, 0.0191, 0.0788],\n",
            "        [0.0539, 0.7257, 0.2204],\n",
            "        [0.0931, 0.6235, 0.2834],\n",
            "        [0.0376, 0.7826, 0.1798]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 0, 0, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 59/63 [00:40<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8751, 0.0504, 0.0745],\n",
            "        [0.0205, 0.6656, 0.3139],\n",
            "        [0.6884, 0.1275, 0.1841],\n",
            "        [0.5175, 0.0809, 0.4016],\n",
            "        [0.0952, 0.3966, 0.5082],\n",
            "        [0.9134, 0.0285, 0.0580],\n",
            "        [0.5156, 0.3195, 0.1650],\n",
            "        [0.7579, 0.1044, 0.1377]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8751, 0.0504, 0.0745],\n",
            "        [0.0205, 0.6656, 0.3139],\n",
            "        [0.6884, 0.1275, 0.1841],\n",
            "        [0.5175, 0.0809, 0.4016],\n",
            "        [0.0952, 0.3966, 0.5082],\n",
            "        [0.9134, 0.0285, 0.0580],\n",
            "        [0.5156, 0.3195, 0.1650],\n",
            "        [0.7579, 0.1044, 0.1377]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 0, 1, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 60/63 [00:41<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0722, 0.7508, 0.1770],\n",
            "        [0.0851, 0.5728, 0.3421],\n",
            "        [0.1349, 0.5122, 0.3529],\n",
            "        [0.0635, 0.7729, 0.1635],\n",
            "        [0.1199, 0.5535, 0.3266],\n",
            "        [0.0258, 0.8055, 0.1687],\n",
            "        [0.4444, 0.3096, 0.2460],\n",
            "        [0.5296, 0.1119, 0.3585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0722, 0.7508, 0.1770],\n",
            "        [0.0851, 0.5728, 0.3421],\n",
            "        [0.1349, 0.5122, 0.3529],\n",
            "        [0.0635, 0.7729, 0.1635],\n",
            "        [0.1199, 0.5535, 0.3266],\n",
            "        [0.0258, 0.8055, 0.1687],\n",
            "        [0.4444, 0.3096, 0.2460],\n",
            "        [0.5296, 0.1119, 0.3585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 2, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 61/63 [00:41<00:01,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9423, 0.0335, 0.0242],\n",
            "        [0.0964, 0.6590, 0.2446],\n",
            "        [0.0763, 0.7461, 0.1776],\n",
            "        [0.0297, 0.7954, 0.1749],\n",
            "        [0.6447, 0.0619, 0.2933],\n",
            "        [0.8405, 0.0675, 0.0920],\n",
            "        [0.8838, 0.0502, 0.0660],\n",
            "        [0.9380, 0.0217, 0.0402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9423, 0.0335, 0.0242],\n",
            "        [0.0964, 0.6590, 0.2446],\n",
            "        [0.0763, 0.7461, 0.1776],\n",
            "        [0.0297, 0.7954, 0.1749],\n",
            "        [0.6447, 0.0619, 0.2933],\n",
            "        [0.8405, 0.0675, 0.0920],\n",
            "        [0.8838, 0.0502, 0.0660],\n",
            "        [0.9380, 0.0217, 0.0402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 2, 2, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 62/63 [00:42<00:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1049, 0.4065, 0.4886],\n",
            "        [0.0668, 0.6620, 0.2713],\n",
            "        [0.6024, 0.1802, 0.2174],\n",
            "        [0.0425, 0.7951, 0.1623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1049, 0.4065, 0.4886],\n",
            "        [0.0668, 0.6620, 0.2713],\n",
            "        [0.6024, 0.1802, 0.2174],\n",
            "        [0.0425, 0.7951, 0.1623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.3372, 0.1495, 0.5133],\n",
            "        [0.0349, 0.7341, 0.2310],\n",
            "        [0.8595, 0.0322, 0.1083],\n",
            "        [0.6379, 0.1526, 0.2095],\n",
            "        [0.8380, 0.0614, 0.1006],\n",
            "        [0.1653, 0.7008, 0.1340],\n",
            "        [0.1149, 0.3102, 0.5749],\n",
            "        [0.8039, 0.0590, 0.1372]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "tensor([[0.3372, 0.1495, 0.5133],\n",
            "        [0.0349, 0.7341, 0.2310],\n",
            "        [0.8595, 0.0322, 0.1083],\n",
            "        [0.6379, 0.1526, 0.2095],\n",
            "        [0.8380, 0.0614, 0.1006],\n",
            "        [0.1653, 0.7008, 0.1340],\n",
            "        [0.1149, 0.3102, 0.5749],\n",
            "        [0.8039, 0.0590, 0.1372]], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.2029, 0.2765, 0.5206],\n",
            "        [0.0755, 0.3336, 0.5909],\n",
            "        [0.0383, 0.7867, 0.1750],\n",
            "        [0.0700, 0.3495, 0.5805],\n",
            "        [0.1223, 0.2540, 0.6237],\n",
            "        [0.0347, 0.8323, 0.1330],\n",
            "        [0.8802, 0.0447, 0.0751],\n",
            "        [0.0201, 0.7552, 0.2247]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 2, 2, 1, 0, 1], device='cuda:0')\n",
            "tensor([[0.2029, 0.2765, 0.5206],\n",
            "        [0.0755, 0.3336, 0.5909],\n",
            "        [0.0383, 0.7867, 0.1750],\n",
            "        [0.0700, 0.3495, 0.5805],\n",
            "        [0.1223, 0.2540, 0.6237],\n",
            "        [0.0347, 0.8323, 0.1330],\n",
            "        [0.8802, 0.0447, 0.0751],\n",
            "        [0.0201, 0.7552, 0.2247]], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0664, 0.6471, 0.2866],\n",
            "        [0.3343, 0.1229, 0.5428],\n",
            "        [0.9315, 0.0216, 0.0468],\n",
            "        [0.0332, 0.8676, 0.0992],\n",
            "        [0.2020, 0.1968, 0.6012],\n",
            "        [0.4179, 0.0851, 0.4970],\n",
            "        [0.0251, 0.7661, 0.2088],\n",
            "        [0.9240, 0.0133, 0.0627]], device='cuda:0')\n",
            "prediction: tensor([1, 2, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "tensor([[0.0664, 0.6471, 0.2866],\n",
            "        [0.3343, 0.1229, 0.5428],\n",
            "        [0.9315, 0.0216, 0.0468],\n",
            "        [0.0332, 0.8676, 0.0992],\n",
            "        [0.2020, 0.1968, 0.6012],\n",
            "        [0.4179, 0.0851, 0.4970],\n",
            "        [0.0251, 0.7661, 0.2088],\n",
            "        [0.9240, 0.0133, 0.0627]], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0472, 0.7567, 0.1961],\n",
            "        [0.9067, 0.0489, 0.0444],\n",
            "        [0.1251, 0.4101, 0.4648],\n",
            "        [0.1576, 0.5081, 0.3343],\n",
            "        [0.0397, 0.8640, 0.0963],\n",
            "        [0.8928, 0.0373, 0.0698],\n",
            "        [0.7523, 0.0827, 0.1650],\n",
            "        [0.9381, 0.0307, 0.0312]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 1, 1, 0, 0, 0], device='cuda:0')\n",
            "tensor([[0.0472, 0.7567, 0.1961],\n",
            "        [0.9067, 0.0489, 0.0444],\n",
            "        [0.1251, 0.4101, 0.4648],\n",
            "        [0.1576, 0.5081, 0.3343],\n",
            "        [0.0397, 0.8640, 0.0963],\n",
            "        [0.8928, 0.0373, 0.0698],\n",
            "        [0.7523, 0.0827, 0.1650],\n",
            "        [0.9381, 0.0307, 0.0312]], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0508, 0.6509, 0.2983],\n",
            "        [0.1338, 0.6247, 0.2415],\n",
            "        [0.7831, 0.1105, 0.1064],\n",
            "        [0.9394, 0.0232, 0.0374],\n",
            "        [0.1060, 0.4569, 0.4371],\n",
            "        [0.9063, 0.0306, 0.0631],\n",
            "        [0.1807, 0.2186, 0.6008],\n",
            "        [0.1612, 0.1557, 0.6831]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 0, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "tensor([[0.0508, 0.6509, 0.2983],\n",
            "        [0.1338, 0.6247, 0.2415],\n",
            "        [0.7831, 0.1105, 0.1064],\n",
            "        [0.9394, 0.0232, 0.0374],\n",
            "        [0.1060, 0.4569, 0.4371],\n",
            "        [0.9063, 0.0306, 0.0631],\n",
            "        [0.1807, 0.2186, 0.6008],\n",
            "        [0.1612, 0.1557, 0.6831]], device='cuda:0')\n",
            "tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.9307, 0.0213, 0.0480],\n",
            "        [0.1126, 0.4907, 0.3967],\n",
            "        [0.7736, 0.1035, 0.1229],\n",
            "        [0.9417, 0.0228, 0.0355],\n",
            "        [0.9474, 0.0163, 0.0362],\n",
            "        [0.9310, 0.0241, 0.0449],\n",
            "        [0.8781, 0.0434, 0.0784],\n",
            "        [0.7757, 0.0817, 0.1426]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([[0.9307, 0.0213, 0.0480],\n",
            "        [0.1126, 0.4907, 0.3967],\n",
            "        [0.7736, 0.1035, 0.1229],\n",
            "        [0.9417, 0.0228, 0.0355],\n",
            "        [0.9474, 0.0163, 0.0362],\n",
            "        [0.9310, 0.0241, 0.0449],\n",
            "        [0.8781, 0.0434, 0.0784],\n",
            "        [0.7757, 0.0817, 0.1426]], device='cuda:0')\n",
            "tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0779, 0.5057, 0.4164],\n",
            "        [0.8003, 0.0892, 0.1106],\n",
            "        [0.0641, 0.3224, 0.6135],\n",
            "        [0.0745, 0.6834, 0.2422],\n",
            "        [0.0864, 0.5266, 0.3870],\n",
            "        [0.0900, 0.3848, 0.5252],\n",
            "        [0.1352, 0.3203, 0.5445],\n",
            "        [0.2364, 0.2697, 0.4940]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "tensor([[0.0779, 0.5057, 0.4164],\n",
            "        [0.8003, 0.0892, 0.1106],\n",
            "        [0.0641, 0.3224, 0.6135],\n",
            "        [0.0745, 0.6834, 0.2422],\n",
            "        [0.0864, 0.5266, 0.3870],\n",
            "        [0.0900, 0.3848, 0.5252],\n",
            "        [0.1352, 0.3203, 0.5445],\n",
            "        [0.2364, 0.2697, 0.4940]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9474, 0.0213, 0.0313],\n",
            "        [0.6269, 0.1325, 0.2406],\n",
            "        [0.6066, 0.2319, 0.1615],\n",
            "        [0.5158, 0.1843, 0.3000],\n",
            "        [0.6677, 0.1437, 0.1886],\n",
            "        [0.4887, 0.2867, 0.2246],\n",
            "        [0.8706, 0.0368, 0.0926],\n",
            "        [0.5741, 0.2820, 0.1440]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([[0.9474, 0.0213, 0.0313],\n",
            "        [0.6269, 0.1325, 0.2406],\n",
            "        [0.6066, 0.2319, 0.1615],\n",
            "        [0.5158, 0.1843, 0.3000],\n",
            "        [0.6677, 0.1437, 0.1886],\n",
            "        [0.4887, 0.2867, 0.2246],\n",
            "        [0.8706, 0.0368, 0.0926],\n",
            "        [0.5741, 0.2820, 0.1440]], device='cuda:0')\n",
            "tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.1003, 0.3380, 0.5618],\n",
            "        [0.3651, 0.3645, 0.2704],\n",
            "        [0.0767, 0.7297, 0.1936],\n",
            "        [0.6548, 0.1389, 0.2063],\n",
            "        [0.7003, 0.0551, 0.2446],\n",
            "        [0.8589, 0.0623, 0.0788],\n",
            "        [0.5952, 0.2083, 0.1965],\n",
            "        [0.3811, 0.3341, 0.2848]], device='cuda:0')\n",
            "prediction: tensor([2, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([[0.1003, 0.3380, 0.5618],\n",
            "        [0.3651, 0.3645, 0.2704],\n",
            "        [0.0767, 0.7297, 0.1936],\n",
            "        [0.6548, 0.1389, 0.2063],\n",
            "        [0.7003, 0.0551, 0.2446],\n",
            "        [0.8589, 0.0623, 0.0788],\n",
            "        [0.5952, 0.2083, 0.1965],\n",
            "        [0.3811, 0.3341, 0.2848]], device='cuda:0')\n",
            "tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.5794, 0.2914, 0.1292],\n",
            "        [0.6377, 0.0902, 0.2721],\n",
            "        [0.7214, 0.1365, 0.1421],\n",
            "        [0.1595, 0.1538, 0.6867],\n",
            "        [0.2910, 0.5438, 0.1653],\n",
            "        [0.9022, 0.0298, 0.0680],\n",
            "        [0.0564, 0.7106, 0.2330],\n",
            "        [0.8408, 0.0556, 0.1035]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "tensor([[0.5794, 0.2914, 0.1292],\n",
            "        [0.6377, 0.0902, 0.2721],\n",
            "        [0.7214, 0.1365, 0.1421],\n",
            "        [0.1595, 0.1538, 0.6867],\n",
            "        [0.2910, 0.5438, 0.1653],\n",
            "        [0.9022, 0.0298, 0.0680],\n",
            "        [0.0564, 0.7106, 0.2330],\n",
            "        [0.8408, 0.0556, 0.1035]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.9250, 0.0332, 0.0418],\n",
            "        [0.8028, 0.0991, 0.0981],\n",
            "        [0.7510, 0.1480, 0.1011],\n",
            "        [0.8626, 0.0733, 0.0642],\n",
            "        [0.8151, 0.0721, 0.1128],\n",
            "        [0.5059, 0.4221, 0.0720],\n",
            "        [0.8977, 0.0221, 0.0802],\n",
            "        [0.0506, 0.7205, 0.2289]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "tensor([[0.9250, 0.0332, 0.0418],\n",
            "        [0.8028, 0.0991, 0.0981],\n",
            "        [0.7510, 0.1480, 0.1011],\n",
            "        [0.8626, 0.0733, 0.0642],\n",
            "        [0.8151, 0.0721, 0.1128],\n",
            "        [0.5059, 0.4221, 0.0720],\n",
            "        [0.8977, 0.0221, 0.0802],\n",
            "        [0.0506, 0.7205, 0.2289]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.9583, 0.0162, 0.0255],\n",
            "        [0.1206, 0.6031, 0.2763],\n",
            "        [0.0419, 0.8479, 0.1102],\n",
            "        [0.9204, 0.0362, 0.0434],\n",
            "        [0.0540, 0.8076, 0.1383],\n",
            "        [0.0459, 0.2014, 0.7527],\n",
            "        [0.0385, 0.8433, 0.1182],\n",
            "        [0.4820, 0.0811, 0.4370]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 1, 0, 1, 2, 1, 0], device='cuda:0')\n",
            "tensor([[0.9583, 0.0162, 0.0255],\n",
            "        [0.1206, 0.6031, 0.2763],\n",
            "        [0.0419, 0.8479, 0.1102],\n",
            "        [0.9204, 0.0362, 0.0434],\n",
            "        [0.0540, 0.8076, 0.1383],\n",
            "        [0.0459, 0.2014, 0.7527],\n",
            "        [0.0385, 0.8433, 0.1182],\n",
            "        [0.4820, 0.0811, 0.4370]], device='cuda:0')\n",
            "tensor([0, 2, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9487, 0.0138, 0.0375],\n",
            "        [0.6491, 0.0642, 0.2867],\n",
            "        [0.0325, 0.6296, 0.3379],\n",
            "        [0.8631, 0.0475, 0.0893]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "tensor([[0.9487, 0.0138, 0.0375],\n",
            "        [0.6491, 0.0642, 0.2867],\n",
            "        [0.0325, 0.6296, 0.3379],\n",
            "        [0.8631, 0.0475, 0.0893]], device='cuda:0')\n",
            "Epochs: 4 | Train Loss:  0.126             | Train Accuracy:  0.556             | Val Loss:  0.117             | Val Accuracy:  0.690\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1552, 0.1248, 0.7200],\n",
            "        [0.4578, 0.1729, 0.3694],\n",
            "        [0.7866, 0.0934, 0.1199],\n",
            "        [0.0313, 0.8684, 0.1003],\n",
            "        [0.2665, 0.1993, 0.5342],\n",
            "        [0.1103, 0.6726, 0.2171],\n",
            "        [0.0611, 0.6140, 0.3249],\n",
            "        [0.3691, 0.3806, 0.2503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1552, 0.1248, 0.7200],\n",
            "        [0.4578, 0.1729, 0.3694],\n",
            "        [0.7866, 0.0934, 0.1199],\n",
            "        [0.0313, 0.8684, 0.1003],\n",
            "        [0.2665, 0.1993, 0.5342],\n",
            "        [0.1103, 0.6726, 0.2171],\n",
            "        [0.0611, 0.6140, 0.3249],\n",
            "        [0.3691, 0.3806, 0.2503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 1, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 1, 1, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/63 [00:00<00:44,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8901, 0.0373, 0.0725],\n",
            "        [0.0945, 0.5688, 0.3366],\n",
            "        [0.6183, 0.1241, 0.2576],\n",
            "        [0.9195, 0.0286, 0.0519],\n",
            "        [0.9014, 0.0258, 0.0728],\n",
            "        [0.9395, 0.0366, 0.0239],\n",
            "        [0.1021, 0.5869, 0.3109],\n",
            "        [0.9305, 0.0251, 0.0444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8901, 0.0373, 0.0725],\n",
            "        [0.0945, 0.5688, 0.3366],\n",
            "        [0.6183, 0.1241, 0.2576],\n",
            "        [0.9195, 0.0286, 0.0519],\n",
            "        [0.9014, 0.0258, 0.0728],\n",
            "        [0.9395, 0.0366, 0.0239],\n",
            "        [0.1021, 0.5869, 0.3109],\n",
            "        [0.9305, 0.0251, 0.0444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 0, 0, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/63 [00:01<00:41,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7997, 0.0850, 0.1154],\n",
            "        [0.5486, 0.1882, 0.2632],\n",
            "        [0.8983, 0.0362, 0.0655],\n",
            "        [0.0221, 0.7947, 0.1832],\n",
            "        [0.0837, 0.7424, 0.1739],\n",
            "        [0.2193, 0.2757, 0.5051],\n",
            "        [0.0446, 0.7631, 0.1923],\n",
            "        [0.8238, 0.0469, 0.1293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7997, 0.0850, 0.1154],\n",
            "        [0.5486, 0.1882, 0.2632],\n",
            "        [0.8983, 0.0362, 0.0655],\n",
            "        [0.0221, 0.7947, 0.1832],\n",
            "        [0.0837, 0.7424, 0.1739],\n",
            "        [0.2193, 0.2757, 0.5051],\n",
            "        [0.0446, 0.7631, 0.1923],\n",
            "        [0.8238, 0.0469, 0.1293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 1, 1, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 1, 1, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/63 [00:02<00:40,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4145, 0.3429, 0.2426],\n",
            "        [0.8936, 0.0486, 0.0578],\n",
            "        [0.0530, 0.8044, 0.1426],\n",
            "        [0.0272, 0.8151, 0.1577],\n",
            "        [0.1101, 0.3012, 0.5886],\n",
            "        [0.8496, 0.0564, 0.0941],\n",
            "        [0.8729, 0.0307, 0.0964],\n",
            "        [0.9180, 0.0285, 0.0535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4145, 0.3429, 0.2426],\n",
            "        [0.8936, 0.0486, 0.0578],\n",
            "        [0.0530, 0.8044, 0.1426],\n",
            "        [0.0272, 0.8151, 0.1577],\n",
            "        [0.1101, 0.3012, 0.5886],\n",
            "        [0.8496, 0.0564, 0.0941],\n",
            "        [0.8729, 0.0307, 0.0964],\n",
            "        [0.9180, 0.0285, 0.0535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 1, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 1, 2, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/63 [00:02<00:39,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9232, 0.0276, 0.0492],\n",
            "        [0.2849, 0.0935, 0.6215],\n",
            "        [0.1789, 0.1107, 0.7105],\n",
            "        [0.2224, 0.4026, 0.3750],\n",
            "        [0.8422, 0.0497, 0.1081],\n",
            "        [0.1326, 0.4675, 0.3999],\n",
            "        [0.9287, 0.0219, 0.0495],\n",
            "        [0.2396, 0.3446, 0.4157]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9232, 0.0276, 0.0492],\n",
            "        [0.2849, 0.0935, 0.6215],\n",
            "        [0.1789, 0.1107, 0.7105],\n",
            "        [0.2224, 0.4026, 0.3750],\n",
            "        [0.8422, 0.0497, 0.1081],\n",
            "        [0.1326, 0.4675, 0.3999],\n",
            "        [0.9287, 0.0219, 0.0495],\n",
            "        [0.2396, 0.3446, 0.4157]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 1, 0, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 2, 0, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/63 [00:03<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3372, 0.1854, 0.4774],\n",
            "        [0.1384, 0.1670, 0.6946],\n",
            "        [0.9131, 0.0402, 0.0467],\n",
            "        [0.9204, 0.0258, 0.0538],\n",
            "        [0.9218, 0.0330, 0.0451],\n",
            "        [0.0365, 0.7989, 0.1646],\n",
            "        [0.9218, 0.0160, 0.0622],\n",
            "        [0.5407, 0.1912, 0.2682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3372, 0.1854, 0.4774],\n",
            "        [0.1384, 0.1670, 0.6946],\n",
            "        [0.9131, 0.0402, 0.0467],\n",
            "        [0.9204, 0.0258, 0.0538],\n",
            "        [0.9218, 0.0330, 0.0451],\n",
            "        [0.0365, 0.7989, 0.1646],\n",
            "        [0.9218, 0.0160, 0.0622],\n",
            "        [0.5407, 0.1912, 0.2682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 0, 0, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 6/63 [00:04<00:38,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8696, 0.0657, 0.0647],\n",
            "        [0.1930, 0.2576, 0.5494],\n",
            "        [0.0300, 0.8755, 0.0945],\n",
            "        [0.9182, 0.0386, 0.0432],\n",
            "        [0.0826, 0.3739, 0.5435],\n",
            "        [0.5020, 0.2312, 0.2668],\n",
            "        [0.2633, 0.2661, 0.4707],\n",
            "        [0.0198, 0.8517, 0.1284]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8696, 0.0657, 0.0647],\n",
            "        [0.1930, 0.2576, 0.5494],\n",
            "        [0.0300, 0.8755, 0.0945],\n",
            "        [0.9182, 0.0386, 0.0432],\n",
            "        [0.0826, 0.3739, 0.5435],\n",
            "        [0.5020, 0.2312, 0.2668],\n",
            "        [0.2633, 0.2661, 0.4707],\n",
            "        [0.0198, 0.8517, 0.1284]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 1, 0, 2, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 1, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/63 [00:04<00:37,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0304, 0.7858, 0.1838],\n",
            "        [0.0800, 0.6132, 0.3068],\n",
            "        [0.1602, 0.5234, 0.3165],\n",
            "        [0.8923, 0.0408, 0.0669],\n",
            "        [0.0218, 0.8160, 0.1622],\n",
            "        [0.2870, 0.6353, 0.0777],\n",
            "        [0.8719, 0.0309, 0.0972],\n",
            "        [0.7678, 0.0780, 0.1542]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0304, 0.7858, 0.1838],\n",
            "        [0.0800, 0.6132, 0.3068],\n",
            "        [0.1602, 0.5234, 0.3165],\n",
            "        [0.8923, 0.0408, 0.0669],\n",
            "        [0.0218, 0.8160, 0.1622],\n",
            "        [0.2870, 0.6353, 0.0777],\n",
            "        [0.8719, 0.0309, 0.0972],\n",
            "        [0.7678, 0.0780, 0.1542]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 0, 1, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/63 [00:05<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9212, 0.0247, 0.0541],\n",
            "        [0.9600, 0.0191, 0.0209],\n",
            "        [0.0670, 0.8016, 0.1314],\n",
            "        [0.3929, 0.2534, 0.3537],\n",
            "        [0.8286, 0.0664, 0.1049],\n",
            "        [0.0458, 0.7744, 0.1798],\n",
            "        [0.0372, 0.8655, 0.0973],\n",
            "        [0.9398, 0.0193, 0.0409]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9212, 0.0247, 0.0541],\n",
            "        [0.9600, 0.0191, 0.0209],\n",
            "        [0.0670, 0.8016, 0.1314],\n",
            "        [0.3929, 0.2534, 0.3537],\n",
            "        [0.8286, 0.0664, 0.1049],\n",
            "        [0.0458, 0.7744, 0.1798],\n",
            "        [0.0372, 0.8655, 0.0973],\n",
            "        [0.9398, 0.0193, 0.0409]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 2, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/63 [00:06<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0267, 0.7621, 0.2112],\n",
            "        [0.9512, 0.0169, 0.0319],\n",
            "        [0.9679, 0.0163, 0.0158],\n",
            "        [0.0269, 0.6906, 0.2825],\n",
            "        [0.5671, 0.2733, 0.1596],\n",
            "        [0.2014, 0.3501, 0.4485],\n",
            "        [0.0380, 0.7055, 0.2566],\n",
            "        [0.0281, 0.7549, 0.2170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0267, 0.7621, 0.2112],\n",
            "        [0.9512, 0.0169, 0.0319],\n",
            "        [0.9679, 0.0163, 0.0158],\n",
            "        [0.0269, 0.6906, 0.2825],\n",
            "        [0.5671, 0.2733, 0.1596],\n",
            "        [0.2014, 0.3501, 0.4485],\n",
            "        [0.0380, 0.7055, 0.2566],\n",
            "        [0.0281, 0.7549, 0.2170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 1, 0, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 1, 1, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/63 [00:06<00:35,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0285, 0.8758, 0.0957],\n",
            "        [0.7227, 0.1136, 0.1637],\n",
            "        [0.9315, 0.0205, 0.0481],\n",
            "        [0.8774, 0.0616, 0.0610],\n",
            "        [0.6731, 0.0643, 0.2626],\n",
            "        [0.0923, 0.4461, 0.4616],\n",
            "        [0.7896, 0.0466, 0.1639],\n",
            "        [0.6663, 0.1410, 0.1927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0285, 0.8758, 0.0957],\n",
            "        [0.7227, 0.1136, 0.1637],\n",
            "        [0.9315, 0.0205, 0.0481],\n",
            "        [0.8774, 0.0616, 0.0610],\n",
            "        [0.6731, 0.0643, 0.2626],\n",
            "        [0.0923, 0.4461, 0.4616],\n",
            "        [0.7896, 0.0466, 0.1639],\n",
            "        [0.6663, 0.1410, 0.1927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/63 [00:07<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8659, 0.0443, 0.0897],\n",
            "        [0.8677, 0.0299, 0.1024],\n",
            "        [0.2602, 0.0442, 0.6956],\n",
            "        [0.7427, 0.0529, 0.2044],\n",
            "        [0.1425, 0.7374, 0.1202],\n",
            "        [0.0547, 0.6078, 0.3375],\n",
            "        [0.0598, 0.4949, 0.4453],\n",
            "        [0.0813, 0.3352, 0.5835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8659, 0.0443, 0.0897],\n",
            "        [0.8677, 0.0299, 0.1024],\n",
            "        [0.2602, 0.0442, 0.6956],\n",
            "        [0.7427, 0.0529, 0.2044],\n",
            "        [0.1425, 0.7374, 0.1202],\n",
            "        [0.0547, 0.6078, 0.3375],\n",
            "        [0.0598, 0.4949, 0.4453],\n",
            "        [0.0813, 0.3352, 0.5835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 2, 1, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/63 [00:08<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0911, 0.6370, 0.2719],\n",
            "        [0.2011, 0.3364, 0.4625],\n",
            "        [0.7722, 0.0629, 0.1649],\n",
            "        [0.7641, 0.0450, 0.1909],\n",
            "        [0.0430, 0.8167, 0.1403],\n",
            "        [0.0431, 0.8490, 0.1078],\n",
            "        [0.0747, 0.7593, 0.1659],\n",
            "        [0.4680, 0.2714, 0.2606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0911, 0.6370, 0.2719],\n",
            "        [0.2011, 0.3364, 0.4625],\n",
            "        [0.7722, 0.0629, 0.1649],\n",
            "        [0.7641, 0.0450, 0.1909],\n",
            "        [0.0430, 0.8167, 0.1403],\n",
            "        [0.0431, 0.8490, 0.1078],\n",
            "        [0.0747, 0.7593, 0.1659],\n",
            "        [0.4680, 0.2714, 0.2606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 0, 1, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 13/63 [00:08<00:33,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1071, 0.2662, 0.6267],\n",
            "        [0.0595, 0.0946, 0.8459],\n",
            "        [0.9397, 0.0131, 0.0472],\n",
            "        [0.1158, 0.5349, 0.3493],\n",
            "        [0.0956, 0.4516, 0.4529],\n",
            "        [0.0814, 0.3104, 0.6083],\n",
            "        [0.2103, 0.5322, 0.2575],\n",
            "        [0.0495, 0.4736, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1071, 0.2662, 0.6267],\n",
            "        [0.0595, 0.0946, 0.8459],\n",
            "        [0.9397, 0.0131, 0.0472],\n",
            "        [0.1158, 0.5349, 0.3493],\n",
            "        [0.0956, 0.4516, 0.4529],\n",
            "        [0.0814, 0.3104, 0.6083],\n",
            "        [0.2103, 0.5322, 0.2575],\n",
            "        [0.0495, 0.4736, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/63 [00:09<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8755, 0.0402, 0.0843],\n",
            "        [0.0240, 0.9111, 0.0649],\n",
            "        [0.0250, 0.8433, 0.1317],\n",
            "        [0.0432, 0.4254, 0.5313],\n",
            "        [0.6526, 0.0409, 0.3065],\n",
            "        [0.0685, 0.3610, 0.5704],\n",
            "        [0.8978, 0.0100, 0.0922],\n",
            "        [0.1248, 0.0721, 0.8031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8755, 0.0402, 0.0843],\n",
            "        [0.0240, 0.9111, 0.0649],\n",
            "        [0.0250, 0.8433, 0.1317],\n",
            "        [0.0432, 0.4254, 0.5313],\n",
            "        [0.6526, 0.0409, 0.3065],\n",
            "        [0.0685, 0.3610, 0.5704],\n",
            "        [0.8978, 0.0100, 0.0922],\n",
            "        [0.1248, 0.0721, 0.8031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 2, 0, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 2, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 15/63 [00:10<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9635, 0.0087, 0.0278],\n",
            "        [0.0552, 0.6473, 0.2975],\n",
            "        [0.0303, 0.8559, 0.1138],\n",
            "        [0.0946, 0.7934, 0.1120],\n",
            "        [0.0407, 0.7994, 0.1598],\n",
            "        [0.4243, 0.1644, 0.4112],\n",
            "        [0.0432, 0.7855, 0.1713],\n",
            "        [0.0352, 0.4662, 0.4987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9635, 0.0087, 0.0278],\n",
            "        [0.0552, 0.6473, 0.2975],\n",
            "        [0.0303, 0.8559, 0.1138],\n",
            "        [0.0946, 0.7934, 0.1120],\n",
            "        [0.0407, 0.7994, 0.1598],\n",
            "        [0.4243, 0.1644, 0.4112],\n",
            "        [0.0432, 0.7855, 0.1713],\n",
            "        [0.0352, 0.4662, 0.4987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 1, 1, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 2, 1, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/63 [00:10<00:31,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0530, 0.6035, 0.3435],\n",
            "        [0.7219, 0.0315, 0.2466],\n",
            "        [0.0373, 0.3979, 0.5647],\n",
            "        [0.0198, 0.7861, 0.1941],\n",
            "        [0.9672, 0.0180, 0.0148],\n",
            "        [0.1103, 0.1892, 0.7005],\n",
            "        [0.9269, 0.0077, 0.0653],\n",
            "        [0.9202, 0.0366, 0.0432]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0530, 0.6035, 0.3435],\n",
            "        [0.7219, 0.0315, 0.2466],\n",
            "        [0.0373, 0.3979, 0.5647],\n",
            "        [0.0198, 0.7861, 0.1941],\n",
            "        [0.9672, 0.0180, 0.0148],\n",
            "        [0.1103, 0.1892, 0.7005],\n",
            "        [0.9269, 0.0077, 0.0653],\n",
            "        [0.9202, 0.0366, 0.0432]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 1, 0, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/63 [00:11<00:30,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1218, 0.2098, 0.6684],\n",
            "        [0.0917, 0.0370, 0.8713],\n",
            "        [0.0154, 0.8096, 0.1749],\n",
            "        [0.0405, 0.2219, 0.7376],\n",
            "        [0.4454, 0.2359, 0.3187],\n",
            "        [0.0141, 0.8741, 0.1118],\n",
            "        [0.7827, 0.0453, 0.1720],\n",
            "        [0.0317, 0.6049, 0.3634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1218, 0.2098, 0.6684],\n",
            "        [0.0917, 0.0370, 0.8713],\n",
            "        [0.0154, 0.8096, 0.1749],\n",
            "        [0.0405, 0.2219, 0.7376],\n",
            "        [0.4454, 0.2359, 0.3187],\n",
            "        [0.0141, 0.8741, 0.1118],\n",
            "        [0.7827, 0.0453, 0.1720],\n",
            "        [0.0317, 0.6049, 0.3634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 2, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 1, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 18/63 [00:12<00:30,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1096, 0.3158, 0.5747],\n",
            "        [0.8730, 0.0264, 0.1006],\n",
            "        [0.4404, 0.0919, 0.4678],\n",
            "        [0.4216, 0.1717, 0.4067],\n",
            "        [0.0348, 0.3161, 0.6491],\n",
            "        [0.2008, 0.1002, 0.6990],\n",
            "        [0.6970, 0.1604, 0.1426],\n",
            "        [0.0913, 0.1315, 0.7772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1096, 0.3158, 0.5747],\n",
            "        [0.8730, 0.0264, 0.1006],\n",
            "        [0.4404, 0.0919, 0.4678],\n",
            "        [0.4216, 0.1717, 0.4067],\n",
            "        [0.0348, 0.3161, 0.6491],\n",
            "        [0.2008, 0.1002, 0.6990],\n",
            "        [0.6970, 0.1604, 0.1426],\n",
            "        [0.0913, 0.1315, 0.7772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 2, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 1, 0, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 19/63 [00:12<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0407, 0.1808, 0.7785],\n",
            "        [0.4413, 0.0914, 0.4673],\n",
            "        [0.9687, 0.0083, 0.0230],\n",
            "        [0.0168, 0.9000, 0.0831],\n",
            "        [0.4919, 0.0971, 0.4110],\n",
            "        [0.0865, 0.7006, 0.2129],\n",
            "        [0.7321, 0.0493, 0.2186],\n",
            "        [0.9024, 0.0294, 0.0682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0407, 0.1808, 0.7785],\n",
            "        [0.4413, 0.0914, 0.4673],\n",
            "        [0.9687, 0.0083, 0.0230],\n",
            "        [0.0168, 0.9000, 0.0831],\n",
            "        [0.4919, 0.0971, 0.4110],\n",
            "        [0.0865, 0.7006, 0.2129],\n",
            "        [0.7321, 0.0493, 0.2186],\n",
            "        [0.9024, 0.0294, 0.0682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 1, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 20/63 [00:13<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8561, 0.0447, 0.0992],\n",
            "        [0.9540, 0.0173, 0.0287],\n",
            "        [0.4130, 0.3387, 0.2483],\n",
            "        [0.9055, 0.0216, 0.0728],\n",
            "        [0.0181, 0.9190, 0.0628],\n",
            "        [0.0524, 0.1047, 0.8429],\n",
            "        [0.7999, 0.0461, 0.1540],\n",
            "        [0.1834, 0.1718, 0.6447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8561, 0.0447, 0.0992],\n",
            "        [0.9540, 0.0173, 0.0287],\n",
            "        [0.4130, 0.3387, 0.2483],\n",
            "        [0.9055, 0.0216, 0.0728],\n",
            "        [0.0181, 0.9190, 0.0628],\n",
            "        [0.0524, 0.1047, 0.8429],\n",
            "        [0.7999, 0.0461, 0.1540],\n",
            "        [0.1834, 0.1718, 0.6447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 1, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 0, 1, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/63 [00:14<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3905, 0.1946, 0.4149],\n",
            "        [0.8969, 0.0185, 0.0846],\n",
            "        [0.1051, 0.2044, 0.6905],\n",
            "        [0.9045, 0.0214, 0.0741],\n",
            "        [0.4713, 0.1886, 0.3401],\n",
            "        [0.0158, 0.8092, 0.1750],\n",
            "        [0.0212, 0.8593, 0.1195],\n",
            "        [0.4191, 0.1674, 0.4135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3905, 0.1946, 0.4149],\n",
            "        [0.8969, 0.0185, 0.0846],\n",
            "        [0.1051, 0.2044, 0.6905],\n",
            "        [0.9045, 0.0214, 0.0741],\n",
            "        [0.4713, 0.1886, 0.3401],\n",
            "        [0.0158, 0.8092, 0.1750],\n",
            "        [0.0212, 0.8593, 0.1195],\n",
            "        [0.4191, 0.1674, 0.4135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 0, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 0, 1, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 22/63 [00:14<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4374, 0.2238, 0.3387],\n",
            "        [0.4570, 0.1210, 0.4220],\n",
            "        [0.3412, 0.3585, 0.3004],\n",
            "        [0.7602, 0.0333, 0.2065],\n",
            "        [0.0480, 0.5929, 0.3591],\n",
            "        [0.0691, 0.1093, 0.8216],\n",
            "        [0.0152, 0.8938, 0.0911],\n",
            "        [0.0194, 0.9047, 0.0759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4374, 0.2238, 0.3387],\n",
            "        [0.4570, 0.1210, 0.4220],\n",
            "        [0.3412, 0.3585, 0.3004],\n",
            "        [0.7602, 0.0333, 0.2065],\n",
            "        [0.0480, 0.5929, 0.3591],\n",
            "        [0.0691, 0.1093, 0.8216],\n",
            "        [0.0152, 0.8938, 0.0911],\n",
            "        [0.0194, 0.9047, 0.0759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 1, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 23/63 [00:15<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6775, 0.1179, 0.2046],\n",
            "        [0.0608, 0.0695, 0.8697],\n",
            "        [0.3310, 0.2133, 0.4557],\n",
            "        [0.1861, 0.2207, 0.5931],\n",
            "        [0.0489, 0.5717, 0.3795],\n",
            "        [0.0635, 0.7173, 0.2192],\n",
            "        [0.0524, 0.7851, 0.1625],\n",
            "        [0.0129, 0.9286, 0.0584]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6775, 0.1179, 0.2046],\n",
            "        [0.0608, 0.0695, 0.8697],\n",
            "        [0.3310, 0.2133, 0.4557],\n",
            "        [0.1861, 0.2207, 0.5931],\n",
            "        [0.0489, 0.5717, 0.3795],\n",
            "        [0.0635, 0.7173, 0.2192],\n",
            "        [0.0524, 0.7851, 0.1625],\n",
            "        [0.0129, 0.9286, 0.0584]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 2, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 2, 1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/63 [00:16<00:26,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8740, 0.0536, 0.0723],\n",
            "        [0.0546, 0.6928, 0.2526],\n",
            "        [0.9417, 0.0093, 0.0490],\n",
            "        [0.8905, 0.0293, 0.0802],\n",
            "        [0.1697, 0.2011, 0.6292],\n",
            "        [0.3933, 0.0765, 0.5303],\n",
            "        [0.4852, 0.0606, 0.4542],\n",
            "        [0.1740, 0.1013, 0.7247]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8740, 0.0536, 0.0723],\n",
            "        [0.0546, 0.6928, 0.2526],\n",
            "        [0.9417, 0.0093, 0.0490],\n",
            "        [0.8905, 0.0293, 0.0802],\n",
            "        [0.1697, 0.2011, 0.6292],\n",
            "        [0.3933, 0.0765, 0.5303],\n",
            "        [0.4852, 0.0606, 0.4542],\n",
            "        [0.1740, 0.1013, 0.7247]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 2, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 0, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 25/63 [00:16<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0995, 0.2663, 0.6342],\n",
            "        [0.6303, 0.1492, 0.2205],\n",
            "        [0.7679, 0.0333, 0.1987],\n",
            "        [0.9665, 0.0121, 0.0214],\n",
            "        [0.3289, 0.2528, 0.4183],\n",
            "        [0.0150, 0.7409, 0.2441],\n",
            "        [0.0177, 0.8221, 0.1602],\n",
            "        [0.7867, 0.0408, 0.1725]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0995, 0.2663, 0.6342],\n",
            "        [0.6303, 0.1492, 0.2205],\n",
            "        [0.7679, 0.0333, 0.1987],\n",
            "        [0.9665, 0.0121, 0.0214],\n",
            "        [0.3289, 0.2528, 0.4183],\n",
            "        [0.0150, 0.7409, 0.2441],\n",
            "        [0.0177, 0.8221, 0.1602],\n",
            "        [0.7867, 0.0408, 0.1725]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 2, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 0, 2, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 26/63 [00:17<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0908, 0.3054, 0.6038],\n",
            "        [0.0813, 0.2554, 0.6633],\n",
            "        [0.0815, 0.2995, 0.6190],\n",
            "        [0.2346, 0.2908, 0.4746],\n",
            "        [0.0610, 0.3629, 0.5761],\n",
            "        [0.3506, 0.2200, 0.4295],\n",
            "        [0.0398, 0.8521, 0.1080],\n",
            "        [0.6302, 0.0593, 0.3105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0908, 0.3054, 0.6038],\n",
            "        [0.0813, 0.2554, 0.6633],\n",
            "        [0.0815, 0.2995, 0.6190],\n",
            "        [0.2346, 0.2908, 0.4746],\n",
            "        [0.0610, 0.3629, 0.5761],\n",
            "        [0.3506, 0.2200, 0.4295],\n",
            "        [0.0398, 0.8521, 0.1080],\n",
            "        [0.6302, 0.0593, 0.3105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 2, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 0, 2, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 27/63 [00:18<00:24,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8575, 0.0252, 0.1174],\n",
            "        [0.2111, 0.0635, 0.7254],\n",
            "        [0.9189, 0.0185, 0.0627],\n",
            "        [0.9184, 0.0284, 0.0532],\n",
            "        [0.0486, 0.3315, 0.6198],\n",
            "        [0.8815, 0.0393, 0.0792],\n",
            "        [0.4790, 0.0886, 0.4323],\n",
            "        [0.1728, 0.2667, 0.5604]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8575, 0.0252, 0.1174],\n",
            "        [0.2111, 0.0635, 0.7254],\n",
            "        [0.9189, 0.0185, 0.0627],\n",
            "        [0.9184, 0.0284, 0.0532],\n",
            "        [0.0486, 0.3315, 0.6198],\n",
            "        [0.8815, 0.0393, 0.0792],\n",
            "        [0.4790, 0.0886, 0.4323],\n",
            "        [0.1728, 0.2667, 0.5604]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 0, 2, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/63 [00:18<00:23,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1329, 0.2601, 0.6069],\n",
            "        [0.9534, 0.0147, 0.0318],\n",
            "        [0.1115, 0.1230, 0.7655],\n",
            "        [0.8523, 0.0292, 0.1185],\n",
            "        [0.1552, 0.1672, 0.6776],\n",
            "        [0.8558, 0.0260, 0.1182],\n",
            "        [0.0560, 0.5266, 0.4175],\n",
            "        [0.1561, 0.1345, 0.7094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1329, 0.2601, 0.6069],\n",
            "        [0.9534, 0.0147, 0.0318],\n",
            "        [0.1115, 0.1230, 0.7655],\n",
            "        [0.8523, 0.0292, 0.1185],\n",
            "        [0.1552, 0.1672, 0.6776],\n",
            "        [0.8558, 0.0260, 0.1182],\n",
            "        [0.0560, 0.5266, 0.4175],\n",
            "        [0.1561, 0.1345, 0.7094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 2, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 29/63 [00:19<00:23,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7367, 0.0565, 0.2068],\n",
            "        [0.1615, 0.2012, 0.6372],\n",
            "        [0.9096, 0.0324, 0.0580],\n",
            "        [0.0874, 0.1582, 0.7544],\n",
            "        [0.6465, 0.0965, 0.2569],\n",
            "        [0.5753, 0.2310, 0.1937],\n",
            "        [0.0418, 0.7026, 0.2556],\n",
            "        [0.1405, 0.3942, 0.4652]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7367, 0.0565, 0.2068],\n",
            "        [0.1615, 0.2012, 0.6372],\n",
            "        [0.9096, 0.0324, 0.0580],\n",
            "        [0.0874, 0.1582, 0.7544],\n",
            "        [0.6465, 0.0965, 0.2569],\n",
            "        [0.5753, 0.2310, 0.1937],\n",
            "        [0.0418, 0.7026, 0.2556],\n",
            "        [0.1405, 0.3942, 0.4652]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 2, 0, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 0, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 30/63 [00:20<00:22,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0166, 0.9418, 0.0416],\n",
            "        [0.1981, 0.3570, 0.4449],\n",
            "        [0.9046, 0.0161, 0.0793],\n",
            "        [0.9268, 0.0148, 0.0583],\n",
            "        [0.4732, 0.0395, 0.4873],\n",
            "        [0.0164, 0.6849, 0.2988],\n",
            "        [0.5454, 0.0522, 0.4024],\n",
            "        [0.1872, 0.3040, 0.5087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0166, 0.9418, 0.0416],\n",
            "        [0.1981, 0.3570, 0.4449],\n",
            "        [0.9046, 0.0161, 0.0793],\n",
            "        [0.9268, 0.0148, 0.0583],\n",
            "        [0.4732, 0.0395, 0.4873],\n",
            "        [0.0164, 0.6849, 0.2988],\n",
            "        [0.5454, 0.0522, 0.4024],\n",
            "        [0.1872, 0.3040, 0.5087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 0, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 31/63 [00:20<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8643, 0.0242, 0.1115],\n",
            "        [0.9266, 0.0296, 0.0438],\n",
            "        [0.1817, 0.1013, 0.7170],\n",
            "        [0.9383, 0.0196, 0.0421],\n",
            "        [0.3000, 0.0965, 0.6035],\n",
            "        [0.0609, 0.7550, 0.1842],\n",
            "        [0.1459, 0.5474, 0.3067],\n",
            "        [0.9586, 0.0149, 0.0265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8643, 0.0242, 0.1115],\n",
            "        [0.9266, 0.0296, 0.0438],\n",
            "        [0.1817, 0.1013, 0.7170],\n",
            "        [0.9383, 0.0196, 0.0421],\n",
            "        [0.3000, 0.0965, 0.6035],\n",
            "        [0.0609, 0.7550, 0.1842],\n",
            "        [0.1459, 0.5474, 0.3067],\n",
            "        [0.9586, 0.0149, 0.0265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 2, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 1, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 32/63 [00:21<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0989, 0.3114, 0.5896],\n",
            "        [0.0165, 0.9483, 0.0353],\n",
            "        [0.0157, 0.7221, 0.2621],\n",
            "        [0.0194, 0.9227, 0.0579],\n",
            "        [0.6007, 0.0735, 0.3257],\n",
            "        [0.0313, 0.8848, 0.0839],\n",
            "        [0.5530, 0.1022, 0.3448],\n",
            "        [0.0353, 0.8672, 0.0975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0989, 0.3114, 0.5896],\n",
            "        [0.0165, 0.9483, 0.0353],\n",
            "        [0.0157, 0.7221, 0.2621],\n",
            "        [0.0194, 0.9227, 0.0579],\n",
            "        [0.6007, 0.0735, 0.3257],\n",
            "        [0.0313, 0.8848, 0.0839],\n",
            "        [0.5530, 0.1022, 0.3448],\n",
            "        [0.0353, 0.8672, 0.0975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 1, 0, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/63 [00:22<00:20,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0232, 0.8972, 0.0796],\n",
            "        [0.2428, 0.1242, 0.6330],\n",
            "        [0.1119, 0.1734, 0.7147],\n",
            "        [0.9407, 0.0157, 0.0436],\n",
            "        [0.0175, 0.8311, 0.1514],\n",
            "        [0.0300, 0.7429, 0.2271],\n",
            "        [0.8923, 0.0169, 0.0908],\n",
            "        [0.2997, 0.2161, 0.4842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0232, 0.8972, 0.0796],\n",
            "        [0.2428, 0.1242, 0.6330],\n",
            "        [0.1119, 0.1734, 0.7147],\n",
            "        [0.9407, 0.0157, 0.0436],\n",
            "        [0.0175, 0.8311, 0.1514],\n",
            "        [0.0300, 0.7429, 0.2271],\n",
            "        [0.8923, 0.0169, 0.0908],\n",
            "        [0.2997, 0.2161, 0.4842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 0, 1, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 2, 1, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 34/63 [00:23<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0126, 0.9259, 0.0615],\n",
            "        [0.0583, 0.0670, 0.8747],\n",
            "        [0.0357, 0.9011, 0.0632],\n",
            "        [0.0733, 0.1656, 0.7611],\n",
            "        [0.8015, 0.0522, 0.1462],\n",
            "        [0.9279, 0.0125, 0.0596],\n",
            "        [0.0216, 0.9222, 0.0562],\n",
            "        [0.0330, 0.8496, 0.1173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0126, 0.9259, 0.0615],\n",
            "        [0.0583, 0.0670, 0.8747],\n",
            "        [0.0357, 0.9011, 0.0632],\n",
            "        [0.0733, 0.1656, 0.7611],\n",
            "        [0.8015, 0.0522, 0.1462],\n",
            "        [0.9279, 0.0125, 0.0596],\n",
            "        [0.0216, 0.9222, 0.0562],\n",
            "        [0.0330, 0.8496, 0.1173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 0, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 2, 0, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 35/63 [00:23<00:19,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0122, 0.8999, 0.0879],\n",
            "        [0.4961, 0.2519, 0.2520],\n",
            "        [0.0378, 0.1852, 0.7770],\n",
            "        [0.3174, 0.0680, 0.6146],\n",
            "        [0.0434, 0.8948, 0.0618],\n",
            "        [0.8938, 0.0316, 0.0745],\n",
            "        [0.6752, 0.1001, 0.2247],\n",
            "        [0.7464, 0.0294, 0.2242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0122, 0.8999, 0.0879],\n",
            "        [0.4961, 0.2519, 0.2520],\n",
            "        [0.0378, 0.1852, 0.7770],\n",
            "        [0.3174, 0.0680, 0.6146],\n",
            "        [0.0434, 0.8948, 0.0618],\n",
            "        [0.8938, 0.0316, 0.0745],\n",
            "        [0.6752, 0.1001, 0.2247],\n",
            "        [0.7464, 0.0294, 0.2242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 2, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 0, 2, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 36/63 [00:24<00:18,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8969, 0.0410, 0.0621],\n",
            "        [0.0290, 0.9009, 0.0701],\n",
            "        [0.4709, 0.1058, 0.4233],\n",
            "        [0.8992, 0.0565, 0.0442],\n",
            "        [0.0801, 0.2659, 0.6540],\n",
            "        [0.0425, 0.2354, 0.7221],\n",
            "        [0.0166, 0.9131, 0.0703],\n",
            "        [0.0201, 0.8350, 0.1449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8969, 0.0410, 0.0621],\n",
            "        [0.0290, 0.9009, 0.0701],\n",
            "        [0.4709, 0.1058, 0.4233],\n",
            "        [0.8992, 0.0565, 0.0442],\n",
            "        [0.0801, 0.2659, 0.6540],\n",
            "        [0.0425, 0.2354, 0.7221],\n",
            "        [0.0166, 0.9131, 0.0703],\n",
            "        [0.0201, 0.8350, 0.1449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 2, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 0, 2, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 37/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8494, 0.0587, 0.0920],\n",
            "        [0.0400, 0.8179, 0.1421],\n",
            "        [0.8209, 0.0214, 0.1578],\n",
            "        [0.0485, 0.3864, 0.5651],\n",
            "        [0.1814, 0.2194, 0.5992],\n",
            "        [0.1582, 0.3307, 0.5111],\n",
            "        [0.0472, 0.2788, 0.6741],\n",
            "        [0.4299, 0.0503, 0.5197]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8494, 0.0587, 0.0920],\n",
            "        [0.0400, 0.8179, 0.1421],\n",
            "        [0.8209, 0.0214, 0.1578],\n",
            "        [0.0485, 0.3864, 0.5651],\n",
            "        [0.1814, 0.2194, 0.5992],\n",
            "        [0.1582, 0.3307, 0.5111],\n",
            "        [0.0472, 0.2788, 0.6741],\n",
            "        [0.4299, 0.0503, 0.5197]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 2, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 38/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5763, 0.2621, 0.1616],\n",
            "        [0.3937, 0.1049, 0.5013],\n",
            "        [0.0404, 0.9144, 0.0452],\n",
            "        [0.1841, 0.1128, 0.7031],\n",
            "        [0.8994, 0.0348, 0.0659],\n",
            "        [0.2864, 0.0995, 0.6141],\n",
            "        [0.0218, 0.8971, 0.0811],\n",
            "        [0.9217, 0.0219, 0.0564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5763, 0.2621, 0.1616],\n",
            "        [0.3937, 0.1049, 0.5013],\n",
            "        [0.0404, 0.9144, 0.0452],\n",
            "        [0.1841, 0.1128, 0.7031],\n",
            "        [0.8994, 0.0348, 0.0659],\n",
            "        [0.2864, 0.0995, 0.6141],\n",
            "        [0.0218, 0.8971, 0.0811],\n",
            "        [0.9217, 0.0219, 0.0564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 1, 2, 0, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 0, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 39/63 [00:26<00:16,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9459, 0.0158, 0.0383],\n",
            "        [0.7622, 0.0361, 0.2017],\n",
            "        [0.0318, 0.9097, 0.0585],\n",
            "        [0.8643, 0.0217, 0.1140],\n",
            "        [0.9509, 0.0116, 0.0375],\n",
            "        [0.0601, 0.2769, 0.6630],\n",
            "        [0.9428, 0.0234, 0.0338],\n",
            "        [0.0562, 0.1821, 0.7617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9459, 0.0158, 0.0383],\n",
            "        [0.7622, 0.0361, 0.2017],\n",
            "        [0.0318, 0.9097, 0.0585],\n",
            "        [0.8643, 0.0217, 0.1140],\n",
            "        [0.9509, 0.0116, 0.0375],\n",
            "        [0.0601, 0.2769, 0.6630],\n",
            "        [0.9428, 0.0234, 0.0338],\n",
            "        [0.0562, 0.1821, 0.7617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 0, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 0, 0, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 40/63 [00:27<00:15,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8864, 0.0215, 0.0921],\n",
            "        [0.8729, 0.0260, 0.1011],\n",
            "        [0.1381, 0.3813, 0.4806],\n",
            "        [0.7224, 0.0716, 0.2060],\n",
            "        [0.0804, 0.5777, 0.3418],\n",
            "        [0.0184, 0.1320, 0.8497],\n",
            "        [0.9078, 0.0323, 0.0598],\n",
            "        [0.6420, 0.1448, 0.2131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8864, 0.0215, 0.0921],\n",
            "        [0.8729, 0.0260, 0.1011],\n",
            "        [0.1381, 0.3813, 0.4806],\n",
            "        [0.7224, 0.0716, 0.2060],\n",
            "        [0.0804, 0.5777, 0.3418],\n",
            "        [0.0184, 0.1320, 0.8497],\n",
            "        [0.9078, 0.0323, 0.0598],\n",
            "        [0.6420, 0.1448, 0.2131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 1, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 41/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0752, 0.4549, 0.4699],\n",
            "        [0.7456, 0.1037, 0.1506],\n",
            "        [0.0284, 0.8495, 0.1221],\n",
            "        [0.8472, 0.0535, 0.0993],\n",
            "        [0.1645, 0.2360, 0.5995],\n",
            "        [0.0191, 0.9423, 0.0386],\n",
            "        [0.6688, 0.1166, 0.2147],\n",
            "        [0.9403, 0.0337, 0.0260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0752, 0.4549, 0.4699],\n",
            "        [0.7456, 0.1037, 0.1506],\n",
            "        [0.0284, 0.8495, 0.1221],\n",
            "        [0.8472, 0.0535, 0.0993],\n",
            "        [0.1645, 0.2360, 0.5995],\n",
            "        [0.0191, 0.9423, 0.0386],\n",
            "        [0.6688, 0.1166, 0.2147],\n",
            "        [0.9403, 0.0337, 0.0260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 0, 2, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 0, 1, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 42/63 [00:28<00:14,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9513, 0.0096, 0.0391],\n",
            "        [0.1890, 0.1087, 0.7023],\n",
            "        [0.0966, 0.1298, 0.7735],\n",
            "        [0.9536, 0.0151, 0.0313],\n",
            "        [0.4407, 0.0452, 0.5141],\n",
            "        [0.9048, 0.0343, 0.0609],\n",
            "        [0.9705, 0.0127, 0.0168],\n",
            "        [0.4795, 0.0831, 0.4373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9513, 0.0096, 0.0391],\n",
            "        [0.1890, 0.1087, 0.7023],\n",
            "        [0.0966, 0.1298, 0.7735],\n",
            "        [0.9536, 0.0151, 0.0313],\n",
            "        [0.4407, 0.0452, 0.5141],\n",
            "        [0.9048, 0.0343, 0.0609],\n",
            "        [0.9705, 0.0127, 0.0168],\n",
            "        [0.4795, 0.0831, 0.4373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 0, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 2, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 43/63 [00:29<00:13,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9352, 0.0237, 0.0411],\n",
            "        [0.9499, 0.0185, 0.0316],\n",
            "        [0.0343, 0.7427, 0.2230],\n",
            "        [0.6998, 0.1523, 0.1479],\n",
            "        [0.0510, 0.7417, 0.2073],\n",
            "        [0.6608, 0.0283, 0.3110],\n",
            "        [0.6428, 0.0297, 0.3275],\n",
            "        [0.2795, 0.2991, 0.4214]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9352, 0.0237, 0.0411],\n",
            "        [0.9499, 0.0185, 0.0316],\n",
            "        [0.0343, 0.7427, 0.2230],\n",
            "        [0.6998, 0.1523, 0.1479],\n",
            "        [0.0510, 0.7417, 0.2073],\n",
            "        [0.6608, 0.0283, 0.3110],\n",
            "        [0.6428, 0.0297, 0.3275],\n",
            "        [0.2795, 0.2991, 0.4214]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 1, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 0, 1, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 44/63 [00:29<00:13,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0356, 0.9367, 0.0277],\n",
            "        [0.0099, 0.9304, 0.0597],\n",
            "        [0.8989, 0.0221, 0.0790],\n",
            "        [0.8034, 0.0132, 0.1834],\n",
            "        [0.0863, 0.5804, 0.3333],\n",
            "        [0.4428, 0.1551, 0.4021],\n",
            "        [0.0242, 0.9542, 0.0215],\n",
            "        [0.9467, 0.0138, 0.0394]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0356, 0.9367, 0.0277],\n",
            "        [0.0099, 0.9304, 0.0597],\n",
            "        [0.8989, 0.0221, 0.0790],\n",
            "        [0.8034, 0.0132, 0.1834],\n",
            "        [0.0863, 0.5804, 0.3333],\n",
            "        [0.4428, 0.1551, 0.4021],\n",
            "        [0.0242, 0.9542, 0.0215],\n",
            "        [0.9467, 0.0138, 0.0394]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 45/63 [00:30<00:12,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8886, 0.0296, 0.0818],\n",
            "        [0.0243, 0.9249, 0.0508],\n",
            "        [0.0138, 0.2856, 0.7006],\n",
            "        [0.9180, 0.0143, 0.0677],\n",
            "        [0.0151, 0.9229, 0.0620],\n",
            "        [0.0829, 0.0521, 0.8650],\n",
            "        [0.0488, 0.5539, 0.3974],\n",
            "        [0.9282, 0.0252, 0.0466]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8886, 0.0296, 0.0818],\n",
            "        [0.0243, 0.9249, 0.0508],\n",
            "        [0.0138, 0.2856, 0.7006],\n",
            "        [0.9180, 0.0143, 0.0677],\n",
            "        [0.0151, 0.9229, 0.0620],\n",
            "        [0.0829, 0.0521, 0.8650],\n",
            "        [0.0488, 0.5539, 0.3974],\n",
            "        [0.9282, 0.0252, 0.0466]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 0, 1, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 46/63 [00:31<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0204, 0.1391, 0.8404],\n",
            "        [0.1345, 0.1843, 0.6812],\n",
            "        [0.8696, 0.0132, 0.1172],\n",
            "        [0.8970, 0.0156, 0.0874],\n",
            "        [0.9471, 0.0223, 0.0307],\n",
            "        [0.8859, 0.0093, 0.1048],\n",
            "        [0.0134, 0.9290, 0.0576],\n",
            "        [0.0109, 0.9322, 0.0570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0204, 0.1391, 0.8404],\n",
            "        [0.1345, 0.1843, 0.6812],\n",
            "        [0.8696, 0.0132, 0.1172],\n",
            "        [0.8970, 0.0156, 0.0874],\n",
            "        [0.9471, 0.0223, 0.0307],\n",
            "        [0.8859, 0.0093, 0.1048],\n",
            "        [0.0134, 0.9290, 0.0576],\n",
            "        [0.0109, 0.9322, 0.0570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 1, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 47/63 [00:32<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9674, 0.0113, 0.0213],\n",
            "        [0.0307, 0.8987, 0.0706],\n",
            "        [0.0453, 0.4743, 0.4804],\n",
            "        [0.7345, 0.0493, 0.2161],\n",
            "        [0.6608, 0.0232, 0.3160],\n",
            "        [0.3354, 0.0845, 0.5802],\n",
            "        [0.9155, 0.0345, 0.0500],\n",
            "        [0.6615, 0.1922, 0.1463]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9674, 0.0113, 0.0213],\n",
            "        [0.0307, 0.8987, 0.0706],\n",
            "        [0.0453, 0.4743, 0.4804],\n",
            "        [0.7345, 0.0493, 0.2161],\n",
            "        [0.6608, 0.0232, 0.3160],\n",
            "        [0.3354, 0.0845, 0.5802],\n",
            "        [0.9155, 0.0345, 0.0500],\n",
            "        [0.6615, 0.1922, 0.1463]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 0, 0, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 0, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 48/63 [00:32<00:10,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0381, 0.0838, 0.8781],\n",
            "        [0.0167, 0.8657, 0.1175],\n",
            "        [0.9593, 0.0177, 0.0230],\n",
            "        [0.9281, 0.0182, 0.0537],\n",
            "        [0.9397, 0.0263, 0.0340],\n",
            "        [0.9601, 0.0138, 0.0262],\n",
            "        [0.0187, 0.9136, 0.0676],\n",
            "        [0.7568, 0.1228, 0.1203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0381, 0.0838, 0.8781],\n",
            "        [0.0167, 0.8657, 0.1175],\n",
            "        [0.9593, 0.0177, 0.0230],\n",
            "        [0.9281, 0.0182, 0.0537],\n",
            "        [0.9397, 0.0263, 0.0340],\n",
            "        [0.9601, 0.0138, 0.0262],\n",
            "        [0.0187, 0.9136, 0.0676],\n",
            "        [0.7568, 0.1228, 0.1203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 0, 0, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 49/63 [00:33<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2866, 0.1290, 0.5843],\n",
            "        [0.0316, 0.5606, 0.4078],\n",
            "        [0.9359, 0.0236, 0.0405],\n",
            "        [0.0156, 0.9364, 0.0480],\n",
            "        [0.0623, 0.2424, 0.6953],\n",
            "        [0.0314, 0.9343, 0.0343],\n",
            "        [0.0154, 0.9281, 0.0565],\n",
            "        [0.7235, 0.0281, 0.2484]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2866, 0.1290, 0.5843],\n",
            "        [0.0316, 0.5606, 0.4078],\n",
            "        [0.9359, 0.0236, 0.0405],\n",
            "        [0.0156, 0.9364, 0.0480],\n",
            "        [0.0623, 0.2424, 0.6953],\n",
            "        [0.0314, 0.9343, 0.0343],\n",
            "        [0.0154, 0.9281, 0.0565],\n",
            "        [0.7235, 0.0281, 0.2484]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 1, 2, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 1, 2, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 50/63 [00:34<00:09,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0505, 0.0967, 0.8528],\n",
            "        [0.9552, 0.0218, 0.0230],\n",
            "        [0.0191, 0.9242, 0.0566],\n",
            "        [0.9652, 0.0159, 0.0189],\n",
            "        [0.3757, 0.1072, 0.5171],\n",
            "        [0.9323, 0.0360, 0.0317],\n",
            "        [0.3145, 0.3035, 0.3819],\n",
            "        [0.5369, 0.0346, 0.4285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0505, 0.0967, 0.8528],\n",
            "        [0.9552, 0.0218, 0.0230],\n",
            "        [0.0191, 0.9242, 0.0566],\n",
            "        [0.9652, 0.0159, 0.0189],\n",
            "        [0.3757, 0.1072, 0.5171],\n",
            "        [0.9323, 0.0360, 0.0317],\n",
            "        [0.3145, 0.3035, 0.3819],\n",
            "        [0.5369, 0.0346, 0.4285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 0, 2, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 1, 1, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 51/63 [00:34<00:08,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9332, 0.0179, 0.0489],\n",
            "        [0.9492, 0.0154, 0.0354],\n",
            "        [0.0191, 0.6856, 0.2953],\n",
            "        [0.9260, 0.0177, 0.0563],\n",
            "        [0.9463, 0.0251, 0.0286],\n",
            "        [0.2574, 0.1687, 0.5739],\n",
            "        [0.0280, 0.9352, 0.0368],\n",
            "        [0.5851, 0.0873, 0.3276]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9332, 0.0179, 0.0489],\n",
            "        [0.9492, 0.0154, 0.0354],\n",
            "        [0.0191, 0.6856, 0.2953],\n",
            "        [0.9260, 0.0177, 0.0563],\n",
            "        [0.9463, 0.0251, 0.0286],\n",
            "        [0.2574, 0.1687, 0.5739],\n",
            "        [0.0280, 0.9352, 0.0368],\n",
            "        [0.5851, 0.0873, 0.3276]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 0, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 0, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 52/63 [00:35<00:07,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0504, 0.1866, 0.7630],\n",
            "        [0.5203, 0.2458, 0.2339],\n",
            "        [0.0873, 0.1195, 0.7931],\n",
            "        [0.4884, 0.2125, 0.2991],\n",
            "        [0.9689, 0.0049, 0.0263],\n",
            "        [0.4698, 0.3976, 0.1326],\n",
            "        [0.9553, 0.0162, 0.0285],\n",
            "        [0.0179, 0.9125, 0.0695]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0504, 0.1866, 0.7630],\n",
            "        [0.5203, 0.2458, 0.2339],\n",
            "        [0.0873, 0.1195, 0.7931],\n",
            "        [0.4884, 0.2125, 0.2991],\n",
            "        [0.9689, 0.0049, 0.0263],\n",
            "        [0.4698, 0.3976, 0.1326],\n",
            "        [0.9553, 0.0162, 0.0285],\n",
            "        [0.0179, 0.9125, 0.0695]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 2, 0, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 53/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7970, 0.0141, 0.1889],\n",
            "        [0.9467, 0.0168, 0.0365],\n",
            "        [0.9525, 0.0149, 0.0326],\n",
            "        [0.0345, 0.8876, 0.0780],\n",
            "        [0.0191, 0.9539, 0.0271],\n",
            "        [0.8475, 0.0178, 0.1347],\n",
            "        [0.1403, 0.0346, 0.8251],\n",
            "        [0.8868, 0.0325, 0.0807]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7970, 0.0141, 0.1889],\n",
            "        [0.9467, 0.0168, 0.0365],\n",
            "        [0.9525, 0.0149, 0.0326],\n",
            "        [0.0345, 0.8876, 0.0780],\n",
            "        [0.0191, 0.9539, 0.0271],\n",
            "        [0.8475, 0.0178, 0.1347],\n",
            "        [0.1403, 0.0346, 0.8251],\n",
            "        [0.8868, 0.0325, 0.0807]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 1, 1, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 1, 1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 54/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0264, 0.2108, 0.7628],\n",
            "        [0.0203, 0.9019, 0.0778],\n",
            "        [0.1443, 0.0598, 0.7959],\n",
            "        [0.0819, 0.2863, 0.6317],\n",
            "        [0.1298, 0.2181, 0.6520],\n",
            "        [0.7406, 0.0627, 0.1967],\n",
            "        [0.9531, 0.0131, 0.0337],\n",
            "        [0.0082, 0.8064, 0.1854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0264, 0.2108, 0.7628],\n",
            "        [0.0203, 0.9019, 0.0778],\n",
            "        [0.1443, 0.0598, 0.7959],\n",
            "        [0.0819, 0.2863, 0.6317],\n",
            "        [0.1298, 0.2181, 0.6520],\n",
            "        [0.7406, 0.0627, 0.1967],\n",
            "        [0.9531, 0.0131, 0.0337],\n",
            "        [0.0082, 0.8064, 0.1854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 2, 2, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 0, 1, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 55/63 [00:37<00:05,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9389, 0.0302, 0.0309],\n",
            "        [0.0154, 0.8361, 0.1485],\n",
            "        [0.4941, 0.0879, 0.4180],\n",
            "        [0.0377, 0.0412, 0.9211],\n",
            "        [0.0209, 0.6508, 0.3283],\n",
            "        [0.0757, 0.2277, 0.6966],\n",
            "        [0.7435, 0.0246, 0.2319],\n",
            "        [0.0646, 0.1498, 0.7856]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9389, 0.0302, 0.0309],\n",
            "        [0.0154, 0.8361, 0.1485],\n",
            "        [0.4941, 0.0879, 0.4180],\n",
            "        [0.0377, 0.0412, 0.9211],\n",
            "        [0.0209, 0.6508, 0.3283],\n",
            "        [0.0757, 0.2277, 0.6966],\n",
            "        [0.7435, 0.0246, 0.2319],\n",
            "        [0.0646, 0.1498, 0.7856]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 1, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 0, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 56/63 [00:38<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9268, 0.0139, 0.0593],\n",
            "        [0.0970, 0.0874, 0.8156],\n",
            "        [0.0206, 0.1369, 0.8425],\n",
            "        [0.9342, 0.0218, 0.0440],\n",
            "        [0.0426, 0.8899, 0.0675],\n",
            "        [0.8599, 0.0302, 0.1099],\n",
            "        [0.6336, 0.1637, 0.2026],\n",
            "        [0.1178, 0.2261, 0.6561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9268, 0.0139, 0.0593],\n",
            "        [0.0970, 0.0874, 0.8156],\n",
            "        [0.0206, 0.1369, 0.8425],\n",
            "        [0.9342, 0.0218, 0.0440],\n",
            "        [0.0426, 0.8899, 0.0675],\n",
            "        [0.8599, 0.0302, 0.1099],\n",
            "        [0.6336, 0.1637, 0.2026],\n",
            "        [0.1178, 0.2261, 0.6561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 0, 1, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 1, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 57/63 [00:38<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8525, 0.0809, 0.0667],\n",
            "        [0.3944, 0.3285, 0.2770],\n",
            "        [0.0096, 0.9486, 0.0418],\n",
            "        [0.0259, 0.8805, 0.0937],\n",
            "        [0.9516, 0.0091, 0.0393],\n",
            "        [0.0573, 0.0710, 0.8716],\n",
            "        [0.1040, 0.1022, 0.7938],\n",
            "        [0.0575, 0.2256, 0.7169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8525, 0.0809, 0.0667],\n",
            "        [0.3944, 0.3285, 0.2770],\n",
            "        [0.0096, 0.9486, 0.0418],\n",
            "        [0.0259, 0.8805, 0.0937],\n",
            "        [0.9516, 0.0091, 0.0393],\n",
            "        [0.0573, 0.0710, 0.8716],\n",
            "        [0.1040, 0.1022, 0.7938],\n",
            "        [0.0575, 0.2256, 0.7169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 1, 0, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 0, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 58/63 [00:39<00:03,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0179, 0.7412, 0.2408],\n",
            "        [0.9518, 0.0175, 0.0306],\n",
            "        [0.9426, 0.0148, 0.0426],\n",
            "        [0.0768, 0.2399, 0.6834],\n",
            "        [0.9613, 0.0188, 0.0199],\n",
            "        [0.0115, 0.9603, 0.0281],\n",
            "        [0.0481, 0.0749, 0.8770],\n",
            "        [0.0381, 0.5577, 0.4043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0179, 0.7412, 0.2408],\n",
            "        [0.9518, 0.0175, 0.0306],\n",
            "        [0.9426, 0.0148, 0.0426],\n",
            "        [0.0768, 0.2399, 0.6834],\n",
            "        [0.9613, 0.0188, 0.0199],\n",
            "        [0.0115, 0.9603, 0.0281],\n",
            "        [0.0481, 0.0749, 0.8770],\n",
            "        [0.0381, 0.5577, 0.4043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 2, 0, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 2, 0, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 59/63 [00:40<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0164, 0.8337, 0.1499],\n",
            "        [0.4502, 0.2276, 0.3222],\n",
            "        [0.0495, 0.3313, 0.6193],\n",
            "        [0.8845, 0.0151, 0.1004],\n",
            "        [0.0117, 0.8085, 0.1798],\n",
            "        [0.0217, 0.4448, 0.5335],\n",
            "        [0.9457, 0.0134, 0.0408],\n",
            "        [0.0903, 0.2325, 0.6772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0164, 0.8337, 0.1499],\n",
            "        [0.4502, 0.2276, 0.3222],\n",
            "        [0.0495, 0.3313, 0.6193],\n",
            "        [0.8845, 0.0151, 0.1004],\n",
            "        [0.0117, 0.8085, 0.1798],\n",
            "        [0.0217, 0.4448, 0.5335],\n",
            "        [0.9457, 0.0134, 0.0408],\n",
            "        [0.0903, 0.2325, 0.6772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 0, 1, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 0, 2, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 60/63 [00:41<00:02,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4155, 0.1436, 0.4409],\n",
            "        [0.0465, 0.1239, 0.8297],\n",
            "        [0.9067, 0.0245, 0.0688],\n",
            "        [0.9590, 0.0113, 0.0297],\n",
            "        [0.0171, 0.8734, 0.1095],\n",
            "        [0.0557, 0.3202, 0.6241],\n",
            "        [0.8937, 0.0220, 0.0843],\n",
            "        [0.0159, 0.6022, 0.3819]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4155, 0.1436, 0.4409],\n",
            "        [0.0465, 0.1239, 0.8297],\n",
            "        [0.9067, 0.0245, 0.0688],\n",
            "        [0.9590, 0.0113, 0.0297],\n",
            "        [0.0171, 0.8734, 0.1095],\n",
            "        [0.0557, 0.3202, 0.6241],\n",
            "        [0.8937, 0.0220, 0.0843],\n",
            "        [0.0159, 0.6022, 0.3819]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 0, 1, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 0, 1, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 61/63 [00:41<00:01,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0251, 0.4191, 0.5558],\n",
            "        [0.0193, 0.4725, 0.5083],\n",
            "        [0.9685, 0.0121, 0.0194],\n",
            "        [0.0105, 0.9220, 0.0675],\n",
            "        [0.9737, 0.0066, 0.0197],\n",
            "        [0.1476, 0.5134, 0.3390],\n",
            "        [0.9572, 0.0118, 0.0309],\n",
            "        [0.0130, 0.9282, 0.0588]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0251, 0.4191, 0.5558],\n",
            "        [0.0193, 0.4725, 0.5083],\n",
            "        [0.9685, 0.0121, 0.0194],\n",
            "        [0.0105, 0.9220, 0.0675],\n",
            "        [0.9737, 0.0066, 0.0197],\n",
            "        [0.1476, 0.5134, 0.3390],\n",
            "        [0.9572, 0.0118, 0.0309],\n",
            "        [0.0130, 0.9282, 0.0588]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 2, 0, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 62/63 [00:42<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4726, 0.0469, 0.4806],\n",
            "        [0.0138, 0.9507, 0.0355],\n",
            "        [0.2229, 0.0766, 0.7005],\n",
            "        [0.0753, 0.2368, 0.6879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4726, 0.0469, 0.4806],\n",
            "        [0.0138, 0.9507, 0.0355],\n",
            "        [0.2229, 0.0766, 0.7005],\n",
            "        [0.0753, 0.2368, 0.6879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0319, 0.0432, 0.9248],\n",
            "        [0.0187, 0.8176, 0.1637],\n",
            "        [0.9369, 0.0215, 0.0416],\n",
            "        [0.0605, 0.0828, 0.8568],\n",
            "        [0.8609, 0.0567, 0.0824],\n",
            "        [0.0393, 0.9391, 0.0216],\n",
            "        [0.0203, 0.1090, 0.8707],\n",
            "        [0.9645, 0.0226, 0.0128]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 2, 0, 1, 2, 0], device='cuda:0')\n",
            "tensor([[0.0319, 0.0432, 0.9248],\n",
            "        [0.0187, 0.8176, 0.1637],\n",
            "        [0.9369, 0.0215, 0.0416],\n",
            "        [0.0605, 0.0828, 0.8568],\n",
            "        [0.8609, 0.0567, 0.0824],\n",
            "        [0.0393, 0.9391, 0.0216],\n",
            "        [0.0203, 0.1090, 0.8707],\n",
            "        [0.9645, 0.0226, 0.0128]], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0566, 0.2810, 0.6624],\n",
            "        [0.0372, 0.0561, 0.9067],\n",
            "        [0.0084, 0.8982, 0.0934],\n",
            "        [0.0977, 0.1104, 0.7920],\n",
            "        [0.0762, 0.3359, 0.5879],\n",
            "        [0.0178, 0.9404, 0.0418],\n",
            "        [0.9668, 0.0086, 0.0246],\n",
            "        [0.0319, 0.3764, 0.5917]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "tensor([[0.0566, 0.2810, 0.6624],\n",
            "        [0.0372, 0.0561, 0.9067],\n",
            "        [0.0084, 0.8982, 0.0934],\n",
            "        [0.0977, 0.1104, 0.7920],\n",
            "        [0.0762, 0.3359, 0.5879],\n",
            "        [0.0178, 0.9404, 0.0418],\n",
            "        [0.9668, 0.0086, 0.0246],\n",
            "        [0.0319, 0.3764, 0.5917]], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0223, 0.8730, 0.1047],\n",
            "        [0.1103, 0.0780, 0.8117],\n",
            "        [0.9709, 0.0125, 0.0167],\n",
            "        [0.0254, 0.4169, 0.5578],\n",
            "        [0.0479, 0.0332, 0.9189],\n",
            "        [0.0487, 0.0294, 0.9218],\n",
            "        [0.0092, 0.7199, 0.2709],\n",
            "        [0.9318, 0.0107, 0.0575]], device='cuda:0')\n",
            "prediction: tensor([1, 2, 0, 2, 2, 2, 1, 0], device='cuda:0')\n",
            "tensor([[0.0223, 0.8730, 0.1047],\n",
            "        [0.1103, 0.0780, 0.8117],\n",
            "        [0.9709, 0.0125, 0.0167],\n",
            "        [0.0254, 0.4169, 0.5578],\n",
            "        [0.0479, 0.0332, 0.9189],\n",
            "        [0.0487, 0.0294, 0.9218],\n",
            "        [0.0092, 0.7199, 0.2709],\n",
            "        [0.9318, 0.0107, 0.0575]], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0382, 0.8695, 0.0924],\n",
            "        [0.8784, 0.0420, 0.0796],\n",
            "        [0.0274, 0.2330, 0.7397],\n",
            "        [0.0514, 0.2358, 0.7128],\n",
            "        [0.0309, 0.9017, 0.0674],\n",
            "        [0.7853, 0.0247, 0.1900],\n",
            "        [0.1034, 0.0281, 0.8685],\n",
            "        [0.7684, 0.0255, 0.2060]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.0382, 0.8695, 0.0924],\n",
            "        [0.8784, 0.0420, 0.0796],\n",
            "        [0.0274, 0.2330, 0.7397],\n",
            "        [0.0514, 0.2358, 0.7128],\n",
            "        [0.0309, 0.9017, 0.0674],\n",
            "        [0.7853, 0.0247, 0.1900],\n",
            "        [0.1034, 0.0281, 0.8685],\n",
            "        [0.7684, 0.0255, 0.2060]], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0052, 0.9706, 0.0242],\n",
            "        [0.0105, 0.9033, 0.0862],\n",
            "        [0.2383, 0.0444, 0.7173],\n",
            "        [0.9065, 0.0215, 0.0720],\n",
            "        [0.0068, 0.8907, 0.1025],\n",
            "        [0.8917, 0.0255, 0.0828],\n",
            "        [0.0273, 0.0697, 0.9031],\n",
            "        [0.0641, 0.0676, 0.8683]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "tensor([[0.0052, 0.9706, 0.0242],\n",
            "        [0.0105, 0.9033, 0.0862],\n",
            "        [0.2383, 0.0444, 0.7173],\n",
            "        [0.9065, 0.0215, 0.0720],\n",
            "        [0.0068, 0.8907, 0.1025],\n",
            "        [0.8917, 0.0255, 0.0828],\n",
            "        [0.0273, 0.0697, 0.9031],\n",
            "        [0.0641, 0.0676, 0.8683]], device='cuda:0')\n",
            "tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.7924, 0.0208, 0.1868],\n",
            "        [0.0118, 0.9076, 0.0806],\n",
            "        [0.0399, 0.2703, 0.6899],\n",
            "        [0.9456, 0.0123, 0.0421],\n",
            "        [0.9150, 0.0154, 0.0696],\n",
            "        [0.9630, 0.0140, 0.0230],\n",
            "        [0.0316, 0.0775, 0.8909],\n",
            "        [0.0560, 0.2019, 0.7422]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 2, 0, 0, 0, 2, 2], device='cuda:0')\n",
            "tensor([[0.7924, 0.0208, 0.1868],\n",
            "        [0.0118, 0.9076, 0.0806],\n",
            "        [0.0399, 0.2703, 0.6899],\n",
            "        [0.9456, 0.0123, 0.0421],\n",
            "        [0.9150, 0.0154, 0.0696],\n",
            "        [0.9630, 0.0140, 0.0230],\n",
            "        [0.0316, 0.0775, 0.8909],\n",
            "        [0.0560, 0.2019, 0.7422]], device='cuda:0')\n",
            "tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0180, 0.8846, 0.0973],\n",
            "        [0.9020, 0.0306, 0.0674],\n",
            "        [0.0287, 0.2379, 0.7335],\n",
            "        [0.0182, 0.6506, 0.3312],\n",
            "        [0.0462, 0.1147, 0.8391],\n",
            "        [0.0376, 0.0978, 0.8646],\n",
            "        [0.0094, 0.8551, 0.1355],\n",
            "        [0.1250, 0.6650, 0.2100]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 1, 2, 2, 1, 1], device='cuda:0')\n",
            "tensor([[0.0180, 0.8846, 0.0973],\n",
            "        [0.9020, 0.0306, 0.0674],\n",
            "        [0.0287, 0.2379, 0.7335],\n",
            "        [0.0182, 0.6506, 0.3312],\n",
            "        [0.0462, 0.1147, 0.8391],\n",
            "        [0.0376, 0.0978, 0.8646],\n",
            "        [0.0094, 0.8551, 0.1355],\n",
            "        [0.1250, 0.6650, 0.2100]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9207, 0.0360, 0.0433],\n",
            "        [0.6023, 0.2278, 0.1699],\n",
            "        [0.4538, 0.3954, 0.1508],\n",
            "        [0.6289, 0.1467, 0.2244],\n",
            "        [0.7347, 0.1586, 0.1067],\n",
            "        [0.5494, 0.2932, 0.1574],\n",
            "        [0.0419, 0.2545, 0.7036],\n",
            "        [0.6325, 0.1656, 0.2019]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 0, 0, 0, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.9207, 0.0360, 0.0433],\n",
            "        [0.6023, 0.2278, 0.1699],\n",
            "        [0.4538, 0.3954, 0.1508],\n",
            "        [0.6289, 0.1467, 0.2244],\n",
            "        [0.7347, 0.1586, 0.1067],\n",
            "        [0.5494, 0.2932, 0.1574],\n",
            "        [0.0419, 0.2545, 0.7036],\n",
            "        [0.6325, 0.1656, 0.2019]], device='cuda:0')\n",
            "tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0237, 0.4856, 0.4907],\n",
            "        [0.2097, 0.4913, 0.2990],\n",
            "        [0.0133, 0.8728, 0.1139],\n",
            "        [0.3409, 0.5226, 0.1365],\n",
            "        [0.5575, 0.3485, 0.0940],\n",
            "        [0.0292, 0.1173, 0.8535],\n",
            "        [0.7169, 0.1101, 0.1730],\n",
            "        [0.4341, 0.1705, 0.3954]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 1, 1, 0, 2, 0, 0], device='cuda:0')\n",
            "tensor([[0.0237, 0.4856, 0.4907],\n",
            "        [0.2097, 0.4913, 0.2990],\n",
            "        [0.0133, 0.8728, 0.1139],\n",
            "        [0.3409, 0.5226, 0.1365],\n",
            "        [0.5575, 0.3485, 0.0940],\n",
            "        [0.0292, 0.1173, 0.8535],\n",
            "        [0.7169, 0.1101, 0.1730],\n",
            "        [0.4341, 0.1705, 0.3954]], device='cuda:0')\n",
            "tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.3189, 0.3767, 0.3045],\n",
            "        [0.0349, 0.0785, 0.8866],\n",
            "        [0.6757, 0.1495, 0.1748],\n",
            "        [0.0366, 0.0552, 0.9083],\n",
            "        [0.4757, 0.2750, 0.2493],\n",
            "        [0.9436, 0.0262, 0.0302],\n",
            "        [0.0175, 0.9101, 0.0724],\n",
            "        [0.7307, 0.0305, 0.2387]], device='cuda:0')\n",
            "prediction: tensor([1, 2, 0, 2, 0, 0, 1, 0], device='cuda:0')\n",
            "tensor([[0.3189, 0.3767, 0.3045],\n",
            "        [0.0349, 0.0785, 0.8866],\n",
            "        [0.6757, 0.1495, 0.1748],\n",
            "        [0.0366, 0.0552, 0.9083],\n",
            "        [0.4757, 0.2750, 0.2493],\n",
            "        [0.9436, 0.0262, 0.0302],\n",
            "        [0.0175, 0.9101, 0.0724],\n",
            "        [0.7307, 0.0305, 0.2387]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.0407, 0.0573, 0.9020],\n",
            "        [0.5411, 0.2229, 0.2361],\n",
            "        [0.4915, 0.2765, 0.2320],\n",
            "        [0.9489, 0.0240, 0.0271],\n",
            "        [0.6760, 0.1301, 0.1939],\n",
            "        [0.2868, 0.4234, 0.2897],\n",
            "        [0.1398, 0.0661, 0.7941],\n",
            "        [0.0093, 0.9016, 0.0891]], device='cuda:0')\n",
            "prediction: tensor([2, 0, 0, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "tensor([[0.0407, 0.0573, 0.9020],\n",
            "        [0.5411, 0.2229, 0.2361],\n",
            "        [0.4915, 0.2765, 0.2320],\n",
            "        [0.9489, 0.0240, 0.0271],\n",
            "        [0.6760, 0.1301, 0.1939],\n",
            "        [0.2868, 0.4234, 0.2897],\n",
            "        [0.1398, 0.0661, 0.7941],\n",
            "        [0.0093, 0.9016, 0.0891]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.9459, 0.0268, 0.0273],\n",
            "        [0.0361, 0.0557, 0.9083],\n",
            "        [0.0116, 0.9564, 0.0319],\n",
            "        [0.8571, 0.0263, 0.1165],\n",
            "        [0.0070, 0.9715, 0.0214],\n",
            "        [0.0376, 0.0663, 0.8962],\n",
            "        [0.0055, 0.9292, 0.0653],\n",
            "        [0.0403, 0.0967, 0.8630]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([[0.9459, 0.0268, 0.0273],\n",
            "        [0.0361, 0.0557, 0.9083],\n",
            "        [0.0116, 0.9564, 0.0319],\n",
            "        [0.8571, 0.0263, 0.1165],\n",
            "        [0.0070, 0.9715, 0.0214],\n",
            "        [0.0376, 0.0663, 0.8962],\n",
            "        [0.0055, 0.9292, 0.0653],\n",
            "        [0.0403, 0.0967, 0.8630]], device='cuda:0')\n",
            "tensor([0, 2, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9723, 0.0103, 0.0173],\n",
            "        [0.0324, 0.0790, 0.8886],\n",
            "        [0.0279, 0.1800, 0.7921],\n",
            "        [0.9603, 0.0151, 0.0247]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 2, 0], device='cuda:0')\n",
            "tensor([[0.9723, 0.0103, 0.0173],\n",
            "        [0.0324, 0.0790, 0.8886],\n",
            "        [0.0279, 0.1800, 0.7921],\n",
            "        [0.9603, 0.0151, 0.0247]], device='cuda:0')\n",
            "Epochs: 5 | Train Loss:  0.111             | Train Accuracy:  0.696             | Val Loss:  0.099             | Val Accuracy:  0.820\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6141, 0.1923, 0.1936],\n",
            "        [0.0117, 0.9446, 0.0437],\n",
            "        [0.0752, 0.0506, 0.8742],\n",
            "        [0.0841, 0.2541, 0.6618],\n",
            "        [0.1177, 0.0216, 0.8607],\n",
            "        [0.0065, 0.9503, 0.0432],\n",
            "        [0.2898, 0.0336, 0.6766],\n",
            "        [0.0338, 0.0422, 0.9240]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6141, 0.1923, 0.1936],\n",
            "        [0.0117, 0.9446, 0.0437],\n",
            "        [0.0752, 0.0506, 0.8742],\n",
            "        [0.0841, 0.2541, 0.6618],\n",
            "        [0.1177, 0.0216, 0.8607],\n",
            "        [0.0065, 0.9503, 0.0432],\n",
            "        [0.2898, 0.0336, 0.6766],\n",
            "        [0.0338, 0.0422, 0.9240]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 2, 2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 2, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/63 [00:00<00:46,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0341, 0.5989, 0.3670],\n",
            "        [0.0207, 0.5399, 0.4394],\n",
            "        [0.0466, 0.0481, 0.9053],\n",
            "        [0.9535, 0.0102, 0.0363],\n",
            "        [0.8185, 0.0200, 0.1616],\n",
            "        [0.0832, 0.0481, 0.8687],\n",
            "        [0.0231, 0.5535, 0.4233],\n",
            "        [0.0320, 0.0375, 0.9306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0341, 0.5989, 0.3670],\n",
            "        [0.0207, 0.5399, 0.4394],\n",
            "        [0.0466, 0.0481, 0.9053],\n",
            "        [0.9535, 0.0102, 0.0363],\n",
            "        [0.8185, 0.0200, 0.1616],\n",
            "        [0.0832, 0.0481, 0.8687],\n",
            "        [0.0231, 0.5535, 0.4233],\n",
            "        [0.0320, 0.0375, 0.9306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 0, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 0, 0, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/63 [00:01<00:42,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7368, 0.1612, 0.1020],\n",
            "        [0.0306, 0.9472, 0.0223],\n",
            "        [0.8978, 0.0277, 0.0745],\n",
            "        [0.9715, 0.0144, 0.0141],\n",
            "        [0.9432, 0.0104, 0.0464],\n",
            "        [0.5888, 0.2998, 0.1114],\n",
            "        [0.0073, 0.9250, 0.0678],\n",
            "        [0.9733, 0.0122, 0.0145]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7368, 0.1612, 0.1020],\n",
            "        [0.0306, 0.9472, 0.0223],\n",
            "        [0.8978, 0.0277, 0.0745],\n",
            "        [0.9715, 0.0144, 0.0141],\n",
            "        [0.9432, 0.0104, 0.0464],\n",
            "        [0.5888, 0.2998, 0.1114],\n",
            "        [0.0073, 0.9250, 0.0678],\n",
            "        [0.9733, 0.0122, 0.0145]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 0, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/63 [00:02<00:40,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0166, 0.8866, 0.0968],\n",
            "        [0.2119, 0.0347, 0.7534],\n",
            "        [0.9210, 0.0397, 0.0393],\n",
            "        [0.0336, 0.1108, 0.8556],\n",
            "        [0.1105, 0.2619, 0.6276],\n",
            "        [0.5662, 0.2623, 0.1714],\n",
            "        [0.9755, 0.0076, 0.0168],\n",
            "        [0.1097, 0.6246, 0.2657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0166, 0.8866, 0.0968],\n",
            "        [0.2119, 0.0347, 0.7534],\n",
            "        [0.9210, 0.0397, 0.0393],\n",
            "        [0.0336, 0.1108, 0.8556],\n",
            "        [0.1105, 0.2619, 0.6276],\n",
            "        [0.5662, 0.2623, 0.1714],\n",
            "        [0.9755, 0.0076, 0.0168],\n",
            "        [0.1097, 0.6246, 0.2657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 2, 2, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 2, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/63 [00:02<00:39,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9380, 0.0184, 0.0436],\n",
            "        [0.9623, 0.0178, 0.0198],\n",
            "        [0.0095, 0.9519, 0.0386],\n",
            "        [0.0482, 0.8315, 0.1202],\n",
            "        [0.0732, 0.0720, 0.8548],\n",
            "        [0.9401, 0.0300, 0.0299],\n",
            "        [0.9274, 0.0274, 0.0453],\n",
            "        [0.0132, 0.9489, 0.0379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9380, 0.0184, 0.0436],\n",
            "        [0.9623, 0.0178, 0.0198],\n",
            "        [0.0095, 0.9519, 0.0386],\n",
            "        [0.0482, 0.8315, 0.1202],\n",
            "        [0.0732, 0.0720, 0.8548],\n",
            "        [0.9401, 0.0300, 0.0299],\n",
            "        [0.9274, 0.0274, 0.0453],\n",
            "        [0.0132, 0.9489, 0.0379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 1, 2, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 1, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/63 [00:03<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0652, 0.5635, 0.3712],\n",
            "        [0.0546, 0.3576, 0.5878],\n",
            "        [0.6010, 0.3404, 0.0587],\n",
            "        [0.2508, 0.3291, 0.4202],\n",
            "        [0.0663, 0.2169, 0.7168],\n",
            "        [0.7729, 0.0655, 0.1616],\n",
            "        [0.0106, 0.9643, 0.0251],\n",
            "        [0.0575, 0.1820, 0.7605]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0652, 0.5635, 0.3712],\n",
            "        [0.0546, 0.3576, 0.5878],\n",
            "        [0.6010, 0.3404, 0.0587],\n",
            "        [0.2508, 0.3291, 0.4202],\n",
            "        [0.0663, 0.2169, 0.7168],\n",
            "        [0.7729, 0.0655, 0.1616],\n",
            "        [0.0106, 0.9643, 0.0251],\n",
            "        [0.0575, 0.1820, 0.7605]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 2, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 0, 2, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 6/63 [00:04<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1371, 0.0714, 0.7916],\n",
            "        [0.9537, 0.0234, 0.0228],\n",
            "        [0.9618, 0.0139, 0.0243],\n",
            "        [0.0187, 0.9567, 0.0246],\n",
            "        [0.9076, 0.0661, 0.0263],\n",
            "        [0.9649, 0.0138, 0.0213],\n",
            "        [0.0168, 0.2670, 0.7162],\n",
            "        [0.0919, 0.1428, 0.7653]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1371, 0.0714, 0.7916],\n",
            "        [0.9537, 0.0234, 0.0228],\n",
            "        [0.9618, 0.0139, 0.0243],\n",
            "        [0.0187, 0.9567, 0.0246],\n",
            "        [0.9076, 0.0661, 0.0263],\n",
            "        [0.9649, 0.0138, 0.0213],\n",
            "        [0.0168, 0.2670, 0.7162],\n",
            "        [0.0919, 0.1428, 0.7653]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 1, 0, 0, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 1, 0, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/63 [00:04<00:37,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1562, 0.3715, 0.4723],\n",
            "        [0.9758, 0.0116, 0.0126],\n",
            "        [0.8101, 0.0972, 0.0927],\n",
            "        [0.8699, 0.0699, 0.0602],\n",
            "        [0.5752, 0.2282, 0.1967],\n",
            "        [0.9722, 0.0152, 0.0126],\n",
            "        [0.9751, 0.0139, 0.0110],\n",
            "        [0.9526, 0.0150, 0.0324]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1562, 0.3715, 0.4723],\n",
            "        [0.9758, 0.0116, 0.0126],\n",
            "        [0.8101, 0.0972, 0.0927],\n",
            "        [0.8699, 0.0699, 0.0602],\n",
            "        [0.5752, 0.2282, 0.1967],\n",
            "        [0.9722, 0.0152, 0.0126],\n",
            "        [0.9751, 0.0139, 0.0110],\n",
            "        [0.9526, 0.0150, 0.0324]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/63 [00:05<00:36,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9729, 0.0148, 0.0122],\n",
            "        [0.1035, 0.1666, 0.7299],\n",
            "        [0.9499, 0.0308, 0.0193],\n",
            "        [0.9425, 0.0323, 0.0252],\n",
            "        [0.9590, 0.0203, 0.0207],\n",
            "        [0.0316, 0.1605, 0.8078],\n",
            "        [0.9599, 0.0234, 0.0166],\n",
            "        [0.0161, 0.9634, 0.0205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9729, 0.0148, 0.0122],\n",
            "        [0.1035, 0.1666, 0.7299],\n",
            "        [0.9499, 0.0308, 0.0193],\n",
            "        [0.9425, 0.0323, 0.0252],\n",
            "        [0.9590, 0.0203, 0.0207],\n",
            "        [0.0316, 0.1605, 0.8078],\n",
            "        [0.9599, 0.0234, 0.0166],\n",
            "        [0.0161, 0.9634, 0.0205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 0, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 0, 0, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/63 [00:06<00:35,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0307, 0.9332, 0.0361],\n",
            "        [0.8830, 0.0963, 0.0207],\n",
            "        [0.9621, 0.0148, 0.0231],\n",
            "        [0.9796, 0.0096, 0.0108],\n",
            "        [0.9490, 0.0321, 0.0189],\n",
            "        [0.0253, 0.1683, 0.8064],\n",
            "        [0.0722, 0.1968, 0.7311],\n",
            "        [0.0112, 0.9486, 0.0402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0307, 0.9332, 0.0361],\n",
            "        [0.8830, 0.0963, 0.0207],\n",
            "        [0.9621, 0.0148, 0.0231],\n",
            "        [0.9796, 0.0096, 0.0108],\n",
            "        [0.9490, 0.0321, 0.0189],\n",
            "        [0.0253, 0.1683, 0.8064],\n",
            "        [0.0722, 0.1968, 0.7311],\n",
            "        [0.0112, 0.9486, 0.0402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 0, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/63 [00:06<00:35,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0614, 0.8313, 0.1073],\n",
            "        [0.0201, 0.8346, 0.1453],\n",
            "        [0.9680, 0.0149, 0.0171],\n",
            "        [0.3603, 0.0933, 0.5464],\n",
            "        [0.0284, 0.0495, 0.9221],\n",
            "        [0.0153, 0.9557, 0.0291],\n",
            "        [0.9107, 0.0294, 0.0599],\n",
            "        [0.0404, 0.2276, 0.7321]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0614, 0.8313, 0.1073],\n",
            "        [0.0201, 0.8346, 0.1453],\n",
            "        [0.9680, 0.0149, 0.0171],\n",
            "        [0.3603, 0.0933, 0.5464],\n",
            "        [0.0284, 0.0495, 0.9221],\n",
            "        [0.0153, 0.9557, 0.0291],\n",
            "        [0.9107, 0.0294, 0.0599],\n",
            "        [0.0404, 0.2276, 0.7321]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 2, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/63 [00:07<00:34,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1656, 0.0865, 0.7479],\n",
            "        [0.0066, 0.9756, 0.0178],\n",
            "        [0.0512, 0.8867, 0.0621],\n",
            "        [0.9258, 0.0384, 0.0358],\n",
            "        [0.0068, 0.9652, 0.0280],\n",
            "        [0.9327, 0.0345, 0.0328],\n",
            "        [0.1021, 0.2005, 0.6974],\n",
            "        [0.0193, 0.9576, 0.0231]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1656, 0.0865, 0.7479],\n",
            "        [0.0066, 0.9756, 0.0178],\n",
            "        [0.0512, 0.8867, 0.0621],\n",
            "        [0.9258, 0.0384, 0.0358],\n",
            "        [0.0068, 0.9652, 0.0280],\n",
            "        [0.9327, 0.0345, 0.0328],\n",
            "        [0.1021, 0.2005, 0.6974],\n",
            "        [0.0193, 0.9576, 0.0231]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 0, 1, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 1, 1, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/63 [00:08<00:34,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0306, 0.9286, 0.0408],\n",
            "        [0.0319, 0.1314, 0.8367],\n",
            "        [0.0077, 0.9695, 0.0228],\n",
            "        [0.9761, 0.0137, 0.0102],\n",
            "        [0.8196, 0.0234, 0.1570],\n",
            "        [0.8117, 0.1007, 0.0877],\n",
            "        [0.0127, 0.8229, 0.1643],\n",
            "        [0.1074, 0.7856, 0.1070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0306, 0.9286, 0.0408],\n",
            "        [0.0319, 0.1314, 0.8367],\n",
            "        [0.0077, 0.9695, 0.0228],\n",
            "        [0.9761, 0.0137, 0.0102],\n",
            "        [0.8196, 0.0234, 0.1570],\n",
            "        [0.8117, 0.1007, 0.0877],\n",
            "        [0.0127, 0.8229, 0.1643],\n",
            "        [0.1074, 0.7856, 0.1070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 0, 2, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 13/63 [00:08<00:33,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0055, 0.9651, 0.0294],\n",
            "        [0.0054, 0.9454, 0.0491],\n",
            "        [0.3506, 0.5596, 0.0898],\n",
            "        [0.0088, 0.9695, 0.0218],\n",
            "        [0.8193, 0.0812, 0.0994],\n",
            "        [0.0136, 0.9259, 0.0605],\n",
            "        [0.1112, 0.0429, 0.8459],\n",
            "        [0.0207, 0.9106, 0.0686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0055, 0.9651, 0.0294],\n",
            "        [0.0054, 0.9454, 0.0491],\n",
            "        [0.3506, 0.5596, 0.0898],\n",
            "        [0.0088, 0.9695, 0.0218],\n",
            "        [0.8193, 0.0812, 0.0994],\n",
            "        [0.0136, 0.9259, 0.0605],\n",
            "        [0.1112, 0.0429, 0.8459],\n",
            "        [0.0207, 0.9106, 0.0686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 1, 0, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 1, 0, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/63 [00:09<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0296, 0.9278, 0.0426],\n",
            "        [0.9694, 0.0152, 0.0155],\n",
            "        [0.9692, 0.0067, 0.0241],\n",
            "        [0.9617, 0.0254, 0.0129],\n",
            "        [0.0068, 0.9760, 0.0172],\n",
            "        [0.4562, 0.3335, 0.2102],\n",
            "        [0.7060, 0.1659, 0.1281],\n",
            "        [0.0600, 0.1689, 0.7710]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0296, 0.9278, 0.0426],\n",
            "        [0.9694, 0.0152, 0.0155],\n",
            "        [0.9692, 0.0067, 0.0241],\n",
            "        [0.9617, 0.0254, 0.0129],\n",
            "        [0.0068, 0.9760, 0.0172],\n",
            "        [0.4562, 0.3335, 0.2102],\n",
            "        [0.7060, 0.1659, 0.1281],\n",
            "        [0.0600, 0.1689, 0.7710]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 1, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 1, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 15/63 [00:10<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9452, 0.0433, 0.0115],\n",
            "        [0.0301, 0.9396, 0.0303],\n",
            "        [0.9377, 0.0196, 0.0427],\n",
            "        [0.9711, 0.0179, 0.0110],\n",
            "        [0.0179, 0.9511, 0.0309],\n",
            "        [0.9780, 0.0135, 0.0084],\n",
            "        [0.0297, 0.0826, 0.8877],\n",
            "        [0.0135, 0.9511, 0.0354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9452, 0.0433, 0.0115],\n",
            "        [0.0301, 0.9396, 0.0303],\n",
            "        [0.9377, 0.0196, 0.0427],\n",
            "        [0.9711, 0.0179, 0.0110],\n",
            "        [0.0179, 0.9511, 0.0309],\n",
            "        [0.9780, 0.0135, 0.0084],\n",
            "        [0.0297, 0.0826, 0.8877],\n",
            "        [0.0135, 0.9511, 0.0354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 1, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 0, 1, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/63 [00:10<00:31,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0828, 0.0291, 0.8881],\n",
            "        [0.0379, 0.2460, 0.7161],\n",
            "        [0.8904, 0.0719, 0.0378],\n",
            "        [0.1537, 0.0571, 0.7892],\n",
            "        [0.0102, 0.9699, 0.0199],\n",
            "        [0.0206, 0.9562, 0.0233],\n",
            "        [0.9644, 0.0144, 0.0213],\n",
            "        [0.9814, 0.0092, 0.0095]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0828, 0.0291, 0.8881],\n",
            "        [0.0379, 0.2460, 0.7161],\n",
            "        [0.8904, 0.0719, 0.0378],\n",
            "        [0.1537, 0.0571, 0.7892],\n",
            "        [0.0102, 0.9699, 0.0199],\n",
            "        [0.0206, 0.9562, 0.0233],\n",
            "        [0.9644, 0.0144, 0.0213],\n",
            "        [0.9814, 0.0092, 0.0095]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 2, 1, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 2, 1, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/63 [00:11<00:31,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0247, 0.5081, 0.4672],\n",
            "        [0.2072, 0.0992, 0.6936],\n",
            "        [0.9795, 0.0108, 0.0097],\n",
            "        [0.9387, 0.0138, 0.0475],\n",
            "        [0.0207, 0.9267, 0.0526],\n",
            "        [0.9335, 0.0281, 0.0385],\n",
            "        [0.9721, 0.0160, 0.0120],\n",
            "        [0.7283, 0.2431, 0.0286]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0247, 0.5081, 0.4672],\n",
            "        [0.2072, 0.0992, 0.6936],\n",
            "        [0.9795, 0.0108, 0.0097],\n",
            "        [0.9387, 0.0138, 0.0475],\n",
            "        [0.0207, 0.9267, 0.0526],\n",
            "        [0.9335, 0.0281, 0.0385],\n",
            "        [0.9721, 0.0160, 0.0120],\n",
            "        [0.7283, 0.2431, 0.0286]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 0, 1, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 18/63 [00:12<00:30,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0181, 0.3333, 0.6486],\n",
            "        [0.9735, 0.0106, 0.0159],\n",
            "        [0.9258, 0.0290, 0.0453],\n",
            "        [0.3103, 0.0499, 0.6399],\n",
            "        [0.0120, 0.9299, 0.0581],\n",
            "        [0.0088, 0.8856, 0.1055],\n",
            "        [0.0730, 0.0732, 0.8538],\n",
            "        [0.0103, 0.9295, 0.0602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0181, 0.3333, 0.6486],\n",
            "        [0.9735, 0.0106, 0.0159],\n",
            "        [0.9258, 0.0290, 0.0453],\n",
            "        [0.3103, 0.0499, 0.6399],\n",
            "        [0.0120, 0.9299, 0.0581],\n",
            "        [0.0088, 0.8856, 0.1055],\n",
            "        [0.0730, 0.0732, 0.8538],\n",
            "        [0.0103, 0.9295, 0.0602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 2, 1, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 1, 1, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 19/63 [00:12<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0137, 0.9461, 0.0402],\n",
            "        [0.3053, 0.4045, 0.2901],\n",
            "        [0.1273, 0.0319, 0.8408],\n",
            "        [0.0281, 0.0190, 0.9529],\n",
            "        [0.9740, 0.0099, 0.0160],\n",
            "        [0.0840, 0.2212, 0.6949],\n",
            "        [0.0162, 0.9064, 0.0774],\n",
            "        [0.0525, 0.1551, 0.7923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0137, 0.9461, 0.0402],\n",
            "        [0.3053, 0.4045, 0.2901],\n",
            "        [0.1273, 0.0319, 0.8408],\n",
            "        [0.0281, 0.0190, 0.9529],\n",
            "        [0.9740, 0.0099, 0.0160],\n",
            "        [0.0840, 0.2212, 0.6949],\n",
            "        [0.0162, 0.9064, 0.0774],\n",
            "        [0.0525, 0.1551, 0.7923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 2, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 2, 0, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 20/63 [00:13<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9833, 0.0089, 0.0078],\n",
            "        [0.2661, 0.0388, 0.6952],\n",
            "        [0.9178, 0.0136, 0.0686],\n",
            "        [0.9557, 0.0200, 0.0243],\n",
            "        [0.0439, 0.1745, 0.7815],\n",
            "        [0.2940, 0.3577, 0.3482],\n",
            "        [0.9488, 0.0198, 0.0314],\n",
            "        [0.0426, 0.1146, 0.8428]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9833, 0.0089, 0.0078],\n",
            "        [0.2661, 0.0388, 0.6952],\n",
            "        [0.9178, 0.0136, 0.0686],\n",
            "        [0.9557, 0.0200, 0.0243],\n",
            "        [0.0439, 0.1745, 0.7815],\n",
            "        [0.2940, 0.3577, 0.3482],\n",
            "        [0.9488, 0.0198, 0.0314],\n",
            "        [0.0426, 0.1146, 0.8428]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 2, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/63 [00:14<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9353, 0.0292, 0.0354],\n",
            "        [0.0168, 0.8941, 0.0890],\n",
            "        [0.9735, 0.0144, 0.0121],\n",
            "        [0.1126, 0.1110, 0.7764],\n",
            "        [0.0217, 0.9459, 0.0324],\n",
            "        [0.9746, 0.0089, 0.0165],\n",
            "        [0.0135, 0.9642, 0.0223],\n",
            "        [0.0122, 0.8846, 0.1032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9353, 0.0292, 0.0354],\n",
            "        [0.0168, 0.8941, 0.0890],\n",
            "        [0.9735, 0.0144, 0.0121],\n",
            "        [0.1126, 0.1110, 0.7764],\n",
            "        [0.0217, 0.9459, 0.0324],\n",
            "        [0.9746, 0.0089, 0.0165],\n",
            "        [0.0135, 0.9642, 0.0223],\n",
            "        [0.0122, 0.8846, 0.1032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 1, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 2, 1, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 22/63 [00:14<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0216, 0.8718, 0.1066],\n",
            "        [0.0090, 0.9455, 0.0455],\n",
            "        [0.4451, 0.1214, 0.4335],\n",
            "        [0.0126, 0.9423, 0.0451],\n",
            "        [0.0210, 0.4123, 0.5667],\n",
            "        [0.9737, 0.0145, 0.0118],\n",
            "        [0.8251, 0.0764, 0.0986],\n",
            "        [0.0463, 0.1654, 0.7882]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0216, 0.8718, 0.1066],\n",
            "        [0.0090, 0.9455, 0.0455],\n",
            "        [0.4451, 0.1214, 0.4335],\n",
            "        [0.0126, 0.9423, 0.0451],\n",
            "        [0.0210, 0.4123, 0.5667],\n",
            "        [0.9737, 0.0145, 0.0118],\n",
            "        [0.8251, 0.0764, 0.0986],\n",
            "        [0.0463, 0.1654, 0.7882]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 23/63 [00:15<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9698, 0.0139, 0.0163],\n",
            "        [0.7559, 0.0461, 0.1980],\n",
            "        [0.9732, 0.0106, 0.0162],\n",
            "        [0.4376, 0.2610, 0.3014],\n",
            "        [0.0222, 0.9510, 0.0267],\n",
            "        [0.4264, 0.0471, 0.5265],\n",
            "        [0.7634, 0.1227, 0.1139],\n",
            "        [0.0051, 0.9558, 0.0391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9698, 0.0139, 0.0163],\n",
            "        [0.7559, 0.0461, 0.1980],\n",
            "        [0.9732, 0.0106, 0.0162],\n",
            "        [0.4376, 0.2610, 0.3014],\n",
            "        [0.0222, 0.9510, 0.0267],\n",
            "        [0.4264, 0.0471, 0.5265],\n",
            "        [0.7634, 0.1227, 0.1139],\n",
            "        [0.0051, 0.9558, 0.0391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 1, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 2, 1, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/63 [00:16<00:26,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6313, 0.2412, 0.1275],\n",
            "        [0.3740, 0.3215, 0.3045],\n",
            "        [0.0093, 0.8607, 0.1300],\n",
            "        [0.0281, 0.8758, 0.0961],\n",
            "        [0.0236, 0.9081, 0.0683],\n",
            "        [0.0137, 0.9583, 0.0280],\n",
            "        [0.0119, 0.9797, 0.0084],\n",
            "        [0.4126, 0.3068, 0.2806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6313, 0.2412, 0.1275],\n",
            "        [0.3740, 0.3215, 0.3045],\n",
            "        [0.0093, 0.8607, 0.1300],\n",
            "        [0.0281, 0.8758, 0.0961],\n",
            "        [0.0236, 0.9081, 0.0683],\n",
            "        [0.0137, 0.9583, 0.0280],\n",
            "        [0.0119, 0.9797, 0.0084],\n",
            "        [0.4126, 0.3068, 0.2806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 25/63 [00:16<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9502, 0.0175, 0.0323],\n",
            "        [0.0122, 0.9270, 0.0608],\n",
            "        [0.0415, 0.9148, 0.0437],\n",
            "        [0.4834, 0.1937, 0.3229],\n",
            "        [0.0344, 0.2355, 0.7301],\n",
            "        [0.2948, 0.0331, 0.6721],\n",
            "        [0.4865, 0.1652, 0.3484],\n",
            "        [0.9682, 0.0152, 0.0166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9502, 0.0175, 0.0323],\n",
            "        [0.0122, 0.9270, 0.0608],\n",
            "        [0.0415, 0.9148, 0.0437],\n",
            "        [0.4834, 0.1937, 0.3229],\n",
            "        [0.0344, 0.2355, 0.7301],\n",
            "        [0.2948, 0.0331, 0.6721],\n",
            "        [0.4865, 0.1652, 0.3484],\n",
            "        [0.9682, 0.0152, 0.0166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 2, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 2, 1, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 26/63 [00:17<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0139, 0.1221, 0.8640],\n",
            "        [0.0145, 0.5870, 0.3984],\n",
            "        [0.0190, 0.8887, 0.0923],\n",
            "        [0.0065, 0.9506, 0.0429],\n",
            "        [0.5108, 0.1017, 0.3875],\n",
            "        [0.1263, 0.0478, 0.8258],\n",
            "        [0.0206, 0.9379, 0.0415],\n",
            "        [0.0418, 0.2571, 0.7011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0139, 0.1221, 0.8640],\n",
            "        [0.0145, 0.5870, 0.3984],\n",
            "        [0.0190, 0.8887, 0.0923],\n",
            "        [0.0065, 0.9506, 0.0429],\n",
            "        [0.5108, 0.1017, 0.3875],\n",
            "        [0.1263, 0.0478, 0.8258],\n",
            "        [0.0206, 0.9379, 0.0415],\n",
            "        [0.0418, 0.2571, 0.7011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 1, 2, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 27/63 [00:18<00:24,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9566, 0.0267, 0.0167],\n",
            "        [0.0297, 0.4572, 0.5132],\n",
            "        [0.0148, 0.9676, 0.0175],\n",
            "        [0.0492, 0.0564, 0.8944],\n",
            "        [0.0480, 0.0515, 0.9006],\n",
            "        [0.9523, 0.0169, 0.0307],\n",
            "        [0.9796, 0.0121, 0.0083],\n",
            "        [0.9752, 0.0127, 0.0121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9566, 0.0267, 0.0167],\n",
            "        [0.0297, 0.4572, 0.5132],\n",
            "        [0.0148, 0.9676, 0.0175],\n",
            "        [0.0492, 0.0564, 0.8944],\n",
            "        [0.0480, 0.0515, 0.9006],\n",
            "        [0.9523, 0.0169, 0.0307],\n",
            "        [0.9796, 0.0121, 0.0083],\n",
            "        [0.9752, 0.0127, 0.0121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 1, 2, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 2, 2, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/63 [00:18<00:23,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0302, 0.0385, 0.9314],\n",
            "        [0.9762, 0.0133, 0.0105],\n",
            "        [0.0724, 0.4547, 0.4729],\n",
            "        [0.9481, 0.0112, 0.0407],\n",
            "        [0.9433, 0.0213, 0.0354],\n",
            "        [0.7750, 0.0387, 0.1862],\n",
            "        [0.8269, 0.0469, 0.1262],\n",
            "        [0.1904, 0.1607, 0.6490]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0302, 0.0385, 0.9314],\n",
            "        [0.9762, 0.0133, 0.0105],\n",
            "        [0.0724, 0.4547, 0.4729],\n",
            "        [0.9481, 0.0112, 0.0407],\n",
            "        [0.9433, 0.0213, 0.0354],\n",
            "        [0.7750, 0.0387, 0.1862],\n",
            "        [0.8269, 0.0469, 0.1262],\n",
            "        [0.1904, 0.1607, 0.6490]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 0, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 1, 0, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 29/63 [00:19<00:23,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0090, 0.9346, 0.0564],\n",
            "        [0.2760, 0.0476, 0.6764],\n",
            "        [0.0078, 0.8464, 0.1457],\n",
            "        [0.6993, 0.1037, 0.1970],\n",
            "        [0.9377, 0.0233, 0.0390],\n",
            "        [0.9262, 0.0420, 0.0318],\n",
            "        [0.9464, 0.0216, 0.0320],\n",
            "        [0.0993, 0.0821, 0.8186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0090, 0.9346, 0.0564],\n",
            "        [0.2760, 0.0476, 0.6764],\n",
            "        [0.0078, 0.8464, 0.1457],\n",
            "        [0.6993, 0.1037, 0.1970],\n",
            "        [0.9377, 0.0233, 0.0390],\n",
            "        [0.9262, 0.0420, 0.0318],\n",
            "        [0.9464, 0.0216, 0.0320],\n",
            "        [0.0993, 0.0821, 0.8186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 0, 0, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 0, 0, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 30/63 [00:20<00:22,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9052, 0.0149, 0.0799],\n",
            "        [0.0153, 0.0749, 0.9098],\n",
            "        [0.0266, 0.0831, 0.8903],\n",
            "        [0.0119, 0.0239, 0.9641],\n",
            "        [0.0071, 0.9806, 0.0123],\n",
            "        [0.0121, 0.9711, 0.0167],\n",
            "        [0.0517, 0.0520, 0.8963],\n",
            "        [0.0134, 0.9663, 0.0203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9052, 0.0149, 0.0799],\n",
            "        [0.0153, 0.0749, 0.9098],\n",
            "        [0.0266, 0.0831, 0.8903],\n",
            "        [0.0119, 0.0239, 0.9641],\n",
            "        [0.0071, 0.9806, 0.0123],\n",
            "        [0.0121, 0.9711, 0.0167],\n",
            "        [0.0517, 0.0520, 0.8963],\n",
            "        [0.0134, 0.9663, 0.0203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 2, 1, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 2, 1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 31/63 [00:20<00:21,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0089, 0.9649, 0.0262],\n",
            "        [0.0300, 0.0367, 0.9334],\n",
            "        [0.9646, 0.0123, 0.0231],\n",
            "        [0.0098, 0.7351, 0.2551],\n",
            "        [0.9539, 0.0193, 0.0268],\n",
            "        [0.8638, 0.0489, 0.0873],\n",
            "        [0.2738, 0.1133, 0.6129],\n",
            "        [0.0089, 0.9726, 0.0185]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0089, 0.9649, 0.0262],\n",
            "        [0.0300, 0.0367, 0.9334],\n",
            "        [0.9646, 0.0123, 0.0231],\n",
            "        [0.0098, 0.7351, 0.2551],\n",
            "        [0.9539, 0.0193, 0.0268],\n",
            "        [0.8638, 0.0489, 0.0873],\n",
            "        [0.2738, 0.1133, 0.6129],\n",
            "        [0.0089, 0.9726, 0.0185]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 1, 0, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 2, 0, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 32/63 [00:21<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0060, 0.9813, 0.0126],\n",
            "        [0.0053, 0.9852, 0.0095],\n",
            "        [0.0193, 0.9584, 0.0223],\n",
            "        [0.0120, 0.9731, 0.0149],\n",
            "        [0.0051, 0.9646, 0.0303],\n",
            "        [0.0401, 0.0810, 0.8789],\n",
            "        [0.9613, 0.0154, 0.0233],\n",
            "        [0.9709, 0.0130, 0.0161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0060, 0.9813, 0.0126],\n",
            "        [0.0053, 0.9852, 0.0095],\n",
            "        [0.0193, 0.9584, 0.0223],\n",
            "        [0.0120, 0.9731, 0.0149],\n",
            "        [0.0051, 0.9646, 0.0303],\n",
            "        [0.0401, 0.0810, 0.8789],\n",
            "        [0.9613, 0.0154, 0.0233],\n",
            "        [0.9709, 0.0130, 0.0161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 1, 1, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 1, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/63 [00:22<00:20,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4679, 0.1006, 0.4316],\n",
            "        [0.9836, 0.0088, 0.0076],\n",
            "        [0.9299, 0.0206, 0.0495],\n",
            "        [0.9347, 0.0204, 0.0449],\n",
            "        [0.9752, 0.0100, 0.0148],\n",
            "        [0.6720, 0.1687, 0.1594],\n",
            "        [0.0346, 0.0334, 0.9320],\n",
            "        [0.9779, 0.0089, 0.0132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4679, 0.1006, 0.4316],\n",
            "        [0.9836, 0.0088, 0.0076],\n",
            "        [0.9299, 0.0206, 0.0495],\n",
            "        [0.9347, 0.0204, 0.0449],\n",
            "        [0.9752, 0.0100, 0.0148],\n",
            "        [0.6720, 0.1687, 0.1594],\n",
            "        [0.0346, 0.0334, 0.9320],\n",
            "        [0.9779, 0.0089, 0.0132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 0, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 0, 0, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 34/63 [00:23<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7809, 0.0804, 0.1388],\n",
            "        [0.0467, 0.0418, 0.9115],\n",
            "        [0.0364, 0.1112, 0.8525],\n",
            "        [0.0099, 0.9380, 0.0521],\n",
            "        [0.0077, 0.0288, 0.9635],\n",
            "        [0.4608, 0.1720, 0.3672],\n",
            "        [0.4658, 0.2814, 0.2528],\n",
            "        [0.0296, 0.1223, 0.8481]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7809, 0.0804, 0.1388],\n",
            "        [0.0467, 0.0418, 0.9115],\n",
            "        [0.0364, 0.1112, 0.8525],\n",
            "        [0.0099, 0.9380, 0.0521],\n",
            "        [0.0077, 0.0288, 0.9635],\n",
            "        [0.4608, 0.1720, 0.3672],\n",
            "        [0.4658, 0.2814, 0.2528],\n",
            "        [0.0296, 0.1223, 0.8481]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 1, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 2, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 35/63 [00:23<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0094, 0.9381, 0.0524],\n",
            "        [0.0086, 0.9291, 0.0623],\n",
            "        [0.9667, 0.0110, 0.0223],\n",
            "        [0.2498, 0.1868, 0.5634],\n",
            "        [0.0259, 0.0531, 0.9210],\n",
            "        [0.0436, 0.0751, 0.8813],\n",
            "        [0.0159, 0.9614, 0.0227],\n",
            "        [0.0820, 0.2123, 0.7057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0094, 0.9381, 0.0524],\n",
            "        [0.0086, 0.9291, 0.0623],\n",
            "        [0.9667, 0.0110, 0.0223],\n",
            "        [0.2498, 0.1868, 0.5634],\n",
            "        [0.0259, 0.0531, 0.9210],\n",
            "        [0.0436, 0.0751, 0.8813],\n",
            "        [0.0159, 0.9614, 0.0227],\n",
            "        [0.0820, 0.2123, 0.7057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 2, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 36/63 [00:24<00:18,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0260, 0.2120, 0.7620],\n",
            "        [0.9740, 0.0090, 0.0170],\n",
            "        [0.0926, 0.1261, 0.7814],\n",
            "        [0.1595, 0.0642, 0.7763],\n",
            "        [0.5630, 0.2245, 0.2125],\n",
            "        [0.0191, 0.9445, 0.0364],\n",
            "        [0.0141, 0.5050, 0.4809],\n",
            "        [0.1030, 0.0443, 0.8527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0260, 0.2120, 0.7620],\n",
            "        [0.9740, 0.0090, 0.0170],\n",
            "        [0.0926, 0.1261, 0.7814],\n",
            "        [0.1595, 0.0642, 0.7763],\n",
            "        [0.5630, 0.2245, 0.2125],\n",
            "        [0.0191, 0.9445, 0.0364],\n",
            "        [0.0141, 0.5050, 0.4809],\n",
            "        [0.1030, 0.0443, 0.8527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 2, 0, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 2, 0, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 37/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0061, 0.9796, 0.0143],\n",
            "        [0.9674, 0.0128, 0.0199],\n",
            "        [0.9860, 0.0079, 0.0061],\n",
            "        [0.1725, 0.1386, 0.6889],\n",
            "        [0.9725, 0.0109, 0.0166],\n",
            "        [0.1190, 0.0289, 0.8522],\n",
            "        [0.0306, 0.0433, 0.9261],\n",
            "        [0.8787, 0.0691, 0.0522]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0061, 0.9796, 0.0143],\n",
            "        [0.9674, 0.0128, 0.0199],\n",
            "        [0.9860, 0.0079, 0.0061],\n",
            "        [0.1725, 0.1386, 0.6889],\n",
            "        [0.9725, 0.0109, 0.0166],\n",
            "        [0.1190, 0.0289, 0.8522],\n",
            "        [0.0306, 0.0433, 0.9261],\n",
            "        [0.8787, 0.0691, 0.0522]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 2, 0, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 38/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9359, 0.0179, 0.0461],\n",
            "        [0.0229, 0.9577, 0.0193],\n",
            "        [0.0247, 0.0554, 0.9199],\n",
            "        [0.9695, 0.0085, 0.0220],\n",
            "        [0.0056, 0.1438, 0.8506],\n",
            "        [0.0402, 0.1274, 0.8323],\n",
            "        [0.0076, 0.9721, 0.0203],\n",
            "        [0.0115, 0.9608, 0.0277]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9359, 0.0179, 0.0461],\n",
            "        [0.0229, 0.9577, 0.0193],\n",
            "        [0.0247, 0.0554, 0.9199],\n",
            "        [0.9695, 0.0085, 0.0220],\n",
            "        [0.0056, 0.1438, 0.8506],\n",
            "        [0.0402, 0.1274, 0.8323],\n",
            "        [0.0076, 0.9721, 0.0203],\n",
            "        [0.0115, 0.9608, 0.0277]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 0, 2, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 2, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 39/63 [00:26<00:16,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0186, 0.0182, 0.9632],\n",
            "        [0.0137, 0.9460, 0.0404],\n",
            "        [0.3446, 0.0303, 0.6251],\n",
            "        [0.4408, 0.2727, 0.2865],\n",
            "        [0.0073, 0.9620, 0.0307],\n",
            "        [0.9552, 0.0193, 0.0255],\n",
            "        [0.3931, 0.0615, 0.5454],\n",
            "        [0.0174, 0.9074, 0.0753]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0186, 0.0182, 0.9632],\n",
            "        [0.0137, 0.9460, 0.0404],\n",
            "        [0.3446, 0.0303, 0.6251],\n",
            "        [0.4408, 0.2727, 0.2865],\n",
            "        [0.0073, 0.9620, 0.0307],\n",
            "        [0.9552, 0.0193, 0.0255],\n",
            "        [0.3931, 0.0615, 0.5454],\n",
            "        [0.0174, 0.9074, 0.0753]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 0, 1, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 0, 1, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 40/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0076, 0.9711, 0.0213],\n",
            "        [0.0396, 0.9357, 0.0247],\n",
            "        [0.0137, 0.2840, 0.7024],\n",
            "        [0.0241, 0.0739, 0.9020],\n",
            "        [0.0294, 0.0685, 0.9021],\n",
            "        [0.5135, 0.2925, 0.1939],\n",
            "        [0.9736, 0.0135, 0.0129],\n",
            "        [0.9651, 0.0155, 0.0194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0076, 0.9711, 0.0213],\n",
            "        [0.0396, 0.9357, 0.0247],\n",
            "        [0.0137, 0.2840, 0.7024],\n",
            "        [0.0241, 0.0739, 0.9020],\n",
            "        [0.0294, 0.0685, 0.9021],\n",
            "        [0.5135, 0.2925, 0.1939],\n",
            "        [0.9736, 0.0135, 0.0129],\n",
            "        [0.9651, 0.0155, 0.0194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 2, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 2, 2, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 41/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0129, 0.9689, 0.0182],\n",
            "        [0.8982, 0.0197, 0.0821],\n",
            "        [0.9207, 0.0239, 0.0555],\n",
            "        [0.0279, 0.9490, 0.0231],\n",
            "        [0.0179, 0.0586, 0.9235],\n",
            "        [0.0150, 0.1326, 0.8525],\n",
            "        [0.0067, 0.8820, 0.1113],\n",
            "        [0.0093, 0.1176, 0.8732]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0129, 0.9689, 0.0182],\n",
            "        [0.8982, 0.0197, 0.0821],\n",
            "        [0.9207, 0.0239, 0.0555],\n",
            "        [0.0279, 0.9490, 0.0231],\n",
            "        [0.0179, 0.0586, 0.9235],\n",
            "        [0.0150, 0.1326, 0.8525],\n",
            "        [0.0067, 0.8820, 0.1113],\n",
            "        [0.0093, 0.1176, 0.8732]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 1, 2, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 1, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 42/63 [00:28<00:14,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.5805, 0.2541, 0.1654],\n",
            "        [0.9643, 0.0050, 0.0307],\n",
            "        [0.8372, 0.0235, 0.1393],\n",
            "        [0.0520, 0.9198, 0.0283],\n",
            "        [0.6601, 0.1785, 0.1614],\n",
            "        [0.9753, 0.0120, 0.0126],\n",
            "        [0.9423, 0.0207, 0.0370],\n",
            "        [0.0062, 0.7817, 0.2122]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.5805, 0.2541, 0.1654],\n",
            "        [0.9643, 0.0050, 0.0307],\n",
            "        [0.8372, 0.0235, 0.1393],\n",
            "        [0.0520, 0.9198, 0.0283],\n",
            "        [0.6601, 0.1785, 0.1614],\n",
            "        [0.9753, 0.0120, 0.0126],\n",
            "        [0.9423, 0.0207, 0.0370],\n",
            "        [0.0062, 0.7817, 0.2122]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 0, 2, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 43/63 [00:29<00:13,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3297, 0.2101, 0.4602],\n",
            "        [0.1013, 0.0567, 0.8419],\n",
            "        [0.6635, 0.1211, 0.2155],\n",
            "        [0.0653, 0.0733, 0.8614],\n",
            "        [0.0052, 0.9705, 0.0243],\n",
            "        [0.0304, 0.2565, 0.7132],\n",
            "        [0.5030, 0.0456, 0.4513],\n",
            "        [0.9388, 0.0232, 0.0380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3297, 0.2101, 0.4602],\n",
            "        [0.1013, 0.0567, 0.8419],\n",
            "        [0.6635, 0.1211, 0.2155],\n",
            "        [0.0653, 0.0733, 0.8614],\n",
            "        [0.0052, 0.9705, 0.0243],\n",
            "        [0.0304, 0.2565, 0.7132],\n",
            "        [0.5030, 0.0456, 0.4513],\n",
            "        [0.9388, 0.0232, 0.0380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 2, 1, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 2, 2, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 44/63 [00:29<00:13,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2744, 0.2444, 0.4812],\n",
            "        [0.0268, 0.0540, 0.9192],\n",
            "        [0.0035, 0.9687, 0.0278],\n",
            "        [0.0069, 0.9787, 0.0144],\n",
            "        [0.9787, 0.0071, 0.0142],\n",
            "        [0.0413, 0.4161, 0.5426],\n",
            "        [0.9772, 0.0072, 0.0156],\n",
            "        [0.9686, 0.0127, 0.0187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2744, 0.2444, 0.4812],\n",
            "        [0.0268, 0.0540, 0.9192],\n",
            "        [0.0035, 0.9687, 0.0278],\n",
            "        [0.0069, 0.9787, 0.0144],\n",
            "        [0.9787, 0.0071, 0.0142],\n",
            "        [0.0413, 0.4161, 0.5426],\n",
            "        [0.9772, 0.0072, 0.0156],\n",
            "        [0.9686, 0.0127, 0.0187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 1, 0, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 1, 0, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 45/63 [00:30<00:12,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0275, 0.0482, 0.9244],\n",
            "        [0.0223, 0.3047, 0.6730],\n",
            "        [0.0299, 0.0744, 0.8957],\n",
            "        [0.0037, 0.9817, 0.0145],\n",
            "        [0.0075, 0.0777, 0.9148],\n",
            "        [0.0367, 0.0136, 0.9497],\n",
            "        [0.7651, 0.0665, 0.1684],\n",
            "        [0.0320, 0.4757, 0.4923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0275, 0.0482, 0.9244],\n",
            "        [0.0223, 0.3047, 0.6730],\n",
            "        [0.0299, 0.0744, 0.8957],\n",
            "        [0.0037, 0.9817, 0.0145],\n",
            "        [0.0075, 0.0777, 0.9148],\n",
            "        [0.0367, 0.0136, 0.9497],\n",
            "        [0.7651, 0.0665, 0.1684],\n",
            "        [0.0320, 0.4757, 0.4923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 1, 2, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 1, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 46/63 [00:31<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0178, 0.9355, 0.0467],\n",
            "        [0.9473, 0.0326, 0.0201],\n",
            "        [0.0270, 0.9520, 0.0210],\n",
            "        [0.0078, 0.9678, 0.0244],\n",
            "        [0.1432, 0.0320, 0.8249],\n",
            "        [0.0394, 0.0672, 0.8934],\n",
            "        [0.0232, 0.0665, 0.9103],\n",
            "        [0.0257, 0.0599, 0.9144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0178, 0.9355, 0.0467],\n",
            "        [0.9473, 0.0326, 0.0201],\n",
            "        [0.0270, 0.9520, 0.0210],\n",
            "        [0.0078, 0.9678, 0.0244],\n",
            "        [0.1432, 0.0320, 0.8249],\n",
            "        [0.0394, 0.0672, 0.8934],\n",
            "        [0.0232, 0.0665, 0.9103],\n",
            "        [0.0257, 0.0599, 0.9144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 1, 1, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 47/63 [00:32<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0124, 0.8355, 0.1522],\n",
            "        [0.0178, 0.9465, 0.0357],\n",
            "        [0.9811, 0.0077, 0.0112],\n",
            "        [0.5930, 0.0299, 0.3770],\n",
            "        [0.0118, 0.0232, 0.9650],\n",
            "        [0.5599, 0.0683, 0.3718],\n",
            "        [0.0106, 0.8059, 0.1836],\n",
            "        [0.0289, 0.0527, 0.9185]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0124, 0.8355, 0.1522],\n",
            "        [0.0178, 0.9465, 0.0357],\n",
            "        [0.9811, 0.0077, 0.0112],\n",
            "        [0.5930, 0.0299, 0.3770],\n",
            "        [0.0118, 0.0232, 0.9650],\n",
            "        [0.5599, 0.0683, 0.3718],\n",
            "        [0.0106, 0.8059, 0.1836],\n",
            "        [0.0289, 0.0527, 0.9185]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 0, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 0, 2, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 48/63 [00:32<00:10,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6971, 0.0694, 0.2335],\n",
            "        [0.0192, 0.1252, 0.8556],\n",
            "        [0.9821, 0.0087, 0.0092],\n",
            "        [0.6810, 0.1891, 0.1299],\n",
            "        [0.0131, 0.0370, 0.9499],\n",
            "        [0.9760, 0.0127, 0.0113],\n",
            "        [0.7533, 0.0761, 0.1706],\n",
            "        [0.0131, 0.9648, 0.0221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6971, 0.0694, 0.2335],\n",
            "        [0.0192, 0.1252, 0.8556],\n",
            "        [0.9821, 0.0087, 0.0092],\n",
            "        [0.6810, 0.1891, 0.1299],\n",
            "        [0.0131, 0.0370, 0.9499],\n",
            "        [0.9760, 0.0127, 0.0113],\n",
            "        [0.7533, 0.0761, 0.1706],\n",
            "        [0.0131, 0.9648, 0.0221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 2, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 1, 1, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 49/63 [00:33<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0135, 0.3187, 0.6678],\n",
            "        [0.9063, 0.0410, 0.0527],\n",
            "        [0.9725, 0.0180, 0.0095],\n",
            "        [0.0056, 0.9585, 0.0359],\n",
            "        [0.0117, 0.9685, 0.0198],\n",
            "        [0.0365, 0.0586, 0.9049],\n",
            "        [0.9817, 0.0087, 0.0096],\n",
            "        [0.6335, 0.0215, 0.3451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0135, 0.3187, 0.6678],\n",
            "        [0.9063, 0.0410, 0.0527],\n",
            "        [0.9725, 0.0180, 0.0095],\n",
            "        [0.0056, 0.9585, 0.0359],\n",
            "        [0.0117, 0.9685, 0.0198],\n",
            "        [0.0365, 0.0586, 0.9049],\n",
            "        [0.9817, 0.0087, 0.0096],\n",
            "        [0.6335, 0.0215, 0.3451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 1, 1, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 1, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 50/63 [00:34<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4977, 0.1619, 0.3405],\n",
            "        [0.0101, 0.9674, 0.0226],\n",
            "        [0.9780, 0.0097, 0.0123],\n",
            "        [0.0169, 0.1162, 0.8668],\n",
            "        [0.6813, 0.1904, 0.1283],\n",
            "        [0.7375, 0.0884, 0.1741],\n",
            "        [0.9759, 0.0053, 0.0188],\n",
            "        [0.9706, 0.0092, 0.0201]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4977, 0.1619, 0.3405],\n",
            "        [0.0101, 0.9674, 0.0226],\n",
            "        [0.9780, 0.0097, 0.0123],\n",
            "        [0.0169, 0.1162, 0.8668],\n",
            "        [0.6813, 0.1904, 0.1283],\n",
            "        [0.7375, 0.0884, 0.1741],\n",
            "        [0.9759, 0.0053, 0.0188],\n",
            "        [0.9706, 0.0092, 0.0201]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 51/63 [00:34<00:08,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3094, 0.3807, 0.3100],\n",
            "        [0.9858, 0.0043, 0.0099],\n",
            "        [0.0064, 0.7986, 0.1949],\n",
            "        [0.0291, 0.0324, 0.9385],\n",
            "        [0.0194, 0.5135, 0.4671],\n",
            "        [0.0134, 0.9422, 0.0444],\n",
            "        [0.9728, 0.0062, 0.0210],\n",
            "        [0.0048, 0.9545, 0.0407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3094, 0.3807, 0.3100],\n",
            "        [0.9858, 0.0043, 0.0099],\n",
            "        [0.0064, 0.7986, 0.1949],\n",
            "        [0.0291, 0.0324, 0.9385],\n",
            "        [0.0194, 0.5135, 0.4671],\n",
            "        [0.0134, 0.9422, 0.0444],\n",
            "        [0.9728, 0.0062, 0.0210],\n",
            "        [0.0048, 0.9545, 0.0407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 2, 1, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 2, 1, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 52/63 [00:35<00:07,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9872, 0.0054, 0.0074],\n",
            "        [0.3500, 0.2007, 0.4492],\n",
            "        [0.9819, 0.0073, 0.0108],\n",
            "        [0.9857, 0.0074, 0.0068],\n",
            "        [0.0110, 0.0695, 0.9195],\n",
            "        [0.0878, 0.0326, 0.8795],\n",
            "        [0.9854, 0.0053, 0.0093],\n",
            "        [0.5411, 0.2854, 0.1735]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9872, 0.0054, 0.0074],\n",
            "        [0.3500, 0.2007, 0.4492],\n",
            "        [0.9819, 0.0073, 0.0108],\n",
            "        [0.9857, 0.0074, 0.0068],\n",
            "        [0.0110, 0.0695, 0.9195],\n",
            "        [0.0878, 0.0326, 0.8795],\n",
            "        [0.9854, 0.0053, 0.0093],\n",
            "        [0.5411, 0.2854, 0.1735]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 0, 2, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 1, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 53/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6693, 0.1969, 0.1338],\n",
            "        [0.0051, 0.8208, 0.1741],\n",
            "        [0.8929, 0.0093, 0.0978],\n",
            "        [0.0421, 0.0267, 0.9312],\n",
            "        [0.1197, 0.0724, 0.8079],\n",
            "        [0.9667, 0.0078, 0.0255],\n",
            "        [0.7028, 0.1480, 0.1491],\n",
            "        [0.9706, 0.0056, 0.0238]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6693, 0.1969, 0.1338],\n",
            "        [0.0051, 0.8208, 0.1741],\n",
            "        [0.8929, 0.0093, 0.0978],\n",
            "        [0.0421, 0.0267, 0.9312],\n",
            "        [0.1197, 0.0724, 0.8079],\n",
            "        [0.9667, 0.0078, 0.0255],\n",
            "        [0.7028, 0.1480, 0.1491],\n",
            "        [0.9706, 0.0056, 0.0238]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 2, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 54/63 [00:36<00:06,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0272, 0.0419, 0.9308],\n",
            "        [0.3771, 0.3530, 0.2699],\n",
            "        [0.4747, 0.0401, 0.4852],\n",
            "        [0.0153, 0.0319, 0.9528],\n",
            "        [0.2390, 0.0396, 0.7213],\n",
            "        [0.0164, 0.6784, 0.3052],\n",
            "        [0.9651, 0.0126, 0.0223],\n",
            "        [0.9857, 0.0086, 0.0057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0272, 0.0419, 0.9308],\n",
            "        [0.3771, 0.3530, 0.2699],\n",
            "        [0.4747, 0.0401, 0.4852],\n",
            "        [0.0153, 0.0319, 0.9528],\n",
            "        [0.2390, 0.0396, 0.7213],\n",
            "        [0.0164, 0.6784, 0.3052],\n",
            "        [0.9651, 0.0126, 0.0223],\n",
            "        [0.9857, 0.0086, 0.0057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 2, 2, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 0, 2, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 55/63 [00:37<00:05,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1464, 0.7273, 0.1264],\n",
            "        [0.9674, 0.0155, 0.0171],\n",
            "        [0.9722, 0.0165, 0.0113],\n",
            "        [0.8540, 0.0272, 0.1188],\n",
            "        [0.9858, 0.0051, 0.0091],\n",
            "        [0.0536, 0.0173, 0.9291],\n",
            "        [0.9665, 0.0103, 0.0233],\n",
            "        [0.9752, 0.0072, 0.0175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1464, 0.7273, 0.1264],\n",
            "        [0.9674, 0.0155, 0.0171],\n",
            "        [0.9722, 0.0165, 0.0113],\n",
            "        [0.8540, 0.0272, 0.1188],\n",
            "        [0.9858, 0.0051, 0.0091],\n",
            "        [0.0536, 0.0173, 0.9291],\n",
            "        [0.9665, 0.0103, 0.0233],\n",
            "        [0.9752, 0.0072, 0.0175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 0, 0, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 56/63 [00:38<00:04,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2320, 0.1752, 0.5928],\n",
            "        [0.9796, 0.0088, 0.0116],\n",
            "        [0.0500, 0.3029, 0.6471],\n",
            "        [0.4380, 0.1364, 0.4256],\n",
            "        [0.1762, 0.0557, 0.7681],\n",
            "        [0.1495, 0.0702, 0.7803],\n",
            "        [0.8290, 0.0309, 0.1401],\n",
            "        [0.0186, 0.0346, 0.9468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2320, 0.1752, 0.5928],\n",
            "        [0.9796, 0.0088, 0.0116],\n",
            "        [0.0500, 0.3029, 0.6471],\n",
            "        [0.4380, 0.1364, 0.4256],\n",
            "        [0.1762, 0.0557, 0.7681],\n",
            "        [0.1495, 0.0702, 0.7803],\n",
            "        [0.8290, 0.0309, 0.1401],\n",
            "        [0.0186, 0.0346, 0.9468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 2, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 57/63 [00:38<00:04,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0082, 0.6930, 0.2988],\n",
            "        [0.0111, 0.9702, 0.0187],\n",
            "        [0.0091, 0.7938, 0.1971],\n",
            "        [0.0235, 0.0240, 0.9525],\n",
            "        [0.9843, 0.0058, 0.0099],\n",
            "        [0.8448, 0.0489, 0.1063],\n",
            "        [0.0082, 0.9735, 0.0183],\n",
            "        [0.0272, 0.9041, 0.0687]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0082, 0.6930, 0.2988],\n",
            "        [0.0111, 0.9702, 0.0187],\n",
            "        [0.0091, 0.7938, 0.1971],\n",
            "        [0.0235, 0.0240, 0.9525],\n",
            "        [0.9843, 0.0058, 0.0099],\n",
            "        [0.8448, 0.0489, 0.1063],\n",
            "        [0.0082, 0.9735, 0.0183],\n",
            "        [0.0272, 0.9041, 0.0687]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 0, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 2, 0, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 58/63 [00:39<00:03,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9774, 0.0068, 0.0158],\n",
            "        [0.9743, 0.0113, 0.0145],\n",
            "        [0.1658, 0.0400, 0.7942],\n",
            "        [0.3970, 0.1095, 0.4936],\n",
            "        [0.2862, 0.0690, 0.6448],\n",
            "        [0.7768, 0.0801, 0.1430],\n",
            "        [0.9864, 0.0084, 0.0052],\n",
            "        [0.2960, 0.0345, 0.6695]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9774, 0.0068, 0.0158],\n",
            "        [0.9743, 0.0113, 0.0145],\n",
            "        [0.1658, 0.0400, 0.7942],\n",
            "        [0.3970, 0.1095, 0.4936],\n",
            "        [0.2862, 0.0690, 0.6448],\n",
            "        [0.7768, 0.0801, 0.1430],\n",
            "        [0.9864, 0.0084, 0.0052],\n",
            "        [0.2960, 0.0345, 0.6695]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 2, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 2, 2, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 59/63 [00:40<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1231, 0.0276, 0.8493],\n",
            "        [0.0740, 0.5103, 0.4157],\n",
            "        [0.9752, 0.0071, 0.0177],\n",
            "        [0.0058, 0.9855, 0.0086],\n",
            "        [0.4191, 0.0933, 0.4876],\n",
            "        [0.1003, 0.0528, 0.8469],\n",
            "        [0.0178, 0.2087, 0.7735],\n",
            "        [0.0243, 0.0478, 0.9279]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1231, 0.0276, 0.8493],\n",
            "        [0.0740, 0.5103, 0.4157],\n",
            "        [0.9752, 0.0071, 0.0177],\n",
            "        [0.0058, 0.9855, 0.0086],\n",
            "        [0.4191, 0.0933, 0.4876],\n",
            "        [0.1003, 0.0528, 0.8469],\n",
            "        [0.0178, 0.2087, 0.7735],\n",
            "        [0.0243, 0.0478, 0.9279]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 1, 2, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 60/63 [00:41<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0120, 0.9133, 0.0747],\n",
            "        [0.9846, 0.0074, 0.0081],\n",
            "        [0.0980, 0.0819, 0.8201],\n",
            "        [0.0230, 0.9520, 0.0250],\n",
            "        [0.9687, 0.0109, 0.0204],\n",
            "        [0.5751, 0.1089, 0.3160],\n",
            "        [0.0361, 0.9413, 0.0226],\n",
            "        [0.9871, 0.0050, 0.0079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0120, 0.9133, 0.0747],\n",
            "        [0.9846, 0.0074, 0.0081],\n",
            "        [0.0980, 0.0819, 0.8201],\n",
            "        [0.0230, 0.9520, 0.0250],\n",
            "        [0.9687, 0.0109, 0.0204],\n",
            "        [0.5751, 0.1089, 0.3160],\n",
            "        [0.0361, 0.9413, 0.0226],\n",
            "        [0.9871, 0.0050, 0.0079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 1, 0, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 1, 0, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 61/63 [00:41<00:01,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.4828, 0.1705, 0.3467],\n",
            "        [0.0218, 0.9603, 0.0179],\n",
            "        [0.5764, 0.1792, 0.2444],\n",
            "        [0.7781, 0.0469, 0.1750],\n",
            "        [0.0073, 0.9764, 0.0164],\n",
            "        [0.9808, 0.0116, 0.0076],\n",
            "        [0.0130, 0.9651, 0.0220],\n",
            "        [0.4286, 0.0229, 0.5485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.4828, 0.1705, 0.3467],\n",
            "        [0.0218, 0.9603, 0.0179],\n",
            "        [0.5764, 0.1792, 0.2444],\n",
            "        [0.7781, 0.0469, 0.1750],\n",
            "        [0.0073, 0.9764, 0.0164],\n",
            "        [0.9808, 0.0116, 0.0076],\n",
            "        [0.0130, 0.9651, 0.0220],\n",
            "        [0.4286, 0.0229, 0.5485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 0, 1, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 62/63 [00:42<00:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0169, 0.9590, 0.0242],\n",
            "        [0.9715, 0.0124, 0.0160],\n",
            "        [0.0496, 0.5854, 0.3650],\n",
            "        [0.9898, 0.0060, 0.0042]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0169, 0.9590, 0.0242],\n",
            "        [0.9715, 0.0124, 0.0160],\n",
            "        [0.0496, 0.5854, 0.3650],\n",
            "        [0.9898, 0.0060, 0.0042]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0117, 0.0203, 0.9680],\n",
            "        [0.0112, 0.9801, 0.0088],\n",
            "        [0.9837, 0.0068, 0.0095],\n",
            "        [0.0932, 0.0978, 0.8090],\n",
            "        [0.9622, 0.0156, 0.0222],\n",
            "        [0.0499, 0.9360, 0.0142],\n",
            "        [0.0306, 0.6052, 0.3641],\n",
            "        [0.9753, 0.0128, 0.0119]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "tensor([[0.0117, 0.0203, 0.9680],\n",
            "        [0.0112, 0.9801, 0.0088],\n",
            "        [0.9837, 0.0068, 0.0095],\n",
            "        [0.0932, 0.0978, 0.8090],\n",
            "        [0.9622, 0.0156, 0.0222],\n",
            "        [0.0499, 0.9360, 0.0142],\n",
            "        [0.0306, 0.6052, 0.3641],\n",
            "        [0.9753, 0.0128, 0.0119]], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0736, 0.1294, 0.7970],\n",
            "        [0.0182, 0.0632, 0.9186],\n",
            "        [0.0127, 0.9754, 0.0119],\n",
            "        [0.0123, 0.0765, 0.9112],\n",
            "        [0.0242, 0.1991, 0.7767],\n",
            "        [0.0085, 0.9795, 0.0120],\n",
            "        [0.9795, 0.0120, 0.0086],\n",
            "        [0.0302, 0.0163, 0.9535]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "tensor([[0.0736, 0.1294, 0.7970],\n",
            "        [0.0182, 0.0632, 0.9186],\n",
            "        [0.0127, 0.9754, 0.0119],\n",
            "        [0.0123, 0.0765, 0.9112],\n",
            "        [0.0242, 0.1991, 0.7767],\n",
            "        [0.0085, 0.9795, 0.0120],\n",
            "        [0.9795, 0.0120, 0.0086],\n",
            "        [0.0302, 0.0163, 0.9535]], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0134, 0.9655, 0.0211],\n",
            "        [0.9327, 0.0175, 0.0498],\n",
            "        [0.9919, 0.0036, 0.0045],\n",
            "        [0.0203, 0.9611, 0.0186],\n",
            "        [0.1212, 0.0355, 0.8433],\n",
            "        [0.0376, 0.2185, 0.7439],\n",
            "        [0.0172, 0.9673, 0.0156],\n",
            "        [0.9873, 0.0057, 0.0070]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "tensor([[0.0134, 0.9655, 0.0211],\n",
            "        [0.9327, 0.0175, 0.0498],\n",
            "        [0.9919, 0.0036, 0.0045],\n",
            "        [0.0203, 0.9611, 0.0186],\n",
            "        [0.1212, 0.0355, 0.8433],\n",
            "        [0.0376, 0.2185, 0.7439],\n",
            "        [0.0172, 0.9673, 0.0156],\n",
            "        [0.9873, 0.0057, 0.0070]], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0264, 0.9655, 0.0081],\n",
            "        [0.9594, 0.0198, 0.0207],\n",
            "        [0.0125, 0.0485, 0.9390],\n",
            "        [0.0329, 0.0703, 0.8968],\n",
            "        [0.0478, 0.9176, 0.0346],\n",
            "        [0.9846, 0.0083, 0.0071],\n",
            "        [0.0270, 0.0396, 0.9334],\n",
            "        [0.9605, 0.0057, 0.0338]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.0264, 0.9655, 0.0081],\n",
            "        [0.9594, 0.0198, 0.0207],\n",
            "        [0.0125, 0.0485, 0.9390],\n",
            "        [0.0329, 0.0703, 0.8968],\n",
            "        [0.0478, 0.9176, 0.0346],\n",
            "        [0.9846, 0.0083, 0.0071],\n",
            "        [0.0270, 0.0396, 0.9334],\n",
            "        [0.9605, 0.0057, 0.0338]], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0135, 0.9736, 0.0128],\n",
            "        [0.0347, 0.9411, 0.0243],\n",
            "        [0.0217, 0.1803, 0.7980],\n",
            "        [0.9467, 0.0064, 0.0469],\n",
            "        [0.0093, 0.9719, 0.0189],\n",
            "        [0.9849, 0.0052, 0.0099],\n",
            "        [0.0315, 0.0641, 0.9044],\n",
            "        [0.0073, 0.2340, 0.7587]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "tensor([[0.0135, 0.9736, 0.0128],\n",
            "        [0.0347, 0.9411, 0.0243],\n",
            "        [0.0217, 0.1803, 0.7980],\n",
            "        [0.9467, 0.0064, 0.0469],\n",
            "        [0.0093, 0.9719, 0.0189],\n",
            "        [0.9849, 0.0052, 0.0099],\n",
            "        [0.0315, 0.0641, 0.9044],\n",
            "        [0.0073, 0.2340, 0.7587]], device='cuda:0')\n",
            "tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.9263, 0.0235, 0.0502],\n",
            "        [0.0243, 0.9538, 0.0220],\n",
            "        [0.0294, 0.9444, 0.0263],\n",
            "        [0.9867, 0.0065, 0.0068],\n",
            "        [0.9775, 0.0125, 0.0099],\n",
            "        [0.9761, 0.0136, 0.0103],\n",
            "        [0.0070, 0.8245, 0.1685],\n",
            "        [0.0232, 0.9584, 0.0184]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
            "tensor([[0.9263, 0.0235, 0.0502],\n",
            "        [0.0243, 0.9538, 0.0220],\n",
            "        [0.0294, 0.9444, 0.0263],\n",
            "        [0.9867, 0.0065, 0.0068],\n",
            "        [0.9775, 0.0125, 0.0099],\n",
            "        [0.9761, 0.0136, 0.0103],\n",
            "        [0.0070, 0.8245, 0.1685],\n",
            "        [0.0232, 0.9584, 0.0184]], device='cuda:0')\n",
            "tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0119, 0.9771, 0.0111],\n",
            "        [0.9568, 0.0148, 0.0284],\n",
            "        [0.0411, 0.2666, 0.6923],\n",
            "        [0.0279, 0.9390, 0.0331],\n",
            "        [0.1671, 0.0502, 0.7827],\n",
            "        [0.0375, 0.1110, 0.8515],\n",
            "        [0.0203, 0.9560, 0.0237],\n",
            "        [0.0866, 0.3328, 0.5806]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 1, 2, 2, 1, 2], device='cuda:0')\n",
            "tensor([[0.0119, 0.9771, 0.0111],\n",
            "        [0.9568, 0.0148, 0.0284],\n",
            "        [0.0411, 0.2666, 0.6923],\n",
            "        [0.0279, 0.9390, 0.0331],\n",
            "        [0.1671, 0.0502, 0.7827],\n",
            "        [0.0375, 0.1110, 0.8515],\n",
            "        [0.0203, 0.9560, 0.0237],\n",
            "        [0.0866, 0.3328, 0.5806]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9812, 0.0118, 0.0070],\n",
            "        [0.5236, 0.1145, 0.3619],\n",
            "        [0.3772, 0.3675, 0.2553],\n",
            "        [0.4647, 0.1526, 0.3827],\n",
            "        [0.9183, 0.0156, 0.0661],\n",
            "        [0.5390, 0.1200, 0.3409],\n",
            "        [0.8732, 0.0153, 0.1115],\n",
            "        [0.7955, 0.1115, 0.0930]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([[0.9812, 0.0118, 0.0070],\n",
            "        [0.5236, 0.1145, 0.3619],\n",
            "        [0.3772, 0.3675, 0.2553],\n",
            "        [0.4647, 0.1526, 0.3827],\n",
            "        [0.9183, 0.0156, 0.0661],\n",
            "        [0.5390, 0.1200, 0.3409],\n",
            "        [0.8732, 0.0153, 0.1115],\n",
            "        [0.7955, 0.1115, 0.0930]], device='cuda:0')\n",
            "tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.1627, 0.1479, 0.6895],\n",
            "        [0.3889, 0.3665, 0.2446],\n",
            "        [0.0121, 0.9717, 0.0162],\n",
            "        [0.7208, 0.0606, 0.2185],\n",
            "        [0.5467, 0.1664, 0.2869],\n",
            "        [0.0423, 0.8474, 0.1103],\n",
            "        [0.6458, 0.0943, 0.2599],\n",
            "        [0.5573, 0.1872, 0.2555]], device='cuda:0')\n",
            "prediction: tensor([2, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
            "tensor([[0.1627, 0.1479, 0.6895],\n",
            "        [0.3889, 0.3665, 0.2446],\n",
            "        [0.0121, 0.9717, 0.0162],\n",
            "        [0.7208, 0.0606, 0.2185],\n",
            "        [0.5467, 0.1664, 0.2869],\n",
            "        [0.0423, 0.8474, 0.1103],\n",
            "        [0.6458, 0.0943, 0.2599],\n",
            "        [0.5573, 0.1872, 0.2555]], device='cuda:0')\n",
            "tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.3782, 0.3346, 0.2872],\n",
            "        [0.0175, 0.3355, 0.6470],\n",
            "        [0.7635, 0.0679, 0.1686],\n",
            "        [0.0845, 0.1031, 0.8124],\n",
            "        [0.2539, 0.4978, 0.2483],\n",
            "        [0.9856, 0.0054, 0.0090],\n",
            "        [0.0249, 0.9604, 0.0146],\n",
            "        [0.9829, 0.0088, 0.0083]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "tensor([[0.3782, 0.3346, 0.2872],\n",
            "        [0.0175, 0.3355, 0.6470],\n",
            "        [0.7635, 0.0679, 0.1686],\n",
            "        [0.0845, 0.1031, 0.8124],\n",
            "        [0.2539, 0.4978, 0.2483],\n",
            "        [0.9856, 0.0054, 0.0090],\n",
            "        [0.0249, 0.9604, 0.0146],\n",
            "        [0.9829, 0.0088, 0.0083]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.2331, 0.2303, 0.5366],\n",
            "        [0.6015, 0.1653, 0.2333],\n",
            "        [0.2916, 0.4554, 0.2531],\n",
            "        [0.9709, 0.0147, 0.0144],\n",
            "        [0.5328, 0.1780, 0.2891],\n",
            "        [0.1373, 0.5722, 0.2904],\n",
            "        [0.0652, 0.0356, 0.8991],\n",
            "        [0.0081, 0.9662, 0.0257]], device='cuda:0')\n",
            "prediction: tensor([2, 0, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "tensor([[0.2331, 0.2303, 0.5366],\n",
            "        [0.6015, 0.1653, 0.2333],\n",
            "        [0.2916, 0.4554, 0.2531],\n",
            "        [0.9709, 0.0147, 0.0144],\n",
            "        [0.5328, 0.1780, 0.2891],\n",
            "        [0.1373, 0.5722, 0.2904],\n",
            "        [0.0652, 0.0356, 0.8991],\n",
            "        [0.0081, 0.9662, 0.0257]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.9857, 0.0095, 0.0048],\n",
            "        [0.6526, 0.0179, 0.3295],\n",
            "        [0.0120, 0.9666, 0.0215],\n",
            "        [0.9764, 0.0121, 0.0114],\n",
            "        [0.0098, 0.9824, 0.0078],\n",
            "        [0.0057, 0.1190, 0.8753],\n",
            "        [0.0120, 0.9755, 0.0125],\n",
            "        [0.0544, 0.0417, 0.9039]], device='cuda:0')\n",
            "prediction: tensor([0, 0, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([[0.9857, 0.0095, 0.0048],\n",
            "        [0.6526, 0.0179, 0.3295],\n",
            "        [0.0120, 0.9666, 0.0215],\n",
            "        [0.9764, 0.0121, 0.0114],\n",
            "        [0.0098, 0.9824, 0.0078],\n",
            "        [0.0057, 0.1190, 0.8753],\n",
            "        [0.0120, 0.9755, 0.0125],\n",
            "        [0.0544, 0.0417, 0.9039]], device='cuda:0')\n",
            "tensor([0, 2, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9861, 0.0092, 0.0047],\n",
            "        [0.0464, 0.0332, 0.9205],\n",
            "        [0.0082, 0.0241, 0.9677],\n",
            "        [0.9897, 0.0044, 0.0060]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 2, 0], device='cuda:0')\n",
            "tensor([[0.9861, 0.0092, 0.0047],\n",
            "        [0.0464, 0.0332, 0.9205],\n",
            "        [0.0082, 0.0241, 0.9677],\n",
            "        [0.9897, 0.0044, 0.0060]], device='cuda:0')\n",
            "Epochs: 6 | Train Loss:  0.098             | Train Accuracy:  0.804             | Val Loss:  0.092             | Val Accuracy:  0.860\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9786, 0.0116, 0.0098],\n",
            "        [0.0286, 0.3809, 0.5905],\n",
            "        [0.0363, 0.0251, 0.9386],\n",
            "        [0.9861, 0.0082, 0.0057],\n",
            "        [0.0141, 0.9767, 0.0092],\n",
            "        [0.0266, 0.9591, 0.0143],\n",
            "        [0.0113, 0.9624, 0.0262],\n",
            "        [0.0078, 0.9851, 0.0071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9786, 0.0116, 0.0098],\n",
            "        [0.0286, 0.3809, 0.5905],\n",
            "        [0.0363, 0.0251, 0.9386],\n",
            "        [0.9861, 0.0082, 0.0057],\n",
            "        [0.0141, 0.9767, 0.0092],\n",
            "        [0.0266, 0.9591, 0.0143],\n",
            "        [0.0113, 0.9624, 0.0262],\n",
            "        [0.0078, 0.9851, 0.0071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 0, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/63 [00:00<00:44,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8237, 0.0993, 0.0770],\n",
            "        [0.1350, 0.1806, 0.6844],\n",
            "        [0.0135, 0.0597, 0.9268],\n",
            "        [0.0162, 0.9699, 0.0139],\n",
            "        [0.0315, 0.9152, 0.0534],\n",
            "        [0.8910, 0.0109, 0.0981],\n",
            "        [0.0122, 0.9668, 0.0210],\n",
            "        [0.6356, 0.0240, 0.3404]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8237, 0.0993, 0.0770],\n",
            "        [0.1350, 0.1806, 0.6844],\n",
            "        [0.0135, 0.0597, 0.9268],\n",
            "        [0.0162, 0.9699, 0.0139],\n",
            "        [0.0315, 0.9152, 0.0534],\n",
            "        [0.8910, 0.0109, 0.0981],\n",
            "        [0.0122, 0.9668, 0.0210],\n",
            "        [0.6356, 0.0240, 0.3404]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 1, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 1, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/63 [00:01<00:41,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0213, 0.9547, 0.0240],\n",
            "        [0.0215, 0.9600, 0.0185],\n",
            "        [0.9677, 0.0121, 0.0202],\n",
            "        [0.0176, 0.9476, 0.0348],\n",
            "        [0.9552, 0.0076, 0.0373],\n",
            "        [0.9375, 0.0137, 0.0488],\n",
            "        [0.3127, 0.3736, 0.3137],\n",
            "        [0.0395, 0.9297, 0.0309]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0213, 0.9547, 0.0240],\n",
            "        [0.0215, 0.9600, 0.0185],\n",
            "        [0.9677, 0.0121, 0.0202],\n",
            "        [0.0176, 0.9476, 0.0348],\n",
            "        [0.9552, 0.0076, 0.0373],\n",
            "        [0.9375, 0.0137, 0.0488],\n",
            "        [0.3127, 0.3736, 0.3137],\n",
            "        [0.0395, 0.9297, 0.0309]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 1, 2, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/63 [00:02<00:40,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9821, 0.0061, 0.0119],\n",
            "        [0.0216, 0.9505, 0.0279],\n",
            "        [0.6460, 0.2044, 0.1496],\n",
            "        [0.0844, 0.8011, 0.1145],\n",
            "        [0.4846, 0.2290, 0.2865],\n",
            "        [0.0107, 0.0889, 0.9004],\n",
            "        [0.0149, 0.9747, 0.0104],\n",
            "        [0.0172, 0.9678, 0.0150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9821, 0.0061, 0.0119],\n",
            "        [0.0216, 0.9505, 0.0279],\n",
            "        [0.6460, 0.2044, 0.1496],\n",
            "        [0.0844, 0.8011, 0.1145],\n",
            "        [0.4846, 0.2290, 0.2865],\n",
            "        [0.0107, 0.0889, 0.9004],\n",
            "        [0.0149, 0.9747, 0.0104],\n",
            "        [0.0172, 0.9678, 0.0150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 1, 0, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 1, 1, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/63 [00:02<00:39,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3697, 0.2882, 0.3421],\n",
            "        [0.0090, 0.9808, 0.0102],\n",
            "        [0.0124, 0.9749, 0.0127],\n",
            "        [0.6004, 0.2814, 0.1181],\n",
            "        [0.9397, 0.0208, 0.0396],\n",
            "        [0.0257, 0.9626, 0.0117],\n",
            "        [0.9335, 0.0232, 0.0433],\n",
            "        [0.0400, 0.9360, 0.0241]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3697, 0.2882, 0.3421],\n",
            "        [0.0090, 0.9808, 0.0102],\n",
            "        [0.0124, 0.9749, 0.0127],\n",
            "        [0.6004, 0.2814, 0.1181],\n",
            "        [0.9397, 0.0208, 0.0396],\n",
            "        [0.0257, 0.9626, 0.0117],\n",
            "        [0.9335, 0.0232, 0.0433],\n",
            "        [0.0400, 0.9360, 0.0241]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/63 [00:03<00:38,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9807, 0.0082, 0.0110],\n",
            "        [0.5181, 0.2142, 0.2677],\n",
            "        [0.9856, 0.0055, 0.0089],\n",
            "        [0.9855, 0.0052, 0.0092],\n",
            "        [0.6848, 0.1177, 0.1975],\n",
            "        [0.0176, 0.9682, 0.0142],\n",
            "        [0.0413, 0.9311, 0.0276],\n",
            "        [0.0255, 0.9616, 0.0129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9807, 0.0082, 0.0110],\n",
            "        [0.5181, 0.2142, 0.2677],\n",
            "        [0.9856, 0.0055, 0.0089],\n",
            "        [0.9855, 0.0052, 0.0092],\n",
            "        [0.6848, 0.1177, 0.1975],\n",
            "        [0.0176, 0.9682, 0.0142],\n",
            "        [0.0413, 0.9311, 0.0276],\n",
            "        [0.0255, 0.9616, 0.0129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 0, 2, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 6/63 [00:04<00:38,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0062, 0.9730, 0.0208],\n",
            "        [0.0203, 0.1621, 0.8177],\n",
            "        [0.0122, 0.9664, 0.0214],\n",
            "        [0.9790, 0.0087, 0.0123],\n",
            "        [0.9555, 0.0257, 0.0188],\n",
            "        [0.0168, 0.9709, 0.0123],\n",
            "        [0.1449, 0.2226, 0.6326],\n",
            "        [0.0580, 0.1206, 0.8215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0062, 0.9730, 0.0208],\n",
            "        [0.0203, 0.1621, 0.8177],\n",
            "        [0.0122, 0.9664, 0.0214],\n",
            "        [0.9790, 0.0087, 0.0123],\n",
            "        [0.9555, 0.0257, 0.0188],\n",
            "        [0.0168, 0.9709, 0.0123],\n",
            "        [0.1449, 0.2226, 0.6326],\n",
            "        [0.0580, 0.1206, 0.8215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 0, 0, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 0, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/63 [00:04<00:37,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9378, 0.0200, 0.0422],\n",
            "        [0.9732, 0.0118, 0.0150],\n",
            "        [0.8939, 0.0201, 0.0860],\n",
            "        [0.9817, 0.0054, 0.0129],\n",
            "        [0.0097, 0.9843, 0.0060],\n",
            "        [0.9799, 0.0122, 0.0079],\n",
            "        [0.5513, 0.2533, 0.1954],\n",
            "        [0.0158, 0.0402, 0.9440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9378, 0.0200, 0.0422],\n",
            "        [0.9732, 0.0118, 0.0150],\n",
            "        [0.8939, 0.0201, 0.0860],\n",
            "        [0.9817, 0.0054, 0.0129],\n",
            "        [0.0097, 0.9843, 0.0060],\n",
            "        [0.9799, 0.0122, 0.0079],\n",
            "        [0.5513, 0.2533, 0.1954],\n",
            "        [0.0158, 0.0402, 0.9440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 1, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 1, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/63 [00:05<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0244, 0.9637, 0.0119],\n",
            "        [0.1131, 0.2626, 0.6243],\n",
            "        [0.0030, 0.9880, 0.0090],\n",
            "        [0.0229, 0.0920, 0.8852],\n",
            "        [0.0193, 0.3191, 0.6616],\n",
            "        [0.0154, 0.9656, 0.0190],\n",
            "        [0.0093, 0.9714, 0.0192],\n",
            "        [0.9596, 0.0234, 0.0170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0244, 0.9637, 0.0119],\n",
            "        [0.1131, 0.2626, 0.6243],\n",
            "        [0.0030, 0.9880, 0.0090],\n",
            "        [0.0229, 0.0920, 0.8852],\n",
            "        [0.0193, 0.3191, 0.6616],\n",
            "        [0.0154, 0.9656, 0.0190],\n",
            "        [0.0093, 0.9714, 0.0192],\n",
            "        [0.9596, 0.0234, 0.0170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 2, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 2, 2, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/63 [00:06<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1071, 0.0967, 0.7962],\n",
            "        [0.8241, 0.0297, 0.1462],\n",
            "        [0.2393, 0.5929, 0.1677],\n",
            "        [0.9852, 0.0066, 0.0082],\n",
            "        [0.5892, 0.1377, 0.2732],\n",
            "        [0.9821, 0.0084, 0.0095],\n",
            "        [0.0220, 0.9471, 0.0309],\n",
            "        [0.9772, 0.0117, 0.0111]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1071, 0.0967, 0.7962],\n",
            "        [0.8241, 0.0297, 0.1462],\n",
            "        [0.2393, 0.5929, 0.1677],\n",
            "        [0.9852, 0.0066, 0.0082],\n",
            "        [0.5892, 0.1377, 0.2732],\n",
            "        [0.9821, 0.0084, 0.0095],\n",
            "        [0.0220, 0.9471, 0.0309],\n",
            "        [0.9772, 0.0117, 0.0111]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 0, 0, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/63 [00:06<00:35,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2227, 0.5088, 0.2685],\n",
            "        [0.0085, 0.9820, 0.0095],\n",
            "        [0.0393, 0.0539, 0.9067],\n",
            "        [0.3385, 0.4037, 0.2578],\n",
            "        [0.9813, 0.0034, 0.0153],\n",
            "        [0.9876, 0.0046, 0.0078],\n",
            "        [0.0143, 0.9763, 0.0094],\n",
            "        [0.0118, 0.9761, 0.0121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2227, 0.5088, 0.2685],\n",
            "        [0.0085, 0.9820, 0.0095],\n",
            "        [0.0393, 0.0539, 0.9067],\n",
            "        [0.3385, 0.4037, 0.2578],\n",
            "        [0.9813, 0.0034, 0.0153],\n",
            "        [0.9876, 0.0046, 0.0078],\n",
            "        [0.0143, 0.9763, 0.0094],\n",
            "        [0.0118, 0.9761, 0.0121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 1, 0, 0, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 0, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/63 [00:07<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9848, 0.0066, 0.0086],\n",
            "        [0.5500, 0.2470, 0.2030],\n",
            "        [0.2169, 0.1644, 0.6187],\n",
            "        [0.5147, 0.1531, 0.3322],\n",
            "        [0.0329, 0.2005, 0.7666],\n",
            "        [0.9887, 0.0059, 0.0054],\n",
            "        [0.9834, 0.0074, 0.0093],\n",
            "        [0.0094, 0.9802, 0.0104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9848, 0.0066, 0.0086],\n",
            "        [0.5500, 0.2470, 0.2030],\n",
            "        [0.2169, 0.1644, 0.6187],\n",
            "        [0.5147, 0.1531, 0.3322],\n",
            "        [0.0329, 0.2005, 0.7666],\n",
            "        [0.9887, 0.0059, 0.0054],\n",
            "        [0.9834, 0.0074, 0.0093],\n",
            "        [0.0094, 0.9802, 0.0104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 2, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 1, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/63 [00:08<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0556, 0.0258, 0.9186],\n",
            "        [0.0800, 0.0373, 0.8827],\n",
            "        [0.8654, 0.0107, 0.1239],\n",
            "        [0.0809, 0.0111, 0.9080],\n",
            "        [0.9761, 0.0105, 0.0134],\n",
            "        [0.0121, 0.0401, 0.9478],\n",
            "        [0.0145, 0.5354, 0.4501],\n",
            "        [0.0075, 0.9842, 0.0083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0556, 0.0258, 0.9186],\n",
            "        [0.0800, 0.0373, 0.8827],\n",
            "        [0.8654, 0.0107, 0.1239],\n",
            "        [0.0809, 0.0111, 0.9080],\n",
            "        [0.9761, 0.0105, 0.0134],\n",
            "        [0.0121, 0.0401, 0.9478],\n",
            "        [0.0145, 0.5354, 0.4501],\n",
            "        [0.0075, 0.9842, 0.0083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 2, 0, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 2, 2, 0, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 13/63 [00:08<00:33,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0137, 0.0981, 0.8883],\n",
            "        [0.0190, 0.9668, 0.0142],\n",
            "        [0.0107, 0.9739, 0.0154],\n",
            "        [0.6470, 0.0160, 0.3370],\n",
            "        [0.9564, 0.0110, 0.0326],\n",
            "        [0.0342, 0.7058, 0.2600],\n",
            "        [0.0626, 0.1303, 0.8071],\n",
            "        [0.0171, 0.9497, 0.0332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0137, 0.0981, 0.8883],\n",
            "        [0.0190, 0.9668, 0.0142],\n",
            "        [0.0107, 0.9739, 0.0154],\n",
            "        [0.6470, 0.0160, 0.3370],\n",
            "        [0.9564, 0.0110, 0.0326],\n",
            "        [0.0342, 0.7058, 0.2600],\n",
            "        [0.0626, 0.1303, 0.8071],\n",
            "        [0.0171, 0.9497, 0.0332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 2, 0, 2, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/63 [00:09<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0416, 0.0340, 0.9244],\n",
            "        [0.9571, 0.0092, 0.0337],\n",
            "        [0.4495, 0.2365, 0.3141],\n",
            "        [0.0112, 0.1438, 0.8449],\n",
            "        [0.3515, 0.2183, 0.4302],\n",
            "        [0.9741, 0.0039, 0.0220],\n",
            "        [0.0097, 0.0175, 0.9728],\n",
            "        [0.9814, 0.0035, 0.0151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0416, 0.0340, 0.9244],\n",
            "        [0.9571, 0.0092, 0.0337],\n",
            "        [0.4495, 0.2365, 0.3141],\n",
            "        [0.0112, 0.1438, 0.8449],\n",
            "        [0.3515, 0.2183, 0.4302],\n",
            "        [0.9741, 0.0039, 0.0220],\n",
            "        [0.0097, 0.0175, 0.9728],\n",
            "        [0.9814, 0.0035, 0.0151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 2, 2, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 2, 2, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 15/63 [00:10<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9680, 0.0103, 0.0217],\n",
            "        [0.0223, 0.9596, 0.0181],\n",
            "        [0.0183, 0.0236, 0.9581],\n",
            "        [0.0169, 0.1650, 0.8181],\n",
            "        [0.9437, 0.0278, 0.0285],\n",
            "        [0.9787, 0.0069, 0.0144],\n",
            "        [0.0180, 0.0230, 0.9590],\n",
            "        [0.1942, 0.0610, 0.7447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9680, 0.0103, 0.0217],\n",
            "        [0.0223, 0.9596, 0.0181],\n",
            "        [0.0183, 0.0236, 0.9581],\n",
            "        [0.0169, 0.1650, 0.8181],\n",
            "        [0.9437, 0.0278, 0.0285],\n",
            "        [0.9787, 0.0069, 0.0144],\n",
            "        [0.0180, 0.0230, 0.9590],\n",
            "        [0.1942, 0.0610, 0.7447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 2, 0, 0, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 0, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/63 [00:10<00:31,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.1126, 0.0877, 0.7998],\n",
            "        [0.0229, 0.0301, 0.9469],\n",
            "        [0.0101, 0.9805, 0.0094],\n",
            "        [0.0269, 0.0295, 0.9436],\n",
            "        [0.0242, 0.0486, 0.9272],\n",
            "        [0.9904, 0.0028, 0.0068],\n",
            "        [0.9496, 0.0155, 0.0349],\n",
            "        [0.0982, 0.0145, 0.8873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.1126, 0.0877, 0.7998],\n",
            "        [0.0229, 0.0301, 0.9469],\n",
            "        [0.0101, 0.9805, 0.0094],\n",
            "        [0.0269, 0.0295, 0.9436],\n",
            "        [0.0242, 0.0486, 0.9272],\n",
            "        [0.9904, 0.0028, 0.0068],\n",
            "        [0.9496, 0.0155, 0.0349],\n",
            "        [0.0982, 0.0145, 0.8873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 2, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 2, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/63 [00:11<00:31,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0353, 0.0188, 0.9459],\n",
            "        [0.9510, 0.0124, 0.0366],\n",
            "        [0.9835, 0.0052, 0.0113],\n",
            "        [0.5996, 0.3058, 0.0946],\n",
            "        [0.9894, 0.0060, 0.0046],\n",
            "        [0.9843, 0.0055, 0.0102],\n",
            "        [0.9787, 0.0069, 0.0144],\n",
            "        [0.9838, 0.0055, 0.0107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0353, 0.0188, 0.9459],\n",
            "        [0.9510, 0.0124, 0.0366],\n",
            "        [0.9835, 0.0052, 0.0113],\n",
            "        [0.5996, 0.3058, 0.0946],\n",
            "        [0.9894, 0.0060, 0.0046],\n",
            "        [0.9843, 0.0055, 0.0102],\n",
            "        [0.9787, 0.0069, 0.0144],\n",
            "        [0.9838, 0.0055, 0.0107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 0, 0, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 18/63 [00:12<00:30,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9803, 0.0058, 0.0139],\n",
            "        [0.0095, 0.0732, 0.9172],\n",
            "        [0.9148, 0.0052, 0.0800],\n",
            "        [0.0264, 0.0813, 0.8923],\n",
            "        [0.4238, 0.4406, 0.1356],\n",
            "        [0.1259, 0.4300, 0.4441],\n",
            "        [0.8485, 0.0799, 0.0716],\n",
            "        [0.0284, 0.0417, 0.9299]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9803, 0.0058, 0.0139],\n",
            "        [0.0095, 0.0732, 0.9172],\n",
            "        [0.9148, 0.0052, 0.0800],\n",
            "        [0.0264, 0.0813, 0.8923],\n",
            "        [0.4238, 0.4406, 0.1356],\n",
            "        [0.1259, 0.4300, 0.4441],\n",
            "        [0.8485, 0.0799, 0.0716],\n",
            "        [0.0284, 0.0417, 0.9299]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 2, 1, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 1, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 19/63 [00:12<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0079, 0.9567, 0.0354],\n",
            "        [0.0088, 0.9458, 0.0454],\n",
            "        [0.0138, 0.9578, 0.0284],\n",
            "        [0.9167, 0.0101, 0.0732],\n",
            "        [0.0158, 0.9612, 0.0231],\n",
            "        [0.9767, 0.0040, 0.0193],\n",
            "        [0.0049, 0.9737, 0.0214],\n",
            "        [0.5313, 0.0637, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0079, 0.9567, 0.0354],\n",
            "        [0.0088, 0.9458, 0.0454],\n",
            "        [0.0138, 0.9578, 0.0284],\n",
            "        [0.9167, 0.0101, 0.0732],\n",
            "        [0.0158, 0.9612, 0.0231],\n",
            "        [0.9767, 0.0040, 0.0193],\n",
            "        [0.0049, 0.9737, 0.0214],\n",
            "        [0.5313, 0.0637, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 0, 1, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 20/63 [00:13<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9867, 0.0062, 0.0071],\n",
            "        [0.0095, 0.9775, 0.0130],\n",
            "        [0.0797, 0.0464, 0.8738],\n",
            "        [0.9891, 0.0029, 0.0080],\n",
            "        [0.4000, 0.0594, 0.5407],\n",
            "        [0.0473, 0.0350, 0.9177],\n",
            "        [0.0170, 0.8278, 0.1552],\n",
            "        [0.2271, 0.5012, 0.2717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9867, 0.0062, 0.0071],\n",
            "        [0.0095, 0.9775, 0.0130],\n",
            "        [0.0797, 0.0464, 0.8738],\n",
            "        [0.9891, 0.0029, 0.0080],\n",
            "        [0.4000, 0.0594, 0.5407],\n",
            "        [0.0473, 0.0350, 0.9177],\n",
            "        [0.0170, 0.8278, 0.1552],\n",
            "        [0.2271, 0.5012, 0.2717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 0, 2, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 0, 0, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/63 [00:14<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9762, 0.0086, 0.0152],\n",
            "        [0.0036, 0.9820, 0.0144],\n",
            "        [0.9512, 0.0044, 0.0444],\n",
            "        [0.0154, 0.0649, 0.9197],\n",
            "        [0.5500, 0.0141, 0.4359],\n",
            "        [0.0221, 0.0185, 0.9595],\n",
            "        [0.0056, 0.9668, 0.0276],\n",
            "        [0.9676, 0.0109, 0.0215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9762, 0.0086, 0.0152],\n",
            "        [0.0036, 0.9820, 0.0144],\n",
            "        [0.9512, 0.0044, 0.0444],\n",
            "        [0.0154, 0.0649, 0.9197],\n",
            "        [0.5500, 0.0141, 0.4359],\n",
            "        [0.0221, 0.0185, 0.9595],\n",
            "        [0.0056, 0.9668, 0.0276],\n",
            "        [0.9676, 0.0109, 0.0215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 0, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 2, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 22/63 [00:14<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0143, 0.0108, 0.9749],\n",
            "        [0.0091, 0.9612, 0.0297],\n",
            "        [0.0703, 0.0073, 0.9223],\n",
            "        [0.2379, 0.0351, 0.7270],\n",
            "        [0.0101, 0.9201, 0.0698],\n",
            "        [0.0617, 0.0494, 0.8889],\n",
            "        [0.0077, 0.5996, 0.3927],\n",
            "        [0.0145, 0.7304, 0.2551]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0143, 0.0108, 0.9749],\n",
            "        [0.0091, 0.9612, 0.0297],\n",
            "        [0.0703, 0.0073, 0.9223],\n",
            "        [0.2379, 0.0351, 0.7270],\n",
            "        [0.0101, 0.9201, 0.0698],\n",
            "        [0.0617, 0.0494, 0.8889],\n",
            "        [0.0077, 0.5996, 0.3927],\n",
            "        [0.0145, 0.7304, 0.2551]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 2, 1, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 2, 1, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 23/63 [00:15<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9887, 0.0058, 0.0054],\n",
            "        [0.9910, 0.0030, 0.0061],\n",
            "        [0.8945, 0.0361, 0.0693],\n",
            "        [0.0130, 0.9530, 0.0340],\n",
            "        [0.9040, 0.0050, 0.0910],\n",
            "        [0.0130, 0.9628, 0.0243],\n",
            "        [0.0605, 0.1542, 0.7853],\n",
            "        [0.0124, 0.8545, 0.1331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9887, 0.0058, 0.0054],\n",
            "        [0.9910, 0.0030, 0.0061],\n",
            "        [0.8945, 0.0361, 0.0693],\n",
            "        [0.0130, 0.9530, 0.0340],\n",
            "        [0.9040, 0.0050, 0.0910],\n",
            "        [0.0130, 0.9628, 0.0243],\n",
            "        [0.0605, 0.1542, 0.7853],\n",
            "        [0.0124, 0.8545, 0.1331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 1, 0, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 1, 2, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/63 [00:16<00:26,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0405, 0.0729, 0.8866],\n",
            "        [0.2391, 0.0702, 0.6907],\n",
            "        [0.0883, 0.0980, 0.8137],\n",
            "        [0.3232, 0.1948, 0.4820],\n",
            "        [0.0179, 0.9399, 0.0422],\n",
            "        [0.0117, 0.9629, 0.0254],\n",
            "        [0.9728, 0.0121, 0.0151],\n",
            "        [0.9841, 0.0053, 0.0106]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0405, 0.0729, 0.8866],\n",
            "        [0.2391, 0.0702, 0.6907],\n",
            "        [0.0883, 0.0980, 0.8137],\n",
            "        [0.3232, 0.1948, 0.4820],\n",
            "        [0.0179, 0.9399, 0.0422],\n",
            "        [0.0117, 0.9629, 0.0254],\n",
            "        [0.9728, 0.0121, 0.0151],\n",
            "        [0.9841, 0.0053, 0.0106]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 2, 1, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 0, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 25/63 [00:16<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0103, 0.8803, 0.1094],\n",
            "        [0.0171, 0.0283, 0.9546],\n",
            "        [0.0081, 0.2160, 0.7758],\n",
            "        [0.0131, 0.9440, 0.0429],\n",
            "        [0.0043, 0.9789, 0.0169],\n",
            "        [0.0087, 0.9715, 0.0198],\n",
            "        [0.9861, 0.0068, 0.0071],\n",
            "        [0.0080, 0.9627, 0.0293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0103, 0.8803, 0.1094],\n",
            "        [0.0171, 0.0283, 0.9546],\n",
            "        [0.0081, 0.2160, 0.7758],\n",
            "        [0.0131, 0.9440, 0.0429],\n",
            "        [0.0043, 0.9789, 0.0169],\n",
            "        [0.0087, 0.9715, 0.0198],\n",
            "        [0.9861, 0.0068, 0.0071],\n",
            "        [0.0080, 0.9627, 0.0293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 1, 1, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 1, 1, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 26/63 [00:17<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0069, 0.9727, 0.0204],\n",
            "        [0.0308, 0.0134, 0.9559],\n",
            "        [0.0080, 0.9536, 0.0384],\n",
            "        [0.0099, 0.8109, 0.1791],\n",
            "        [0.9609, 0.0121, 0.0270],\n",
            "        [0.0120, 0.0094, 0.9785],\n",
            "        [0.0050, 0.9672, 0.0278],\n",
            "        [0.0376, 0.0707, 0.8917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0069, 0.9727, 0.0204],\n",
            "        [0.0308, 0.0134, 0.9559],\n",
            "        [0.0080, 0.9536, 0.0384],\n",
            "        [0.0099, 0.8109, 0.1791],\n",
            "        [0.9609, 0.0121, 0.0270],\n",
            "        [0.0120, 0.0094, 0.9785],\n",
            "        [0.0050, 0.9672, 0.0278],\n",
            "        [0.0376, 0.0707, 0.8917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 1, 0, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 27/63 [00:18<00:24,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9881, 0.0042, 0.0077],\n",
            "        [0.9246, 0.0206, 0.0548],\n",
            "        [0.0165, 0.0180, 0.9656],\n",
            "        [0.0123, 0.0331, 0.9546],\n",
            "        [0.0522, 0.1198, 0.8279],\n",
            "        [0.9096, 0.0133, 0.0771],\n",
            "        [0.0084, 0.9676, 0.0240],\n",
            "        [0.0347, 0.0465, 0.9188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9881, 0.0042, 0.0077],\n",
            "        [0.9246, 0.0206, 0.0548],\n",
            "        [0.0165, 0.0180, 0.9656],\n",
            "        [0.0123, 0.0331, 0.9546],\n",
            "        [0.0522, 0.1198, 0.8279],\n",
            "        [0.9096, 0.0133, 0.0771],\n",
            "        [0.0084, 0.9676, 0.0240],\n",
            "        [0.0347, 0.0465, 0.9188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 2, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 2, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/63 [00:18<00:23,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2553, 0.0642, 0.6805],\n",
            "        [0.9762, 0.0058, 0.0180],\n",
            "        [0.1877, 0.7158, 0.0965],\n",
            "        [0.1957, 0.0402, 0.7641],\n",
            "        [0.2848, 0.0193, 0.6959],\n",
            "        [0.0118, 0.9659, 0.0223],\n",
            "        [0.0039, 0.9054, 0.0908],\n",
            "        [0.0063, 0.9469, 0.0468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2553, 0.0642, 0.6805],\n",
            "        [0.9762, 0.0058, 0.0180],\n",
            "        [0.1877, 0.7158, 0.0965],\n",
            "        [0.1957, 0.0402, 0.7641],\n",
            "        [0.2848, 0.0193, 0.6959],\n",
            "        [0.0118, 0.9659, 0.0223],\n",
            "        [0.0039, 0.9054, 0.0908],\n",
            "        [0.0063, 0.9469, 0.0468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 2, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 1, 0, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 29/63 [00:19<00:23,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0150, 0.9659, 0.0191],\n",
            "        [0.0153, 0.0646, 0.9200],\n",
            "        [0.0093, 0.9768, 0.0138],\n",
            "        [0.0247, 0.0385, 0.9368],\n",
            "        [0.0118, 0.9609, 0.0273],\n",
            "        [0.9844, 0.0051, 0.0105],\n",
            "        [0.0085, 0.9687, 0.0227],\n",
            "        [0.0263, 0.0122, 0.9616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0150, 0.9659, 0.0191],\n",
            "        [0.0153, 0.0646, 0.9200],\n",
            "        [0.0093, 0.9768, 0.0138],\n",
            "        [0.0247, 0.0385, 0.9368],\n",
            "        [0.0118, 0.9609, 0.0273],\n",
            "        [0.9844, 0.0051, 0.0105],\n",
            "        [0.0085, 0.9687, 0.0227],\n",
            "        [0.0263, 0.0122, 0.9616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 2, 1, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 2, 1, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 30/63 [00:20<00:22,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8646, 0.0136, 0.1218],\n",
            "        [0.9793, 0.0046, 0.0161],\n",
            "        [0.0249, 0.0191, 0.9559],\n",
            "        [0.9670, 0.0035, 0.0295],\n",
            "        [0.0212, 0.0278, 0.9511],\n",
            "        [0.0655, 0.0167, 0.9178],\n",
            "        [0.1050, 0.0615, 0.8335],\n",
            "        [0.0105, 0.9786, 0.0109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8646, 0.0136, 0.1218],\n",
            "        [0.9793, 0.0046, 0.0161],\n",
            "        [0.0249, 0.0191, 0.9559],\n",
            "        [0.9670, 0.0035, 0.0295],\n",
            "        [0.0212, 0.0278, 0.9511],\n",
            "        [0.0655, 0.0167, 0.9178],\n",
            "        [0.1050, 0.0615, 0.8335],\n",
            "        [0.0105, 0.9786, 0.0109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 2, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 31/63 [00:20<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0276, 0.0226, 0.9499],\n",
            "        [0.8255, 0.0261, 0.1484],\n",
            "        [0.9899, 0.0054, 0.0046],\n",
            "        [0.9861, 0.0060, 0.0079],\n",
            "        [0.9575, 0.0055, 0.0370],\n",
            "        [0.0086, 0.9800, 0.0114],\n",
            "        [0.9520, 0.0118, 0.0362],\n",
            "        [0.9898, 0.0040, 0.0062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0276, 0.0226, 0.9499],\n",
            "        [0.8255, 0.0261, 0.1484],\n",
            "        [0.9899, 0.0054, 0.0046],\n",
            "        [0.9861, 0.0060, 0.0079],\n",
            "        [0.9575, 0.0055, 0.0370],\n",
            "        [0.0086, 0.9800, 0.0114],\n",
            "        [0.9520, 0.0118, 0.0362],\n",
            "        [0.9898, 0.0040, 0.0062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 32/63 [00:21<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9858, 0.0049, 0.0093],\n",
            "        [0.0355, 0.0262, 0.9383],\n",
            "        [0.0076, 0.1375, 0.8549],\n",
            "        [0.9877, 0.0066, 0.0057],\n",
            "        [0.0107, 0.9665, 0.0228],\n",
            "        [0.9885, 0.0054, 0.0061],\n",
            "        [0.9486, 0.0044, 0.0470],\n",
            "        [0.0163, 0.0269, 0.9568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9858, 0.0049, 0.0093],\n",
            "        [0.0355, 0.0262, 0.9383],\n",
            "        [0.0076, 0.1375, 0.8549],\n",
            "        [0.9877, 0.0066, 0.0057],\n",
            "        [0.0107, 0.9665, 0.0228],\n",
            "        [0.9885, 0.0054, 0.0061],\n",
            "        [0.9486, 0.0044, 0.0470],\n",
            "        [0.0163, 0.0269, 0.9568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 0, 1, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 0, 1, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/63 [00:22<00:20,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9733, 0.0090, 0.0176],\n",
            "        [0.2802, 0.0650, 0.6548],\n",
            "        [0.9536, 0.0137, 0.0327],\n",
            "        [0.0254, 0.0264, 0.9482],\n",
            "        [0.9702, 0.0190, 0.0108],\n",
            "        [0.9632, 0.0060, 0.0308],\n",
            "        [0.0497, 0.0179, 0.9324],\n",
            "        [0.9628, 0.0162, 0.0210]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9733, 0.0090, 0.0176],\n",
            "        [0.2802, 0.0650, 0.6548],\n",
            "        [0.9536, 0.0137, 0.0327],\n",
            "        [0.0254, 0.0264, 0.9482],\n",
            "        [0.9702, 0.0190, 0.0108],\n",
            "        [0.9632, 0.0060, 0.0308],\n",
            "        [0.0497, 0.0179, 0.9324],\n",
            "        [0.9628, 0.0162, 0.0210]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 2, 0, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 2, 0, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 34/63 [00:23<00:19,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9841, 0.0049, 0.0111],\n",
            "        [0.0113, 0.9646, 0.0240],\n",
            "        [0.0119, 0.0289, 0.9592],\n",
            "        [0.9884, 0.0064, 0.0052],\n",
            "        [0.0142, 0.9669, 0.0189],\n",
            "        [0.0923, 0.0821, 0.8256],\n",
            "        [0.0154, 0.0219, 0.9627],\n",
            "        [0.2331, 0.4296, 0.3373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9841, 0.0049, 0.0111],\n",
            "        [0.0113, 0.9646, 0.0240],\n",
            "        [0.0119, 0.0289, 0.9592],\n",
            "        [0.9884, 0.0064, 0.0052],\n",
            "        [0.0142, 0.9669, 0.0189],\n",
            "        [0.0923, 0.0821, 0.8256],\n",
            "        [0.0154, 0.0219, 0.9627],\n",
            "        [0.2331, 0.4296, 0.3373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 0, 1, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 0, 1, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 35/63 [00:23<00:19,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2510, 0.0436, 0.7054],\n",
            "        [0.0586, 0.6127, 0.3287],\n",
            "        [0.9806, 0.0052, 0.0142],\n",
            "        [0.0181, 0.0227, 0.9592],\n",
            "        [0.0150, 0.9744, 0.0105],\n",
            "        [0.0128, 0.9764, 0.0108],\n",
            "        [0.9895, 0.0047, 0.0058],\n",
            "        [0.1989, 0.0442, 0.7568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2510, 0.0436, 0.7054],\n",
            "        [0.0586, 0.6127, 0.3287],\n",
            "        [0.9806, 0.0052, 0.0142],\n",
            "        [0.0181, 0.0227, 0.9592],\n",
            "        [0.0150, 0.9744, 0.0105],\n",
            "        [0.0128, 0.9764, 0.0108],\n",
            "        [0.9895, 0.0047, 0.0058],\n",
            "        [0.1989, 0.0442, 0.7568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 2, 1, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 2, 1, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 36/63 [00:24<00:18,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0137, 0.9701, 0.0162],\n",
            "        [0.0042, 0.9766, 0.0192],\n",
            "        [0.9906, 0.0056, 0.0039],\n",
            "        [0.0082, 0.9802, 0.0116],\n",
            "        [0.9878, 0.0038, 0.0084],\n",
            "        [0.0129, 0.9789, 0.0082],\n",
            "        [0.0090, 0.9614, 0.0295],\n",
            "        [0.8351, 0.0317, 0.1332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0137, 0.9701, 0.0162],\n",
            "        [0.0042, 0.9766, 0.0192],\n",
            "        [0.9906, 0.0056, 0.0039],\n",
            "        [0.0082, 0.9802, 0.0116],\n",
            "        [0.9878, 0.0038, 0.0084],\n",
            "        [0.0129, 0.9789, 0.0082],\n",
            "        [0.0090, 0.9614, 0.0295],\n",
            "        [0.8351, 0.0317, 0.1332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 37/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9836, 0.0073, 0.0091],\n",
            "        [0.9753, 0.0059, 0.0188],\n",
            "        [0.6321, 0.0195, 0.3484],\n",
            "        [0.8927, 0.0292, 0.0781],\n",
            "        [0.0447, 0.0105, 0.9448],\n",
            "        [0.0594, 0.0208, 0.9198],\n",
            "        [0.0101, 0.8926, 0.0973],\n",
            "        [0.9884, 0.0028, 0.0089]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9836, 0.0073, 0.0091],\n",
            "        [0.9753, 0.0059, 0.0188],\n",
            "        [0.6321, 0.0195, 0.3484],\n",
            "        [0.8927, 0.0292, 0.0781],\n",
            "        [0.0447, 0.0105, 0.9448],\n",
            "        [0.0594, 0.0208, 0.9198],\n",
            "        [0.0101, 0.8926, 0.0973],\n",
            "        [0.9884, 0.0028, 0.0089]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 2, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 2, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 38/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9679, 0.0042, 0.0279],\n",
            "        [0.9897, 0.0045, 0.0058],\n",
            "        [0.0034, 0.9747, 0.0219],\n",
            "        [0.0107, 0.0937, 0.8956],\n",
            "        [0.0181, 0.9703, 0.0116],\n",
            "        [0.4580, 0.3111, 0.2309],\n",
            "        [0.0083, 0.0167, 0.9750],\n",
            "        [0.0079, 0.9745, 0.0177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9679, 0.0042, 0.0279],\n",
            "        [0.9897, 0.0045, 0.0058],\n",
            "        [0.0034, 0.9747, 0.0219],\n",
            "        [0.0107, 0.0937, 0.8956],\n",
            "        [0.0181, 0.9703, 0.0116],\n",
            "        [0.4580, 0.3111, 0.2309],\n",
            "        [0.0083, 0.0167, 0.9750],\n",
            "        [0.0079, 0.9745, 0.0177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 2, 1, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 1, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 39/63 [00:26<00:16,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0194, 0.2879, 0.6927],\n",
            "        [0.0291, 0.0558, 0.9151],\n",
            "        [0.0118, 0.9607, 0.0275],\n",
            "        [0.0272, 0.0249, 0.9479],\n",
            "        [0.9734, 0.0064, 0.0203],\n",
            "        [0.0075, 0.9733, 0.0192],\n",
            "        [0.9704, 0.0075, 0.0221],\n",
            "        [0.0098, 0.9710, 0.0192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0194, 0.2879, 0.6927],\n",
            "        [0.0291, 0.0558, 0.9151],\n",
            "        [0.0118, 0.9607, 0.0275],\n",
            "        [0.0272, 0.0249, 0.9479],\n",
            "        [0.9734, 0.0064, 0.0203],\n",
            "        [0.0075, 0.9733, 0.0192],\n",
            "        [0.9704, 0.0075, 0.0221],\n",
            "        [0.0098, 0.9710, 0.0192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 2, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 0, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 40/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9881, 0.0053, 0.0065],\n",
            "        [0.9863, 0.0035, 0.0102],\n",
            "        [0.0092, 0.9775, 0.0134],\n",
            "        [0.2803, 0.1036, 0.6160],\n",
            "        [0.0781, 0.2077, 0.7142],\n",
            "        [0.9533, 0.0257, 0.0209],\n",
            "        [0.0131, 0.9702, 0.0166],\n",
            "        [0.0267, 0.0344, 0.9389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9881, 0.0053, 0.0065],\n",
            "        [0.9863, 0.0035, 0.0102],\n",
            "        [0.0092, 0.9775, 0.0134],\n",
            "        [0.2803, 0.1036, 0.6160],\n",
            "        [0.0781, 0.2077, 0.7142],\n",
            "        [0.9533, 0.0257, 0.0209],\n",
            "        [0.0131, 0.9702, 0.0166],\n",
            "        [0.0267, 0.0344, 0.9389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 2, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 0, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 41/63 [00:27<00:15,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0329, 0.0393, 0.9279],\n",
            "        [0.0084, 0.9842, 0.0074],\n",
            "        [0.9812, 0.0115, 0.0073],\n",
            "        [0.1536, 0.0907, 0.7557],\n",
            "        [0.7414, 0.1182, 0.1403],\n",
            "        [0.0232, 0.0235, 0.9533],\n",
            "        [0.1188, 0.6852, 0.1960],\n",
            "        [0.0222, 0.0079, 0.9699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0329, 0.0393, 0.9279],\n",
            "        [0.0084, 0.9842, 0.0074],\n",
            "        [0.9812, 0.0115, 0.0073],\n",
            "        [0.1536, 0.0907, 0.7557],\n",
            "        [0.7414, 0.1182, 0.1403],\n",
            "        [0.0232, 0.0235, 0.9533],\n",
            "        [0.1188, 0.6852, 0.1960],\n",
            "        [0.0222, 0.0079, 0.9699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 2, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 2, 0, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 42/63 [00:28<00:14,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0068, 0.9744, 0.0188],\n",
            "        [0.9799, 0.0083, 0.0118],\n",
            "        [0.9817, 0.0063, 0.0121],\n",
            "        [0.9747, 0.0104, 0.0149],\n",
            "        [0.9840, 0.0059, 0.0101],\n",
            "        [0.0071, 0.9839, 0.0090],\n",
            "        [0.0047, 0.9919, 0.0034],\n",
            "        [0.9876, 0.0059, 0.0065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0068, 0.9744, 0.0188],\n",
            "        [0.9799, 0.0083, 0.0118],\n",
            "        [0.9817, 0.0063, 0.0121],\n",
            "        [0.9747, 0.0104, 0.0149],\n",
            "        [0.9840, 0.0059, 0.0101],\n",
            "        [0.0071, 0.9839, 0.0090],\n",
            "        [0.0047, 0.9919, 0.0034],\n",
            "        [0.9876, 0.0059, 0.0065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 0, 0, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 43/63 [00:29<00:13,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0047, 0.9721, 0.0232],\n",
            "        [0.0041, 0.9890, 0.0069],\n",
            "        [0.0525, 0.0553, 0.8922],\n",
            "        [0.9798, 0.0050, 0.0153],\n",
            "        [0.3217, 0.2511, 0.4272],\n",
            "        [0.9833, 0.0081, 0.0086],\n",
            "        [0.0087, 0.9356, 0.0558],\n",
            "        [0.9553, 0.0218, 0.0228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0047, 0.9721, 0.0232],\n",
            "        [0.0041, 0.9890, 0.0069],\n",
            "        [0.0525, 0.0553, 0.8922],\n",
            "        [0.9798, 0.0050, 0.0153],\n",
            "        [0.3217, 0.2511, 0.4272],\n",
            "        [0.9833, 0.0081, 0.0086],\n",
            "        [0.0087, 0.9356, 0.0558],\n",
            "        [0.9553, 0.0218, 0.0228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 0, 2, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 0, 0, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 44/63 [00:29<00:13,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.8350, 0.0108, 0.1543],\n",
            "        [0.0701, 0.0091, 0.9207],\n",
            "        [0.0063, 0.0111, 0.9826],\n",
            "        [0.0245, 0.9360, 0.0395],\n",
            "        [0.0128, 0.0145, 0.9728],\n",
            "        [0.0115, 0.9742, 0.0143],\n",
            "        [0.8832, 0.0394, 0.0774],\n",
            "        [0.0247, 0.0475, 0.9278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.8350, 0.0108, 0.1543],\n",
            "        [0.0701, 0.0091, 0.9207],\n",
            "        [0.0063, 0.0111, 0.9826],\n",
            "        [0.0245, 0.9360, 0.0395],\n",
            "        [0.0128, 0.0145, 0.9728],\n",
            "        [0.0115, 0.9742, 0.0143],\n",
            "        [0.8832, 0.0394, 0.0774],\n",
            "        [0.0247, 0.0475, 0.9278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 1, 2, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 2, 1, 2, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 45/63 [00:30<00:12,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0337, 0.1941, 0.7723],\n",
            "        [0.9823, 0.0057, 0.0120],\n",
            "        [0.0171, 0.0343, 0.9486],\n",
            "        [0.9602, 0.0110, 0.0288],\n",
            "        [0.0334, 0.0187, 0.9479],\n",
            "        [0.0450, 0.0824, 0.8726],\n",
            "        [0.6239, 0.0293, 0.3467],\n",
            "        [0.0034, 0.9899, 0.0067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0337, 0.1941, 0.7723],\n",
            "        [0.9823, 0.0057, 0.0120],\n",
            "        [0.0171, 0.0343, 0.9486],\n",
            "        [0.9602, 0.0110, 0.0288],\n",
            "        [0.0334, 0.0187, 0.9479],\n",
            "        [0.0450, 0.0824, 0.8726],\n",
            "        [0.6239, 0.0293, 0.3467],\n",
            "        [0.0034, 0.9899, 0.0067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 0, 2, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 2, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 46/63 [00:31<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9896, 0.0036, 0.0068],\n",
            "        [0.9695, 0.0110, 0.0195],\n",
            "        [0.9851, 0.0068, 0.0081],\n",
            "        [0.0267, 0.0885, 0.8848],\n",
            "        [0.9767, 0.0069, 0.0164],\n",
            "        [0.0697, 0.0249, 0.9054],\n",
            "        [0.0054, 0.9501, 0.0444],\n",
            "        [0.0071, 0.9794, 0.0135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9896, 0.0036, 0.0068],\n",
            "        [0.9695, 0.0110, 0.0195],\n",
            "        [0.9851, 0.0068, 0.0081],\n",
            "        [0.0267, 0.0885, 0.8848],\n",
            "        [0.9767, 0.0069, 0.0164],\n",
            "        [0.0697, 0.0249, 0.9054],\n",
            "        [0.0054, 0.9501, 0.0444],\n",
            "        [0.0071, 0.9794, 0.0135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 2, 0, 2, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 2, 0, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 47/63 [00:32<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3550, 0.0583, 0.5866],\n",
            "        [0.0050, 0.9859, 0.0091],\n",
            "        [0.1685, 0.0404, 0.7911],\n",
            "        [0.9808, 0.0096, 0.0096],\n",
            "        [0.9511, 0.0117, 0.0372],\n",
            "        [0.6080, 0.0749, 0.3172],\n",
            "        [0.0102, 0.9705, 0.0193],\n",
            "        [0.0292, 0.0320, 0.9388]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3550, 0.0583, 0.5866],\n",
            "        [0.0050, 0.9859, 0.0091],\n",
            "        [0.1685, 0.0404, 0.7911],\n",
            "        [0.9808, 0.0096, 0.0096],\n",
            "        [0.9511, 0.0117, 0.0372],\n",
            "        [0.6080, 0.0749, 0.3172],\n",
            "        [0.0102, 0.9705, 0.0193],\n",
            "        [0.0292, 0.0320, 0.9388]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 0, 0, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 0, 0, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 48/63 [00:32<00:10,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0080, 0.9626, 0.0295],\n",
            "        [0.1166, 0.6032, 0.2802],\n",
            "        [0.4117, 0.3479, 0.2405],\n",
            "        [0.9869, 0.0067, 0.0064],\n",
            "        [0.0089, 0.9750, 0.0160],\n",
            "        [0.9882, 0.0046, 0.0072],\n",
            "        [0.1030, 0.0356, 0.8614],\n",
            "        [0.9899, 0.0062, 0.0039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0080, 0.9626, 0.0295],\n",
            "        [0.1166, 0.6032, 0.2802],\n",
            "        [0.4117, 0.3479, 0.2405],\n",
            "        [0.9869, 0.0067, 0.0064],\n",
            "        [0.0089, 0.9750, 0.0160],\n",
            "        [0.9882, 0.0046, 0.0072],\n",
            "        [0.1030, 0.0356, 0.8614],\n",
            "        [0.9899, 0.0062, 0.0039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 0, 1, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 0, 1, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 49/63 [00:33<00:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0689, 0.1233, 0.8078],\n",
            "        [0.0169, 0.5461, 0.4370],\n",
            "        [0.0455, 0.0080, 0.9465],\n",
            "        [0.0143, 0.0503, 0.9354],\n",
            "        [0.9675, 0.0083, 0.0242],\n",
            "        [0.9866, 0.0055, 0.0079],\n",
            "        [0.0255, 0.0213, 0.9532],\n",
            "        [0.4296, 0.1430, 0.4274]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0689, 0.1233, 0.8078],\n",
            "        [0.0169, 0.5461, 0.4370],\n",
            "        [0.0455, 0.0080, 0.9465],\n",
            "        [0.0143, 0.0503, 0.9354],\n",
            "        [0.9675, 0.0083, 0.0242],\n",
            "        [0.9866, 0.0055, 0.0079],\n",
            "        [0.0255, 0.0213, 0.9532],\n",
            "        [0.4296, 0.1430, 0.4274]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 2, 0, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 2, 0, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 50/63 [00:34<00:09,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0152, 0.0833, 0.9015],\n",
            "        [0.9916, 0.0056, 0.0028],\n",
            "        [0.0276, 0.1189, 0.8535],\n",
            "        [0.0420, 0.0662, 0.8918],\n",
            "        [0.9867, 0.0049, 0.0084],\n",
            "        [0.7953, 0.0671, 0.1376],\n",
            "        [0.0061, 0.9860, 0.0079],\n",
            "        [0.0213, 0.0170, 0.9617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0152, 0.0833, 0.9015],\n",
            "        [0.9916, 0.0056, 0.0028],\n",
            "        [0.0276, 0.1189, 0.8535],\n",
            "        [0.0420, 0.0662, 0.8918],\n",
            "        [0.9867, 0.0049, 0.0084],\n",
            "        [0.7953, 0.0671, 0.1376],\n",
            "        [0.0061, 0.9860, 0.0079],\n",
            "        [0.0213, 0.0170, 0.9617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 2, 0, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 2, 0, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 51/63 [00:34<00:08,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9749, 0.0059, 0.0192],\n",
            "        [0.9780, 0.0093, 0.0128],\n",
            "        [0.0049, 0.9793, 0.0158],\n",
            "        [0.9885, 0.0052, 0.0062],\n",
            "        [0.0103, 0.9742, 0.0155],\n",
            "        [0.9934, 0.0026, 0.0040],\n",
            "        [0.9937, 0.0020, 0.0043],\n",
            "        [0.0054, 0.9841, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9749, 0.0059, 0.0192],\n",
            "        [0.9780, 0.0093, 0.0128],\n",
            "        [0.0049, 0.9793, 0.0158],\n",
            "        [0.9885, 0.0052, 0.0062],\n",
            "        [0.0103, 0.9742, 0.0155],\n",
            "        [0.9934, 0.0026, 0.0040],\n",
            "        [0.9937, 0.0020, 0.0043],\n",
            "        [0.0054, 0.9841, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 52/63 [00:35<00:07,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0497, 0.0317, 0.9186],\n",
            "        [0.9674, 0.0123, 0.0203],\n",
            "        [0.9902, 0.0062, 0.0036],\n",
            "        [0.0921, 0.0314, 0.8765],\n",
            "        [0.0049, 0.9864, 0.0087],\n",
            "        [0.0112, 0.0142, 0.9747],\n",
            "        [0.9705, 0.0113, 0.0182],\n",
            "        [0.9823, 0.0100, 0.0077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0497, 0.0317, 0.9186],\n",
            "        [0.9674, 0.0123, 0.0203],\n",
            "        [0.9902, 0.0062, 0.0036],\n",
            "        [0.0921, 0.0314, 0.8765],\n",
            "        [0.0049, 0.9864, 0.0087],\n",
            "        [0.0112, 0.0142, 0.9747],\n",
            "        [0.9705, 0.0113, 0.0182],\n",
            "        [0.9823, 0.0100, 0.0077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 2, 1, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 1, 1, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 53/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0071, 0.9558, 0.0371],\n",
            "        [0.0063, 0.9794, 0.0143],\n",
            "        [0.0105, 0.0165, 0.9730],\n",
            "        [0.2510, 0.0783, 0.6707],\n",
            "        [0.3727, 0.2149, 0.4125],\n",
            "        [0.0083, 0.9823, 0.0095],\n",
            "        [0.0153, 0.9714, 0.0133],\n",
            "        [0.9646, 0.0100, 0.0255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0071, 0.9558, 0.0371],\n",
            "        [0.0063, 0.9794, 0.0143],\n",
            "        [0.0105, 0.0165, 0.9730],\n",
            "        [0.2510, 0.0783, 0.6707],\n",
            "        [0.3727, 0.2149, 0.4125],\n",
            "        [0.0083, 0.9823, 0.0095],\n",
            "        [0.0153, 0.9714, 0.0133],\n",
            "        [0.9646, 0.0100, 0.0255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 2, 2, 2, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 0, 2, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 54/63 [00:36<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3269, 0.1230, 0.5502],\n",
            "        [0.0533, 0.1244, 0.8223],\n",
            "        [0.9744, 0.0109, 0.0147],\n",
            "        [0.0057, 0.9575, 0.0369],\n",
            "        [0.9916, 0.0046, 0.0038],\n",
            "        [0.0062, 0.9833, 0.0105],\n",
            "        [0.0068, 0.0333, 0.9599],\n",
            "        [0.0155, 0.9689, 0.0156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3269, 0.1230, 0.5502],\n",
            "        [0.0533, 0.1244, 0.8223],\n",
            "        [0.9744, 0.0109, 0.0147],\n",
            "        [0.0057, 0.9575, 0.0369],\n",
            "        [0.9916, 0.0046, 0.0038],\n",
            "        [0.0062, 0.9833, 0.0105],\n",
            "        [0.0068, 0.0333, 0.9599],\n",
            "        [0.0155, 0.9689, 0.0156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 0, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 2, 0, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 55/63 [00:37<00:05,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0656, 0.0072, 0.9272],\n",
            "        [0.0035, 0.9781, 0.0184],\n",
            "        [0.6941, 0.1952, 0.1107],\n",
            "        [0.0648, 0.0808, 0.8544],\n",
            "        [0.0070, 0.9854, 0.0076],\n",
            "        [0.9916, 0.0044, 0.0040],\n",
            "        [0.9844, 0.0045, 0.0111],\n",
            "        [0.9799, 0.0074, 0.0127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0656, 0.0072, 0.9272],\n",
            "        [0.0035, 0.9781, 0.0184],\n",
            "        [0.6941, 0.1952, 0.1107],\n",
            "        [0.0648, 0.0808, 0.8544],\n",
            "        [0.0070, 0.9854, 0.0076],\n",
            "        [0.9916, 0.0044, 0.0040],\n",
            "        [0.9844, 0.0045, 0.0111],\n",
            "        [0.9799, 0.0074, 0.0127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 2, 1, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 2, 1, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 56/63 [00:38<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9836, 0.0079, 0.0084],\n",
            "        [0.0135, 0.0045, 0.9821],\n",
            "        [0.9823, 0.0095, 0.0082],\n",
            "        [0.0152, 0.9748, 0.0100],\n",
            "        [0.0473, 0.0140, 0.9387],\n",
            "        [0.9890, 0.0057, 0.0054],\n",
            "        [0.0509, 0.1124, 0.8367],\n",
            "        [0.0119, 0.0217, 0.9664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9836, 0.0079, 0.0084],\n",
            "        [0.0135, 0.0045, 0.9821],\n",
            "        [0.9823, 0.0095, 0.0082],\n",
            "        [0.0152, 0.9748, 0.0100],\n",
            "        [0.0473, 0.0140, 0.9387],\n",
            "        [0.9890, 0.0057, 0.0054],\n",
            "        [0.0509, 0.1124, 0.8367],\n",
            "        [0.0119, 0.0217, 0.9664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 1, 2, 0, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 1, 2, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 57/63 [00:39<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0049, 0.9675, 0.0277],\n",
            "        [0.0152, 0.0509, 0.9338],\n",
            "        [0.0062, 0.9742, 0.0196],\n",
            "        [0.9876, 0.0076, 0.0049],\n",
            "        [0.4871, 0.3215, 0.1915],\n",
            "        [0.0090, 0.0159, 0.9751],\n",
            "        [0.4551, 0.0167, 0.5282],\n",
            "        [0.0375, 0.1520, 0.8105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0049, 0.9675, 0.0277],\n",
            "        [0.0152, 0.0509, 0.9338],\n",
            "        [0.0062, 0.9742, 0.0196],\n",
            "        [0.9876, 0.0076, 0.0049],\n",
            "        [0.4871, 0.3215, 0.1915],\n",
            "        [0.0090, 0.0159, 0.9751],\n",
            "        [0.4551, 0.0167, 0.5282],\n",
            "        [0.0375, 0.1520, 0.8105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 0, 0, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 0, 1, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 58/63 [00:39<00:03,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0389, 0.9355, 0.0256],\n",
            "        [0.3779, 0.0967, 0.5254],\n",
            "        [0.0181, 0.0259, 0.9561],\n",
            "        [0.0117, 0.9771, 0.0112],\n",
            "        [0.0143, 0.0679, 0.9177],\n",
            "        [0.0059, 0.9834, 0.0107],\n",
            "        [0.0121, 0.7383, 0.2496],\n",
            "        [0.9904, 0.0061, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0389, 0.9355, 0.0256],\n",
            "        [0.3779, 0.0967, 0.5254],\n",
            "        [0.0181, 0.0259, 0.9561],\n",
            "        [0.0117, 0.9771, 0.0112],\n",
            "        [0.0143, 0.0679, 0.9177],\n",
            "        [0.0059, 0.9834, 0.0107],\n",
            "        [0.0121, 0.7383, 0.2496],\n",
            "        [0.9904, 0.0061, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 1, 2, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 2, 1, 2, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 59/63 [00:40<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.2232, 0.0762, 0.7006],\n",
            "        [0.0145, 0.0608, 0.9247],\n",
            "        [0.4850, 0.2046, 0.3104],\n",
            "        [0.9858, 0.0036, 0.0106],\n",
            "        [0.0075, 0.9813, 0.0111],\n",
            "        [0.2703, 0.5027, 0.2270],\n",
            "        [0.9843, 0.0077, 0.0080],\n",
            "        [0.0076, 0.0516, 0.9408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.2232, 0.0762, 0.7006],\n",
            "        [0.0145, 0.0608, 0.9247],\n",
            "        [0.4850, 0.2046, 0.3104],\n",
            "        [0.9858, 0.0036, 0.0106],\n",
            "        [0.0075, 0.9813, 0.0111],\n",
            "        [0.2703, 0.5027, 0.2270],\n",
            "        [0.9843, 0.0077, 0.0080],\n",
            "        [0.0076, 0.0516, 0.9408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 0, 1, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 0, 1, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 60/63 [00:41<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0048, 0.0486, 0.9466],\n",
            "        [0.9804, 0.0050, 0.0147],\n",
            "        [0.9894, 0.0037, 0.0069],\n",
            "        [0.0052, 0.9652, 0.0296],\n",
            "        [0.9906, 0.0038, 0.0056],\n",
            "        [0.9884, 0.0055, 0.0061],\n",
            "        [0.0150, 0.0210, 0.9640],\n",
            "        [0.0249, 0.0157, 0.9594]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0048, 0.0486, 0.9466],\n",
            "        [0.9804, 0.0050, 0.0147],\n",
            "        [0.9894, 0.0037, 0.0069],\n",
            "        [0.0052, 0.9652, 0.0296],\n",
            "        [0.9906, 0.0038, 0.0056],\n",
            "        [0.9884, 0.0055, 0.0061],\n",
            "        [0.0150, 0.0210, 0.9640],\n",
            "        [0.0249, 0.0157, 0.9594]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 1, 0, 0, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 2, 0, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 61/63 [00:41<00:01,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9915, 0.0040, 0.0045],\n",
            "        [0.9912, 0.0053, 0.0035],\n",
            "        [0.0050, 0.9914, 0.0036],\n",
            "        [0.0154, 0.0359, 0.9487],\n",
            "        [0.0484, 0.0527, 0.8989],\n",
            "        [0.0465, 0.0115, 0.9419],\n",
            "        [0.5627, 0.2457, 0.1917],\n",
            "        [0.9915, 0.0040, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9915, 0.0040, 0.0045],\n",
            "        [0.9912, 0.0053, 0.0035],\n",
            "        [0.0050, 0.9914, 0.0036],\n",
            "        [0.0154, 0.0359, 0.9487],\n",
            "        [0.0484, 0.0527, 0.8989],\n",
            "        [0.0465, 0.0115, 0.9419],\n",
            "        [0.5627, 0.2457, 0.1917],\n",
            "        [0.9915, 0.0040, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 2, 2, 2, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 2, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 62/63 [00:42<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9894, 0.0029, 0.0077],\n",
            "        [0.0109, 0.9736, 0.0155],\n",
            "        [0.2257, 0.0216, 0.7527],\n",
            "        [0.0185, 0.0056, 0.9759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9894, 0.0029, 0.0077],\n",
            "        [0.0109, 0.9736, 0.0155],\n",
            "        [0.2257, 0.0216, 0.7527],\n",
            "        [0.0185, 0.0056, 0.9759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0110, 0.0234, 0.9656],\n",
            "        [0.0038, 0.9861, 0.0102],\n",
            "        [0.9914, 0.0038, 0.0048],\n",
            "        [0.0215, 0.0352, 0.9433],\n",
            "        [0.9833, 0.0087, 0.0080],\n",
            "        [0.0039, 0.9914, 0.0047],\n",
            "        [0.0160, 0.4640, 0.5200],\n",
            "        [0.9920, 0.0038, 0.0042]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 2, 0, 1, 2, 0], device='cuda:0')\n",
            "tensor([[0.0110, 0.0234, 0.9656],\n",
            "        [0.0038, 0.9861, 0.0102],\n",
            "        [0.9914, 0.0038, 0.0048],\n",
            "        [0.0215, 0.0352, 0.9433],\n",
            "        [0.9833, 0.0087, 0.0080],\n",
            "        [0.0039, 0.9914, 0.0047],\n",
            "        [0.0160, 0.4640, 0.5200],\n",
            "        [0.9920, 0.0038, 0.0042]], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0175, 0.0287, 0.9539],\n",
            "        [0.0115, 0.0155, 0.9730],\n",
            "        [0.0067, 0.9845, 0.0088],\n",
            "        [0.0153, 0.0082, 0.9765],\n",
            "        [0.0155, 0.0182, 0.9663],\n",
            "        [0.0072, 0.9783, 0.0145],\n",
            "        [0.9897, 0.0044, 0.0059],\n",
            "        [0.0248, 0.0154, 0.9598]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "tensor([[0.0175, 0.0287, 0.9539],\n",
            "        [0.0115, 0.0155, 0.9730],\n",
            "        [0.0067, 0.9845, 0.0088],\n",
            "        [0.0153, 0.0082, 0.9765],\n",
            "        [0.0155, 0.0182, 0.9663],\n",
            "        [0.0072, 0.9783, 0.0145],\n",
            "        [0.9897, 0.0044, 0.0059],\n",
            "        [0.0248, 0.0154, 0.9598]], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0046, 0.9779, 0.0175],\n",
            "        [0.9668, 0.0185, 0.0148],\n",
            "        [0.9919, 0.0040, 0.0042],\n",
            "        [0.0307, 0.8991, 0.0701],\n",
            "        [0.0840, 0.0142, 0.9018],\n",
            "        [0.0775, 0.0097, 0.9128],\n",
            "        [0.0099, 0.9798, 0.0103],\n",
            "        [0.9854, 0.0031, 0.0115]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "tensor([[0.0046, 0.9779, 0.0175],\n",
            "        [0.9668, 0.0185, 0.0148],\n",
            "        [0.9919, 0.0040, 0.0042],\n",
            "        [0.0307, 0.8991, 0.0701],\n",
            "        [0.0840, 0.0142, 0.9018],\n",
            "        [0.0775, 0.0097, 0.9128],\n",
            "        [0.0099, 0.9798, 0.0103],\n",
            "        [0.9854, 0.0031, 0.0115]], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0113, 0.9776, 0.0111],\n",
            "        [0.9875, 0.0073, 0.0052],\n",
            "        [0.0080, 0.0656, 0.9263],\n",
            "        [0.0079, 0.0301, 0.9620],\n",
            "        [0.0096, 0.9754, 0.0151],\n",
            "        [0.9903, 0.0047, 0.0049],\n",
            "        [0.0062, 0.0167, 0.9771],\n",
            "        [0.9872, 0.0057, 0.0071]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.0113, 0.9776, 0.0111],\n",
            "        [0.9875, 0.0073, 0.0052],\n",
            "        [0.0080, 0.0656, 0.9263],\n",
            "        [0.0079, 0.0301, 0.9620],\n",
            "        [0.0096, 0.9754, 0.0151],\n",
            "        [0.9903, 0.0047, 0.0049],\n",
            "        [0.0062, 0.0167, 0.9771],\n",
            "        [0.9872, 0.0057, 0.0071]], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0029, 0.9909, 0.0062],\n",
            "        [0.0062, 0.9833, 0.0105],\n",
            "        [0.0886, 0.0246, 0.8868],\n",
            "        [0.9817, 0.0092, 0.0091],\n",
            "        [0.0079, 0.9697, 0.0224],\n",
            "        [0.9795, 0.0108, 0.0097],\n",
            "        [0.0092, 0.0161, 0.9747],\n",
            "        [0.0180, 0.0145, 0.9676]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "tensor([[0.0029, 0.9909, 0.0062],\n",
            "        [0.0062, 0.9833, 0.0105],\n",
            "        [0.0886, 0.0246, 0.8868],\n",
            "        [0.9817, 0.0092, 0.0091],\n",
            "        [0.0079, 0.9697, 0.0224],\n",
            "        [0.9795, 0.0108, 0.0097],\n",
            "        [0.0092, 0.0161, 0.9747],\n",
            "        [0.0180, 0.0145, 0.9676]], device='cuda:0')\n",
            "tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.9700, 0.0147, 0.0154],\n",
            "        [0.0059, 0.9890, 0.0051],\n",
            "        [0.0114, 0.9416, 0.0469],\n",
            "        [0.9912, 0.0050, 0.0038],\n",
            "        [0.9956, 0.0024, 0.0020],\n",
            "        [0.9938, 0.0026, 0.0035],\n",
            "        [0.0075, 0.0083, 0.9843],\n",
            "        [0.0061, 0.9844, 0.0094]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 1, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "tensor([[0.9700, 0.0147, 0.0154],\n",
            "        [0.0059, 0.9890, 0.0051],\n",
            "        [0.0114, 0.9416, 0.0469],\n",
            "        [0.9912, 0.0050, 0.0038],\n",
            "        [0.9956, 0.0024, 0.0020],\n",
            "        [0.9938, 0.0026, 0.0035],\n",
            "        [0.0075, 0.0083, 0.9843],\n",
            "        [0.0061, 0.9844, 0.0094]], device='cuda:0')\n",
            "tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0069, 0.9832, 0.0099],\n",
            "        [0.9800, 0.0080, 0.0120],\n",
            "        [0.0094, 0.0145, 0.9761],\n",
            "        [0.0106, 0.9683, 0.0211],\n",
            "        [0.9814, 0.0082, 0.0104],\n",
            "        [0.0167, 0.0162, 0.9672],\n",
            "        [0.0032, 0.9835, 0.0133],\n",
            "        [0.0377, 0.0953, 0.8671]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "tensor([[0.0069, 0.9832, 0.0099],\n",
            "        [0.9800, 0.0080, 0.0120],\n",
            "        [0.0094, 0.0145, 0.9761],\n",
            "        [0.0106, 0.9683, 0.0211],\n",
            "        [0.9814, 0.0082, 0.0104],\n",
            "        [0.0167, 0.0162, 0.9672],\n",
            "        [0.0032, 0.9835, 0.0133],\n",
            "        [0.0377, 0.0953, 0.8671]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9750, 0.0128, 0.0122],\n",
            "        [0.3243, 0.1089, 0.5668],\n",
            "        [0.5360, 0.2193, 0.2447],\n",
            "        [0.5037, 0.0935, 0.4028],\n",
            "        [0.9227, 0.0321, 0.0451],\n",
            "        [0.4388, 0.3733, 0.1879],\n",
            "        [0.0386, 0.0213, 0.9401],\n",
            "        [0.3288, 0.3022, 0.3690]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 0, 0, 0, 0, 2, 2], device='cuda:0')\n",
            "tensor([[0.9750, 0.0128, 0.0122],\n",
            "        [0.3243, 0.1089, 0.5668],\n",
            "        [0.5360, 0.2193, 0.2447],\n",
            "        [0.5037, 0.0935, 0.4028],\n",
            "        [0.9227, 0.0321, 0.0451],\n",
            "        [0.4388, 0.3733, 0.1879],\n",
            "        [0.0386, 0.0213, 0.9401],\n",
            "        [0.3288, 0.3022, 0.3690]], device='cuda:0')\n",
            "tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0160, 0.0589, 0.9251],\n",
            "        [0.2228, 0.6476, 0.1296],\n",
            "        [0.0074, 0.9792, 0.0134],\n",
            "        [0.6884, 0.1776, 0.1341],\n",
            "        [0.3576, 0.2699, 0.3725],\n",
            "        [0.0051, 0.8965, 0.0984],\n",
            "        [0.6625, 0.1276, 0.2098],\n",
            "        [0.4258, 0.0986, 0.4756]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "tensor([[0.0160, 0.0589, 0.9251],\n",
            "        [0.2228, 0.6476, 0.1296],\n",
            "        [0.0074, 0.9792, 0.0134],\n",
            "        [0.6884, 0.1776, 0.1341],\n",
            "        [0.3576, 0.2699, 0.3725],\n",
            "        [0.0051, 0.8965, 0.0984],\n",
            "        [0.6625, 0.1276, 0.2098],\n",
            "        [0.4258, 0.0986, 0.4756]], device='cuda:0')\n",
            "tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0340, 0.1677, 0.7983],\n",
            "        [0.0097, 0.9683, 0.0221],\n",
            "        [0.9035, 0.0402, 0.0563],\n",
            "        [0.0162, 0.0330, 0.9508],\n",
            "        [0.0461, 0.1956, 0.7584],\n",
            "        [0.9669, 0.0160, 0.0171],\n",
            "        [0.0109, 0.9672, 0.0220],\n",
            "        [0.9876, 0.0059, 0.0066]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 2, 2, 0, 1, 0], device='cuda:0')\n",
            "tensor([[0.0340, 0.1677, 0.7983],\n",
            "        [0.0097, 0.9683, 0.0221],\n",
            "        [0.9035, 0.0402, 0.0563],\n",
            "        [0.0162, 0.0330, 0.9508],\n",
            "        [0.0461, 0.1956, 0.7584],\n",
            "        [0.9669, 0.0160, 0.0171],\n",
            "        [0.0109, 0.9672, 0.0220],\n",
            "        [0.9876, 0.0059, 0.0066]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.0332, 0.0272, 0.9396],\n",
            "        [0.8246, 0.0303, 0.1451],\n",
            "        [0.0482, 0.5006, 0.4512],\n",
            "        [0.9759, 0.0092, 0.0149],\n",
            "        [0.8145, 0.0503, 0.1353],\n",
            "        [0.0110, 0.8954, 0.0936],\n",
            "        [0.0071, 0.0243, 0.9686],\n",
            "        [0.0047, 0.9834, 0.0120]], device='cuda:0')\n",
            "prediction: tensor([2, 0, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "tensor([[0.0332, 0.0272, 0.9396],\n",
            "        [0.8246, 0.0303, 0.1451],\n",
            "        [0.0482, 0.5006, 0.4512],\n",
            "        [0.9759, 0.0092, 0.0149],\n",
            "        [0.8145, 0.0503, 0.1353],\n",
            "        [0.0110, 0.8954, 0.0936],\n",
            "        [0.0071, 0.0243, 0.9686],\n",
            "        [0.0047, 0.9834, 0.0120]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.9847, 0.0070, 0.0083],\n",
            "        [0.0136, 0.0720, 0.9144],\n",
            "        [0.0067, 0.9793, 0.0140],\n",
            "        [0.9829, 0.0098, 0.0074],\n",
            "        [0.0049, 0.9856, 0.0095],\n",
            "        [0.0117, 0.0185, 0.9697],\n",
            "        [0.0088, 0.9573, 0.0339],\n",
            "        [0.0128, 0.0166, 0.9705]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([[0.9847, 0.0070, 0.0083],\n",
            "        [0.0136, 0.0720, 0.9144],\n",
            "        [0.0067, 0.9793, 0.0140],\n",
            "        [0.9829, 0.0098, 0.0074],\n",
            "        [0.0049, 0.9856, 0.0095],\n",
            "        [0.0117, 0.0185, 0.9697],\n",
            "        [0.0088, 0.9573, 0.0339],\n",
            "        [0.0128, 0.0166, 0.9705]], device='cuda:0')\n",
            "tensor([0, 2, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9906, 0.0050, 0.0045],\n",
            "        [0.0121, 0.0255, 0.9624],\n",
            "        [0.0069, 0.0088, 0.9843],\n",
            "        [0.9867, 0.0045, 0.0088]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 2, 0], device='cuda:0')\n",
            "tensor([[0.9906, 0.0050, 0.0045],\n",
            "        [0.0121, 0.0255, 0.9624],\n",
            "        [0.0069, 0.0088, 0.9843],\n",
            "        [0.9867, 0.0045, 0.0088]], device='cuda:0')\n",
            "Epochs: 7 | Train Loss:  0.091             | Train Accuracy:  0.846             | Val Loss:  0.084             | Val Accuracy:  0.930\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0514, 0.0380, 0.9106],\n",
            "        [0.9916, 0.0044, 0.0040],\n",
            "        [0.0109, 0.9771, 0.0120],\n",
            "        [0.0096, 0.9697, 0.0207],\n",
            "        [0.0143, 0.0074, 0.9784],\n",
            "        [0.9911, 0.0046, 0.0043],\n",
            "        [0.9720, 0.0178, 0.0103],\n",
            "        [0.0095, 0.0614, 0.9291]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0514, 0.0380, 0.9106],\n",
            "        [0.9916, 0.0044, 0.0040],\n",
            "        [0.0109, 0.9771, 0.0120],\n",
            "        [0.0096, 0.9697, 0.0207],\n",
            "        [0.0143, 0.0074, 0.9784],\n",
            "        [0.9911, 0.0046, 0.0043],\n",
            "        [0.9720, 0.0178, 0.0103],\n",
            "        [0.0095, 0.0614, 0.9291]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 1, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 1, 2, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/63 [00:00<00:44,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9925, 0.0029, 0.0046],\n",
            "        [0.9793, 0.0085, 0.0123],\n",
            "        [0.9801, 0.0054, 0.0145],\n",
            "        [0.9768, 0.0048, 0.0184],\n",
            "        [0.0042, 0.9729, 0.0229],\n",
            "        [0.2274, 0.0578, 0.7148],\n",
            "        [0.0863, 0.1125, 0.8013],\n",
            "        [0.0364, 0.0207, 0.9429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9925, 0.0029, 0.0046],\n",
            "        [0.9793, 0.0085, 0.0123],\n",
            "        [0.9801, 0.0054, 0.0145],\n",
            "        [0.9768, 0.0048, 0.0184],\n",
            "        [0.0042, 0.9729, 0.0229],\n",
            "        [0.2274, 0.0578, 0.7148],\n",
            "        [0.0863, 0.1125, 0.8013],\n",
            "        [0.0364, 0.0207, 0.9429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 1, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 0, 1, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/63 [00:01<00:41,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0051, 0.0229, 0.9720],\n",
            "        [0.0070, 0.9838, 0.0092],\n",
            "        [0.1385, 0.6969, 0.1646],\n",
            "        [0.9560, 0.0142, 0.0298],\n",
            "        [0.9808, 0.0086, 0.0105],\n",
            "        [0.1950, 0.4671, 0.3378],\n",
            "        [0.8746, 0.0249, 0.1006],\n",
            "        [0.0136, 0.0726, 0.9138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0051, 0.0229, 0.9720],\n",
            "        [0.0070, 0.9838, 0.0092],\n",
            "        [0.1385, 0.6969, 0.1646],\n",
            "        [0.9560, 0.0142, 0.0298],\n",
            "        [0.9808, 0.0086, 0.0105],\n",
            "        [0.1950, 0.4671, 0.3378],\n",
            "        [0.8746, 0.0249, 0.1006],\n",
            "        [0.0136, 0.0726, 0.9138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 0, 0, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 0, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/63 [00:02<00:40,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9783, 0.0082, 0.0134],\n",
            "        [0.0092, 0.7618, 0.2290],\n",
            "        [0.0059, 0.9838, 0.0103],\n",
            "        [0.9644, 0.0099, 0.0257],\n",
            "        [0.9719, 0.0069, 0.0212],\n",
            "        [0.0026, 0.9857, 0.0117],\n",
            "        [0.0092, 0.0069, 0.9839],\n",
            "        [0.0048, 0.9744, 0.0208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9783, 0.0082, 0.0134],\n",
            "        [0.0092, 0.7618, 0.2290],\n",
            "        [0.0059, 0.9838, 0.0103],\n",
            "        [0.9644, 0.0099, 0.0257],\n",
            "        [0.9719, 0.0069, 0.0212],\n",
            "        [0.0026, 0.9857, 0.0117],\n",
            "        [0.0092, 0.0069, 0.9839],\n",
            "        [0.0048, 0.9744, 0.0208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/63 [00:02<00:39,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0073, 0.9627, 0.0300],\n",
            "        [0.0085, 0.9820, 0.0095],\n",
            "        [0.9885, 0.0047, 0.0068],\n",
            "        [0.0068, 0.9713, 0.0219],\n",
            "        [0.0460, 0.0299, 0.9241],\n",
            "        [0.9500, 0.0190, 0.0310],\n",
            "        [0.0107, 0.9788, 0.0105],\n",
            "        [0.9828, 0.0079, 0.0094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0073, 0.9627, 0.0300],\n",
            "        [0.0085, 0.9820, 0.0095],\n",
            "        [0.9885, 0.0047, 0.0068],\n",
            "        [0.0068, 0.9713, 0.0219],\n",
            "        [0.0460, 0.0299, 0.9241],\n",
            "        [0.9500, 0.0190, 0.0310],\n",
            "        [0.0107, 0.9788, 0.0105],\n",
            "        [0.9828, 0.0079, 0.0094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 2, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 2, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/63 [00:03<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0249, 0.0138, 0.9613],\n",
            "        [0.0131, 0.9305, 0.0563],\n",
            "        [0.0137, 0.9730, 0.0133],\n",
            "        [0.9853, 0.0051, 0.0096],\n",
            "        [0.0272, 0.0145, 0.9583],\n",
            "        [0.0073, 0.9867, 0.0060],\n",
            "        [0.0157, 0.0160, 0.9683],\n",
            "        [0.0079, 0.9778, 0.0143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0249, 0.0138, 0.9613],\n",
            "        [0.0131, 0.9305, 0.0563],\n",
            "        [0.0137, 0.9730, 0.0133],\n",
            "        [0.9853, 0.0051, 0.0096],\n",
            "        [0.0272, 0.0145, 0.9583],\n",
            "        [0.0073, 0.9867, 0.0060],\n",
            "        [0.0157, 0.0160, 0.9683],\n",
            "        [0.0079, 0.9778, 0.0143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 1, 0, 2, 1, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 0, 2, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 6/63 [00:04<00:38,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9844, 0.0038, 0.0118],\n",
            "        [0.9878, 0.0069, 0.0054],\n",
            "        [0.9936, 0.0029, 0.0035],\n",
            "        [0.0036, 0.0153, 0.9811],\n",
            "        [0.0068, 0.9753, 0.0179],\n",
            "        [0.0052, 0.9874, 0.0073],\n",
            "        [0.0046, 0.8271, 0.1682],\n",
            "        [0.9792, 0.0077, 0.0131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9844, 0.0038, 0.0118],\n",
            "        [0.9878, 0.0069, 0.0054],\n",
            "        [0.9936, 0.0029, 0.0035],\n",
            "        [0.0036, 0.0153, 0.9811],\n",
            "        [0.0068, 0.9753, 0.0179],\n",
            "        [0.0052, 0.9874, 0.0073],\n",
            "        [0.0046, 0.8271, 0.1682],\n",
            "        [0.9792, 0.0077, 0.0131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 2, 1, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 2, 1, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/63 [00:04<00:37,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0507, 0.0194, 0.9298],\n",
            "        [0.9886, 0.0028, 0.0085],\n",
            "        [0.0022, 0.9828, 0.0150],\n",
            "        [0.0138, 0.0131, 0.9731],\n",
            "        [0.0221, 0.0139, 0.9640],\n",
            "        [0.9844, 0.0044, 0.0112],\n",
            "        [0.0258, 0.1512, 0.8230],\n",
            "        [0.0031, 0.9901, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0507, 0.0194, 0.9298],\n",
            "        [0.9886, 0.0028, 0.0085],\n",
            "        [0.0022, 0.9828, 0.0150],\n",
            "        [0.0138, 0.0131, 0.9731],\n",
            "        [0.0221, 0.0139, 0.9640],\n",
            "        [0.9844, 0.0044, 0.0112],\n",
            "        [0.0258, 0.1512, 0.8230],\n",
            "        [0.0031, 0.9901, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 2, 2, 0, 2, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 2, 2, 0, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/63 [00:05<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9892, 0.0031, 0.0077],\n",
            "        [0.9861, 0.0044, 0.0095],\n",
            "        [0.0183, 0.6146, 0.3671],\n",
            "        [0.5577, 0.0590, 0.3833],\n",
            "        [0.9919, 0.0037, 0.0043],\n",
            "        [0.5560, 0.2756, 0.1684],\n",
            "        [0.9962, 0.0017, 0.0020],\n",
            "        [0.0046, 0.0116, 0.9838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9892, 0.0031, 0.0077],\n",
            "        [0.9861, 0.0044, 0.0095],\n",
            "        [0.0183, 0.6146, 0.3671],\n",
            "        [0.5577, 0.0590, 0.3833],\n",
            "        [0.9919, 0.0037, 0.0043],\n",
            "        [0.5560, 0.2756, 0.1684],\n",
            "        [0.9962, 0.0017, 0.0020],\n",
            "        [0.0046, 0.0116, 0.9838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 0, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 0, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/63 [00:06<00:36,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0088, 0.0301, 0.9611],\n",
            "        [0.0059, 0.9862, 0.0079],\n",
            "        [0.6988, 0.1358, 0.1654],\n",
            "        [0.0128, 0.0496, 0.9376],\n",
            "        [0.0123, 0.0117, 0.9760],\n",
            "        [0.0067, 0.9037, 0.0896],\n",
            "        [0.3954, 0.3589, 0.2457],\n",
            "        [0.0843, 0.8031, 0.1126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0088, 0.0301, 0.9611],\n",
            "        [0.0059, 0.9862, 0.0079],\n",
            "        [0.6988, 0.1358, 0.1654],\n",
            "        [0.0128, 0.0496, 0.9376],\n",
            "        [0.0123, 0.0117, 0.9760],\n",
            "        [0.0067, 0.9037, 0.0896],\n",
            "        [0.3954, 0.3589, 0.2457],\n",
            "        [0.0843, 0.8031, 0.1126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 2, 2, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 2, 2, 1, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/63 [00:06<00:35,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0103, 0.0079, 0.9817],\n",
            "        [0.0098, 0.0088, 0.9814],\n",
            "        [0.0065, 0.9839, 0.0096],\n",
            "        [0.0161, 0.0113, 0.9726],\n",
            "        [0.4216, 0.2034, 0.3750],\n",
            "        [0.0077, 0.9716, 0.0207],\n",
            "        [0.9861, 0.0034, 0.0105],\n",
            "        [0.9914, 0.0044, 0.0043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0103, 0.0079, 0.9817],\n",
            "        [0.0098, 0.0088, 0.9814],\n",
            "        [0.0065, 0.9839, 0.0096],\n",
            "        [0.0161, 0.0113, 0.9726],\n",
            "        [0.4216, 0.2034, 0.3750],\n",
            "        [0.0077, 0.9716, 0.0207],\n",
            "        [0.9861, 0.0034, 0.0105],\n",
            "        [0.9914, 0.0044, 0.0043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 2, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 0, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/63 [00:07<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9865, 0.0070, 0.0066],\n",
            "        [0.0315, 0.5643, 0.4042],\n",
            "        [0.9764, 0.0088, 0.0147],\n",
            "        [0.0047, 0.9125, 0.0828],\n",
            "        [0.0166, 0.0512, 0.9322],\n",
            "        [0.0081, 0.0168, 0.9751],\n",
            "        [0.0410, 0.0447, 0.9143],\n",
            "        [0.0062, 0.0253, 0.9685]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9865, 0.0070, 0.0066],\n",
            "        [0.0315, 0.5643, 0.4042],\n",
            "        [0.9764, 0.0088, 0.0147],\n",
            "        [0.0047, 0.9125, 0.0828],\n",
            "        [0.0166, 0.0512, 0.9322],\n",
            "        [0.0081, 0.0168, 0.9751],\n",
            "        [0.0410, 0.0447, 0.9143],\n",
            "        [0.0062, 0.0253, 0.9685]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 1, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/63 [00:08<00:34,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9765, 0.0071, 0.0164],\n",
            "        [0.0065, 0.9862, 0.0073],\n",
            "        [0.0084, 0.0592, 0.9324],\n",
            "        [0.0056, 0.9742, 0.0202],\n",
            "        [0.0114, 0.0198, 0.9688],\n",
            "        [0.0051, 0.9821, 0.0128],\n",
            "        [0.0036, 0.9609, 0.0355],\n",
            "        [0.0120, 0.9576, 0.0304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9765, 0.0071, 0.0164],\n",
            "        [0.0065, 0.9862, 0.0073],\n",
            "        [0.0084, 0.0592, 0.9324],\n",
            "        [0.0056, 0.9742, 0.0202],\n",
            "        [0.0114, 0.0198, 0.9688],\n",
            "        [0.0051, 0.9821, 0.0128],\n",
            "        [0.0036, 0.9609, 0.0355],\n",
            "        [0.0120, 0.9576, 0.0304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 2, 1, 2, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 1, 2, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 13/63 [00:08<00:33,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0101, 0.0237, 0.9662],\n",
            "        [0.0081, 0.9619, 0.0300],\n",
            "        [0.8510, 0.0776, 0.0714],\n",
            "        [0.0090, 0.0114, 0.9796],\n",
            "        [0.0046, 0.9503, 0.0451],\n",
            "        [0.0057, 0.9853, 0.0090],\n",
            "        [0.0100, 0.9766, 0.0135],\n",
            "        [0.9921, 0.0033, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0101, 0.0237, 0.9662],\n",
            "        [0.0081, 0.9619, 0.0300],\n",
            "        [0.8510, 0.0776, 0.0714],\n",
            "        [0.0090, 0.0114, 0.9796],\n",
            "        [0.0046, 0.9503, 0.0451],\n",
            "        [0.0057, 0.9853, 0.0090],\n",
            "        [0.0100, 0.9766, 0.0135],\n",
            "        [0.9921, 0.0033, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 2, 1, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 2, 1, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/63 [00:09<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9913, 0.0028, 0.0059],\n",
            "        [0.0345, 0.0742, 0.8913],\n",
            "        [0.0050, 0.9774, 0.0176],\n",
            "        [0.0115, 0.0072, 0.9813],\n",
            "        [0.5472, 0.0953, 0.3576],\n",
            "        [0.0051, 0.0187, 0.9762],\n",
            "        [0.9490, 0.0065, 0.0445],\n",
            "        [0.0112, 0.0072, 0.9815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9913, 0.0028, 0.0059],\n",
            "        [0.0345, 0.0742, 0.8913],\n",
            "        [0.0050, 0.9774, 0.0176],\n",
            "        [0.0115, 0.0072, 0.9813],\n",
            "        [0.5472, 0.0953, 0.3576],\n",
            "        [0.0051, 0.0187, 0.9762],\n",
            "        [0.9490, 0.0065, 0.0445],\n",
            "        [0.0112, 0.0072, 0.9815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 1, 2, 0, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 1, 0, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 15/63 [00:10<00:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0074, 0.0224, 0.9703],\n",
            "        [0.0023, 0.9849, 0.0127],\n",
            "        [0.9906, 0.0038, 0.0056],\n",
            "        [0.0093, 0.0125, 0.9782],\n",
            "        [0.3135, 0.3908, 0.2957],\n",
            "        [0.0073, 0.9785, 0.0142],\n",
            "        [0.0019, 0.9860, 0.0122],\n",
            "        [0.0046, 0.9729, 0.0225]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0074, 0.0224, 0.9703],\n",
            "        [0.0023, 0.9849, 0.0127],\n",
            "        [0.9906, 0.0038, 0.0056],\n",
            "        [0.0093, 0.0125, 0.9782],\n",
            "        [0.3135, 0.3908, 0.2957],\n",
            "        [0.0073, 0.9785, 0.0142],\n",
            "        [0.0019, 0.9860, 0.0122],\n",
            "        [0.0046, 0.9729, 0.0225]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 2, 1, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 2, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/63 [00:10<00:31,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.7825, 0.0193, 0.1982],\n",
            "        [0.0034, 0.9898, 0.0068],\n",
            "        [0.0031, 0.9590, 0.0379],\n",
            "        [0.9876, 0.0051, 0.0073],\n",
            "        [0.4842, 0.3182, 0.1977],\n",
            "        [0.0033, 0.9867, 0.0101],\n",
            "        [0.4556, 0.2025, 0.3419],\n",
            "        [0.9777, 0.0076, 0.0147]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.7825, 0.0193, 0.1982],\n",
            "        [0.0034, 0.9898, 0.0068],\n",
            "        [0.0031, 0.9590, 0.0379],\n",
            "        [0.9876, 0.0051, 0.0073],\n",
            "        [0.4842, 0.3182, 0.1977],\n",
            "        [0.0033, 0.9867, 0.0101],\n",
            "        [0.4556, 0.2025, 0.3419],\n",
            "        [0.9777, 0.0076, 0.0147]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/63 [00:11<00:30,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0253, 0.9542, 0.0204],\n",
            "        [0.8919, 0.0161, 0.0919],\n",
            "        [0.9810, 0.0079, 0.0111],\n",
            "        [0.9611, 0.0059, 0.0330],\n",
            "        [0.9570, 0.0073, 0.0357],\n",
            "        [0.0041, 0.8928, 0.1031],\n",
            "        [0.8538, 0.0216, 0.1245],\n",
            "        [0.9576, 0.0060, 0.0365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0253, 0.9542, 0.0204],\n",
            "        [0.8919, 0.0161, 0.0919],\n",
            "        [0.9810, 0.0079, 0.0111],\n",
            "        [0.9611, 0.0059, 0.0330],\n",
            "        [0.9570, 0.0073, 0.0357],\n",
            "        [0.0041, 0.8928, 0.1031],\n",
            "        [0.8538, 0.0216, 0.1245],\n",
            "        [0.9576, 0.0060, 0.0365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 18/63 [00:12<00:30,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0060, 0.0120, 0.9820],\n",
            "        [0.0047, 0.9882, 0.0071],\n",
            "        [0.0100, 0.0239, 0.9661],\n",
            "        [0.2466, 0.5370, 0.2164],\n",
            "        [0.9917, 0.0026, 0.0057],\n",
            "        [0.0096, 0.0231, 0.9673],\n",
            "        [0.9471, 0.0063, 0.0466],\n",
            "        [0.0425, 0.0216, 0.9359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0060, 0.0120, 0.9820],\n",
            "        [0.0047, 0.9882, 0.0071],\n",
            "        [0.0100, 0.0239, 0.9661],\n",
            "        [0.2466, 0.5370, 0.2164],\n",
            "        [0.9917, 0.0026, 0.0057],\n",
            "        [0.0096, 0.0231, 0.9673],\n",
            "        [0.9471, 0.0063, 0.0466],\n",
            "        [0.0425, 0.0216, 0.9359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 2, 1, 0, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 2, 0, 2, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 19/63 [00:12<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9843, 0.0052, 0.0105],\n",
            "        [0.0040, 0.0129, 0.9830],\n",
            "        [0.0058, 0.9892, 0.0049],\n",
            "        [0.0163, 0.0107, 0.9730],\n",
            "        [0.9775, 0.0127, 0.0098],\n",
            "        [0.7405, 0.0240, 0.2355],\n",
            "        [0.9920, 0.0041, 0.0039],\n",
            "        [0.0089, 0.0193, 0.9718]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9843, 0.0052, 0.0105],\n",
            "        [0.0040, 0.0129, 0.9830],\n",
            "        [0.0058, 0.9892, 0.0049],\n",
            "        [0.0163, 0.0107, 0.9730],\n",
            "        [0.9775, 0.0127, 0.0098],\n",
            "        [0.7405, 0.0240, 0.2355],\n",
            "        [0.9920, 0.0041, 0.0039],\n",
            "        [0.0089, 0.0193, 0.9718]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 1, 2, 0, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 2, 0, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 20/63 [00:13<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0562, 0.6229, 0.3209],\n",
            "        [0.0123, 0.0121, 0.9756],\n",
            "        [0.0091, 0.0162, 0.9746],\n",
            "        [0.9930, 0.0035, 0.0034],\n",
            "        [0.0163, 0.9658, 0.0180],\n",
            "        [0.0052, 0.0074, 0.9874],\n",
            "        [0.9262, 0.0127, 0.0611],\n",
            "        [0.2918, 0.2300, 0.4782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0562, 0.6229, 0.3209],\n",
            "        [0.0123, 0.0121, 0.9756],\n",
            "        [0.0091, 0.0162, 0.9746],\n",
            "        [0.9930, 0.0035, 0.0034],\n",
            "        [0.0163, 0.9658, 0.0180],\n",
            "        [0.0052, 0.0074, 0.9874],\n",
            "        [0.9262, 0.0127, 0.0611],\n",
            "        [0.2918, 0.2300, 0.4782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 0, 1, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 0, 1, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/63 [00:14<00:28,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9900, 0.0045, 0.0055],\n",
            "        [0.0073, 0.9779, 0.0149],\n",
            "        [0.9856, 0.0064, 0.0081],\n",
            "        [0.0046, 0.0288, 0.9666],\n",
            "        [0.8921, 0.0568, 0.0512],\n",
            "        [0.0031, 0.9801, 0.0168],\n",
            "        [0.9862, 0.0038, 0.0101],\n",
            "        [0.0051, 0.9856, 0.0093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9900, 0.0045, 0.0055],\n",
            "        [0.0073, 0.9779, 0.0149],\n",
            "        [0.9856, 0.0064, 0.0081],\n",
            "        [0.0046, 0.0288, 0.9666],\n",
            "        [0.8921, 0.0568, 0.0512],\n",
            "        [0.0031, 0.9801, 0.0168],\n",
            "        [0.9862, 0.0038, 0.0101],\n",
            "        [0.0051, 0.9856, 0.0093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 0, 2, 0, 1, 0, 1], device='cuda:0')\n",
            "train labels: tensor([0, 1, 0, 2, 0, 1, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 22/63 [00:14<00:27,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9875, 0.0038, 0.0087],\n",
            "        [0.0295, 0.8485, 0.1221],\n",
            "        [0.0140, 0.9794, 0.0065],\n",
            "        [0.0036, 0.0101, 0.9863],\n",
            "        [0.0054, 0.9849, 0.0096],\n",
            "        [0.0026, 0.9952, 0.0022],\n",
            "        [0.0068, 0.9870, 0.0061],\n",
            "        [0.0055, 0.0115, 0.9830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9875, 0.0038, 0.0087],\n",
            "        [0.0295, 0.8485, 0.1221],\n",
            "        [0.0140, 0.9794, 0.0065],\n",
            "        [0.0036, 0.0101, 0.9863],\n",
            "        [0.0054, 0.9849, 0.0096],\n",
            "        [0.0026, 0.9952, 0.0022],\n",
            "        [0.0068, 0.9870, 0.0061],\n",
            "        [0.0055, 0.0115, 0.9830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 2, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 2, 1, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 23/63 [00:15<00:27,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0052, 0.9068, 0.0880],\n",
            "        [0.2909, 0.1033, 0.6058],\n",
            "        [0.9920, 0.0047, 0.0033],\n",
            "        [0.0198, 0.0830, 0.8972],\n",
            "        [0.0300, 0.0238, 0.9462],\n",
            "        [0.0060, 0.9706, 0.0233],\n",
            "        [0.0216, 0.0131, 0.9653],\n",
            "        [0.0052, 0.0062, 0.9887]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0052, 0.9068, 0.0880],\n",
            "        [0.2909, 0.1033, 0.6058],\n",
            "        [0.9920, 0.0047, 0.0033],\n",
            "        [0.0198, 0.0830, 0.8972],\n",
            "        [0.0300, 0.0238, 0.9462],\n",
            "        [0.0060, 0.9706, 0.0233],\n",
            "        [0.0216, 0.0131, 0.9653],\n",
            "        [0.0052, 0.0062, 0.9887]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 2, 2, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 0, 2, 2, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/63 [00:16<00:26,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9792, 0.0044, 0.0164],\n",
            "        [0.1458, 0.4326, 0.4215],\n",
            "        [0.0051, 0.9897, 0.0052],\n",
            "        [0.9500, 0.0064, 0.0436],\n",
            "        [0.0051, 0.0685, 0.9264],\n",
            "        [0.9906, 0.0051, 0.0044],\n",
            "        [0.4795, 0.1347, 0.3858],\n",
            "        [0.9331, 0.0076, 0.0593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9792, 0.0044, 0.0164],\n",
            "        [0.1458, 0.4326, 0.4215],\n",
            "        [0.0051, 0.9897, 0.0052],\n",
            "        [0.9500, 0.0064, 0.0436],\n",
            "        [0.0051, 0.0685, 0.9264],\n",
            "        [0.9906, 0.0051, 0.0044],\n",
            "        [0.4795, 0.1347, 0.3858],\n",
            "        [0.9331, 0.0076, 0.0593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 0, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 25/63 [00:16<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9901, 0.0033, 0.0066],\n",
            "        [0.0222, 0.0088, 0.9690],\n",
            "        [0.9861, 0.0047, 0.0092],\n",
            "        [0.3141, 0.2436, 0.4423],\n",
            "        [0.0024, 0.0192, 0.9783],\n",
            "        [0.8478, 0.0682, 0.0840],\n",
            "        [0.0063, 0.9823, 0.0114],\n",
            "        [0.0139, 0.0190, 0.9671]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9901, 0.0033, 0.0066],\n",
            "        [0.0222, 0.0088, 0.9690],\n",
            "        [0.9861, 0.0047, 0.0092],\n",
            "        [0.3141, 0.2436, 0.4423],\n",
            "        [0.0024, 0.0192, 0.9783],\n",
            "        [0.8478, 0.0682, 0.0840],\n",
            "        [0.0063, 0.9823, 0.0114],\n",
            "        [0.0139, 0.0190, 0.9671]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 2, 2, 0, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 2, 0, 0, 2, 0, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 26/63 [00:17<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0031, 0.9887, 0.0083],\n",
            "        [0.0070, 0.0149, 0.9780],\n",
            "        [0.0449, 0.6879, 0.2672],\n",
            "        [0.9888, 0.0020, 0.0092],\n",
            "        [0.1817, 0.0488, 0.7695],\n",
            "        [0.9952, 0.0024, 0.0024],\n",
            "        [0.9881, 0.0033, 0.0086],\n",
            "        [0.9893, 0.0067, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0031, 0.9887, 0.0083],\n",
            "        [0.0070, 0.0149, 0.9780],\n",
            "        [0.0449, 0.6879, 0.2672],\n",
            "        [0.9888, 0.0020, 0.0092],\n",
            "        [0.1817, 0.0488, 0.7695],\n",
            "        [0.9952, 0.0024, 0.0024],\n",
            "        [0.9881, 0.0033, 0.0086],\n",
            "        [0.9893, 0.0067, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 0, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 0, 0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 27/63 [00:18<00:24,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0029, 0.9889, 0.0082],\n",
            "        [0.9938, 0.0031, 0.0031],\n",
            "        [0.0104, 0.6047, 0.3848],\n",
            "        [0.9823, 0.0092, 0.0085],\n",
            "        [0.1023, 0.0160, 0.8817],\n",
            "        [0.9830, 0.0042, 0.0128],\n",
            "        [0.9190, 0.0111, 0.0699],\n",
            "        [0.0087, 0.0267, 0.9646]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0029, 0.9889, 0.0082],\n",
            "        [0.9938, 0.0031, 0.0031],\n",
            "        [0.0104, 0.6047, 0.3848],\n",
            "        [0.9823, 0.0092, 0.0085],\n",
            "        [0.1023, 0.0160, 0.8817],\n",
            "        [0.9830, 0.0042, 0.0128],\n",
            "        [0.9190, 0.0111, 0.0699],\n",
            "        [0.0087, 0.0267, 0.9646]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 0, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 0, 1, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/63 [00:18<00:23,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0067, 0.9894, 0.0039],\n",
            "        [0.8773, 0.0128, 0.1099],\n",
            "        [0.0089, 0.9896, 0.0015],\n",
            "        [0.0043, 0.9908, 0.0049],\n",
            "        [0.8786, 0.0813, 0.0402],\n",
            "        [0.9948, 0.0030, 0.0023],\n",
            "        [0.0050, 0.0179, 0.9771],\n",
            "        [0.6329, 0.0203, 0.3468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0067, 0.9894, 0.0039],\n",
            "        [0.8773, 0.0128, 0.1099],\n",
            "        [0.0089, 0.9896, 0.0015],\n",
            "        [0.0043, 0.9908, 0.0049],\n",
            "        [0.8786, 0.0813, 0.0402],\n",
            "        [0.9948, 0.0030, 0.0023],\n",
            "        [0.0050, 0.0179, 0.9771],\n",
            "        [0.6329, 0.0203, 0.3468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 1, 1, 0, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 1, 1, 0, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 29/63 [00:19<00:23,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.3488, 0.0524, 0.5988],\n",
            "        [0.0086, 0.0435, 0.9479],\n",
            "        [0.0070, 0.0197, 0.9733],\n",
            "        [0.9889, 0.0051, 0.0060],\n",
            "        [0.2228, 0.6631, 0.1142],\n",
            "        [0.0040, 0.9149, 0.0812],\n",
            "        [0.0067, 0.0043, 0.9890],\n",
            "        [0.9457, 0.0124, 0.0418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.3488, 0.0524, 0.5988],\n",
            "        [0.0086, 0.0435, 0.9479],\n",
            "        [0.0070, 0.0197, 0.9733],\n",
            "        [0.9889, 0.0051, 0.0060],\n",
            "        [0.2228, 0.6631, 0.1142],\n",
            "        [0.0040, 0.9149, 0.0812],\n",
            "        [0.0067, 0.0043, 0.9890],\n",
            "        [0.9457, 0.0124, 0.0418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 2, 0, 1, 1, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 0, 0, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 30/63 [00:20<00:22,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9942, 0.0025, 0.0033],\n",
            "        [0.9930, 0.0029, 0.0041],\n",
            "        [0.0058, 0.9882, 0.0060],\n",
            "        [0.0027, 0.0417, 0.9556],\n",
            "        [0.9888, 0.0047, 0.0065],\n",
            "        [0.0061, 0.0563, 0.9375],\n",
            "        [0.2962, 0.2922, 0.4116],\n",
            "        [0.0116, 0.9821, 0.0064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9942, 0.0025, 0.0033],\n",
            "        [0.9930, 0.0029, 0.0041],\n",
            "        [0.0058, 0.9882, 0.0060],\n",
            "        [0.0027, 0.0417, 0.9556],\n",
            "        [0.9888, 0.0047, 0.0065],\n",
            "        [0.0061, 0.0563, 0.9375],\n",
            "        [0.2962, 0.2922, 0.4116],\n",
            "        [0.0116, 0.9821, 0.0064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 2, 0, 2, 2, 1], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 2, 0, 2, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 31/63 [00:20<00:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0074, 0.9815, 0.0112],\n",
            "        [0.0111, 0.9788, 0.0101],\n",
            "        [0.0041, 0.9923, 0.0037],\n",
            "        [0.0045, 0.9913, 0.0042],\n",
            "        [0.9929, 0.0024, 0.0047],\n",
            "        [0.9880, 0.0064, 0.0056],\n",
            "        [0.0428, 0.0104, 0.9467],\n",
            "        [0.0663, 0.2589, 0.6748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0074, 0.9815, 0.0112],\n",
            "        [0.0111, 0.9788, 0.0101],\n",
            "        [0.0041, 0.9923, 0.0037],\n",
            "        [0.0045, 0.9913, 0.0042],\n",
            "        [0.9929, 0.0024, 0.0047],\n",
            "        [0.9880, 0.0064, 0.0056],\n",
            "        [0.0428, 0.0104, 0.9467],\n",
            "        [0.0663, 0.2589, 0.6748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 1, 0, 0, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 1, 1, 0, 0, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 32/63 [00:21<00:21,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9819, 0.0035, 0.0146],\n",
            "        [0.9684, 0.0146, 0.0170],\n",
            "        [0.0075, 0.9887, 0.0038],\n",
            "        [0.5466, 0.2348, 0.2186],\n",
            "        [0.0064, 0.9851, 0.0085],\n",
            "        [0.0056, 0.9830, 0.0115],\n",
            "        [0.0033, 0.9767, 0.0200],\n",
            "        [0.0058, 0.0113, 0.9829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9819, 0.0035, 0.0146],\n",
            "        [0.9684, 0.0146, 0.0170],\n",
            "        [0.0075, 0.9887, 0.0038],\n",
            "        [0.5466, 0.2348, 0.2186],\n",
            "        [0.0064, 0.9851, 0.0085],\n",
            "        [0.0056, 0.9830, 0.0115],\n",
            "        [0.0033, 0.9767, 0.0200],\n",
            "        [0.0058, 0.0113, 0.9829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 1, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 1, 1, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/63 [00:22<00:20,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9685, 0.0156, 0.0159],\n",
            "        [0.9770, 0.0106, 0.0124],\n",
            "        [0.0041, 0.0051, 0.9908],\n",
            "        [0.0176, 0.0140, 0.9684],\n",
            "        [0.0247, 0.0253, 0.9500],\n",
            "        [0.5968, 0.1684, 0.2348],\n",
            "        [0.9887, 0.0029, 0.0084],\n",
            "        [0.9846, 0.0092, 0.0062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9685, 0.0156, 0.0159],\n",
            "        [0.9770, 0.0106, 0.0124],\n",
            "        [0.0041, 0.0051, 0.9908],\n",
            "        [0.0176, 0.0140, 0.9684],\n",
            "        [0.0247, 0.0253, 0.9500],\n",
            "        [0.5968, 0.1684, 0.2348],\n",
            "        [0.9887, 0.0029, 0.0084],\n",
            "        [0.9846, 0.0092, 0.0062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 2, 2, 0, 0, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 2, 2, 2, 2, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 34/63 [00:23<00:19,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0098, 0.9765, 0.0137],\n",
            "        [0.0064, 0.9794, 0.0142],\n",
            "        [0.0471, 0.8113, 0.1416],\n",
            "        [0.0086, 0.0263, 0.9651],\n",
            "        [0.0463, 0.0323, 0.9214],\n",
            "        [0.0069, 0.9863, 0.0068],\n",
            "        [0.0337, 0.5491, 0.4172],\n",
            "        [0.9564, 0.0044, 0.0391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0098, 0.9765, 0.0137],\n",
            "        [0.0064, 0.9794, 0.0142],\n",
            "        [0.0471, 0.8113, 0.1416],\n",
            "        [0.0086, 0.0263, 0.9651],\n",
            "        [0.0463, 0.0323, 0.9214],\n",
            "        [0.0069, 0.9863, 0.0068],\n",
            "        [0.0337, 0.5491, 0.4172],\n",
            "        [0.9564, 0.0044, 0.0391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 1, 2, 2, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 2, 2, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 35/63 [00:23<00:19,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0035, 0.0025, 0.9939],\n",
            "        [0.5816, 0.1613, 0.2571],\n",
            "        [0.0116, 0.9746, 0.0139],\n",
            "        [0.0224, 0.0057, 0.9719],\n",
            "        [0.0042, 0.9905, 0.0053],\n",
            "        [0.7624, 0.0056, 0.2319],\n",
            "        [0.0089, 0.6002, 0.3909],\n",
            "        [0.9838, 0.0057, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0035, 0.0025, 0.9939],\n",
            "        [0.5816, 0.1613, 0.2571],\n",
            "        [0.0116, 0.9746, 0.0139],\n",
            "        [0.0224, 0.0057, 0.9719],\n",
            "        [0.0042, 0.9905, 0.0053],\n",
            "        [0.7624, 0.0056, 0.2319],\n",
            "        [0.0089, 0.6002, 0.3909],\n",
            "        [0.9838, 0.0057, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 1, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 36/63 [00:24<00:18,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0053, 0.9918, 0.0028],\n",
            "        [0.0537, 0.0457, 0.9005],\n",
            "        [0.4132, 0.2125, 0.3743],\n",
            "        [0.9924, 0.0012, 0.0064],\n",
            "        [0.0033, 0.9763, 0.0204],\n",
            "        [0.0088, 0.9782, 0.0130],\n",
            "        [0.9152, 0.0310, 0.0538],\n",
            "        [0.9886, 0.0068, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0053, 0.9918, 0.0028],\n",
            "        [0.0537, 0.0457, 0.9005],\n",
            "        [0.4132, 0.2125, 0.3743],\n",
            "        [0.9924, 0.0012, 0.0064],\n",
            "        [0.0033, 0.9763, 0.0204],\n",
            "        [0.0088, 0.9782, 0.0130],\n",
            "        [0.9152, 0.0310, 0.0538],\n",
            "        [0.9886, 0.0068, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 0, 1, 1, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 37/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0036, 0.9943, 0.0021],\n",
            "        [0.0190, 0.0186, 0.9625],\n",
            "        [0.0055, 0.9894, 0.0051],\n",
            "        [0.0072, 0.9807, 0.0121],\n",
            "        [0.9922, 0.0037, 0.0041],\n",
            "        [0.3530, 0.2320, 0.4149],\n",
            "        [0.0390, 0.0081, 0.9529],\n",
            "        [0.0048, 0.1787, 0.8165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0036, 0.9943, 0.0021],\n",
            "        [0.0190, 0.0186, 0.9625],\n",
            "        [0.0055, 0.9894, 0.0051],\n",
            "        [0.0072, 0.9807, 0.0121],\n",
            "        [0.9922, 0.0037, 0.0041],\n",
            "        [0.3530, 0.2320, 0.4149],\n",
            "        [0.0390, 0.0081, 0.9529],\n",
            "        [0.0048, 0.1787, 0.8165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 0, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 1, 0, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 38/63 [00:25<00:17,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0081, 0.9869, 0.0050],\n",
            "        [0.9926, 0.0035, 0.0039],\n",
            "        [0.9924, 0.0040, 0.0036],\n",
            "        [0.9922, 0.0051, 0.0027],\n",
            "        [0.9858, 0.0024, 0.0118],\n",
            "        [0.0170, 0.0083, 0.9747],\n",
            "        [0.0028, 0.9922, 0.0049],\n",
            "        [0.0376, 0.0168, 0.9456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0081, 0.9869, 0.0050],\n",
            "        [0.9926, 0.0035, 0.0039],\n",
            "        [0.9924, 0.0040, 0.0036],\n",
            "        [0.9922, 0.0051, 0.0027],\n",
            "        [0.9858, 0.0024, 0.0118],\n",
            "        [0.0170, 0.0083, 0.9747],\n",
            "        [0.0028, 0.9922, 0.0049],\n",
            "        [0.0376, 0.0168, 0.9456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 0, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 39/63 [00:26<00:16,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0086, 0.9710, 0.0205],\n",
            "        [0.0060, 0.0064, 0.9876],\n",
            "        [0.0041, 0.9916, 0.0042],\n",
            "        [0.0113, 0.9810, 0.0077],\n",
            "        [0.9775, 0.0028, 0.0196],\n",
            "        [0.1289, 0.3817, 0.4893],\n",
            "        [0.2190, 0.0175, 0.7635],\n",
            "        [0.9878, 0.0078, 0.0044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0086, 0.9710, 0.0205],\n",
            "        [0.0060, 0.0064, 0.9876],\n",
            "        [0.0041, 0.9916, 0.0042],\n",
            "        [0.0113, 0.9810, 0.0077],\n",
            "        [0.9775, 0.0028, 0.0196],\n",
            "        [0.1289, 0.3817, 0.4893],\n",
            "        [0.2190, 0.0175, 0.7635],\n",
            "        [0.9878, 0.0078, 0.0044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 1, 1, 0, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 2, 1, 1, 0, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 40/63 [00:27<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0097, 0.0258, 0.9645],\n",
            "        [0.0063, 0.9869, 0.0068],\n",
            "        [0.9822, 0.0119, 0.0059],\n",
            "        [0.0063, 0.9879, 0.0057],\n",
            "        [0.2152, 0.0974, 0.6874],\n",
            "        [0.9910, 0.0030, 0.0060],\n",
            "        [0.9888, 0.0062, 0.0050],\n",
            "        [0.0081, 0.9850, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0097, 0.0258, 0.9645],\n",
            "        [0.0063, 0.9869, 0.0068],\n",
            "        [0.9822, 0.0119, 0.0059],\n",
            "        [0.0063, 0.9879, 0.0057],\n",
            "        [0.2152, 0.0974, 0.6874],\n",
            "        [0.9910, 0.0030, 0.0060],\n",
            "        [0.9888, 0.0062, 0.0050],\n",
            "        [0.0081, 0.9850, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 1, 0, 1, 2, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 1, 2, 1, 2, 0, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 41/63 [00:27<00:15,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0154, 0.0169, 0.9678],\n",
            "        [0.1828, 0.0390, 0.7782],\n",
            "        [0.9943, 0.0041, 0.0017],\n",
            "        [0.2260, 0.4126, 0.3614],\n",
            "        [0.0031, 0.9934, 0.0035],\n",
            "        [0.0040, 0.0076, 0.9885],\n",
            "        [0.0065, 0.9853, 0.0082],\n",
            "        [0.9713, 0.0126, 0.0161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0154, 0.0169, 0.9678],\n",
            "        [0.1828, 0.0390, 0.7782],\n",
            "        [0.9943, 0.0041, 0.0017],\n",
            "        [0.2260, 0.4126, 0.3614],\n",
            "        [0.0031, 0.9934, 0.0035],\n",
            "        [0.0040, 0.0076, 0.9885],\n",
            "        [0.0065, 0.9853, 0.0082],\n",
            "        [0.9713, 0.0126, 0.0161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 0, 1, 1, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 2, 1, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 42/63 [00:28<00:14,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0020, 0.9949, 0.0030],\n",
            "        [0.0170, 0.0580, 0.9250],\n",
            "        [0.0303, 0.0451, 0.9247],\n",
            "        [0.1520, 0.5954, 0.2526],\n",
            "        [0.9842, 0.0098, 0.0059],\n",
            "        [0.0090, 0.9811, 0.0100],\n",
            "        [0.0067, 0.9883, 0.0050],\n",
            "        [0.0045, 0.9811, 0.0144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0020, 0.9949, 0.0030],\n",
            "        [0.0170, 0.0580, 0.9250],\n",
            "        [0.0303, 0.0451, 0.9247],\n",
            "        [0.1520, 0.5954, 0.2526],\n",
            "        [0.9842, 0.0098, 0.0059],\n",
            "        [0.0090, 0.9811, 0.0100],\n",
            "        [0.0067, 0.9883, 0.0050],\n",
            "        [0.0045, 0.9811, 0.0144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 2, 2, 1, 0, 1, 1, 1], device='cuda:0')\n",
            "train labels: tensor([1, 2, 2, 1, 0, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 43/63 [00:29<00:13,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9849, 0.0072, 0.0079],\n",
            "        [0.9943, 0.0035, 0.0022],\n",
            "        [0.0138, 0.2220, 0.7641],\n",
            "        [0.9919, 0.0046, 0.0035],\n",
            "        [0.0269, 0.0121, 0.9610],\n",
            "        [0.9907, 0.0061, 0.0031],\n",
            "        [0.9846, 0.0108, 0.0046],\n",
            "        [0.0094, 0.0155, 0.9751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9849, 0.0072, 0.0079],\n",
            "        [0.9943, 0.0035, 0.0022],\n",
            "        [0.0138, 0.2220, 0.7641],\n",
            "        [0.9919, 0.0046, 0.0035],\n",
            "        [0.0269, 0.0121, 0.9610],\n",
            "        [0.9907, 0.0061, 0.0031],\n",
            "        [0.9846, 0.0108, 0.0046],\n",
            "        [0.0094, 0.0155, 0.9751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 2, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 0, 2, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 44/63 [00:29<00:13,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0171, 0.0145, 0.9684],\n",
            "        [0.9891, 0.0062, 0.0048],\n",
            "        [0.0039, 0.9923, 0.0039],\n",
            "        [0.0101, 0.0224, 0.9674],\n",
            "        [0.0139, 0.0653, 0.9209],\n",
            "        [0.0029, 0.0532, 0.9439],\n",
            "        [0.1261, 0.0372, 0.8366],\n",
            "        [0.0090, 0.0069, 0.9841]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0171, 0.0145, 0.9684],\n",
            "        [0.9891, 0.0062, 0.0048],\n",
            "        [0.0039, 0.9923, 0.0039],\n",
            "        [0.0101, 0.0224, 0.9674],\n",
            "        [0.0139, 0.0653, 0.9209],\n",
            "        [0.0029, 0.0532, 0.9439],\n",
            "        [0.1261, 0.0372, 0.8366],\n",
            "        [0.0090, 0.0069, 0.9841]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 2, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 45/63 [00:30<00:12,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0135, 0.0125, 0.9740],\n",
            "        [0.0119, 0.0448, 0.9433],\n",
            "        [0.0072, 0.9866, 0.0062],\n",
            "        [0.0118, 0.0227, 0.9655],\n",
            "        [0.0144, 0.0656, 0.9199],\n",
            "        [0.0207, 0.0057, 0.9736],\n",
            "        [0.0065, 0.9843, 0.0092],\n",
            "        [0.9953, 0.0035, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0135, 0.0125, 0.9740],\n",
            "        [0.0119, 0.0448, 0.9433],\n",
            "        [0.0072, 0.9866, 0.0062],\n",
            "        [0.0118, 0.0227, 0.9655],\n",
            "        [0.0144, 0.0656, 0.9199],\n",
            "        [0.0207, 0.0057, 0.9736],\n",
            "        [0.0065, 0.9843, 0.0092],\n",
            "        [0.9953, 0.0035, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 2, 1, 2, 2, 2, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 2, 2, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 46/63 [00:31<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9937, 0.0029, 0.0034],\n",
            "        [0.9822, 0.0062, 0.0116],\n",
            "        [0.0201, 0.0149, 0.9651],\n",
            "        [0.8298, 0.0858, 0.0844],\n",
            "        [0.6977, 0.1211, 0.1812],\n",
            "        [0.9921, 0.0054, 0.0026],\n",
            "        [0.9909, 0.0036, 0.0055],\n",
            "        [0.0081, 0.0210, 0.9709]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9937, 0.0029, 0.0034],\n",
            "        [0.9822, 0.0062, 0.0116],\n",
            "        [0.0201, 0.0149, 0.9651],\n",
            "        [0.8298, 0.0858, 0.0844],\n",
            "        [0.6977, 0.1211, 0.1812],\n",
            "        [0.9921, 0.0054, 0.0026],\n",
            "        [0.9909, 0.0036, 0.0055],\n",
            "        [0.0081, 0.0210, 0.9709]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 2, 0, 0, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 2, 2, 2, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 47/63 [00:32<00:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0103, 0.0062, 0.9835],\n",
            "        [0.5212, 0.2701, 0.2087],\n",
            "        [0.9649, 0.0247, 0.0105],\n",
            "        [0.9887, 0.0068, 0.0045],\n",
            "        [0.9923, 0.0047, 0.0030],\n",
            "        [0.0124, 0.9816, 0.0061],\n",
            "        [0.0058, 0.0135, 0.9807],\n",
            "        [0.0074, 0.0152, 0.9774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0103, 0.0062, 0.9835],\n",
            "        [0.5212, 0.2701, 0.2087],\n",
            "        [0.9649, 0.0247, 0.0105],\n",
            "        [0.9887, 0.0068, 0.0045],\n",
            "        [0.9923, 0.0047, 0.0030],\n",
            "        [0.0124, 0.9816, 0.0061],\n",
            "        [0.0058, 0.0135, 0.9807],\n",
            "        [0.0074, 0.0152, 0.9774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 0, 0, 1, 2, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 0, 0, 1, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 48/63 [00:32<00:10,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0051, 0.9926, 0.0022],\n",
            "        [0.9811, 0.0144, 0.0045],\n",
            "        [0.9809, 0.0065, 0.0126],\n",
            "        [0.9948, 0.0035, 0.0017],\n",
            "        [0.0081, 0.9873, 0.0046],\n",
            "        [0.0032, 0.0837, 0.9131],\n",
            "        [0.1230, 0.0642, 0.8128],\n",
            "        [0.9876, 0.0083, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0051, 0.9926, 0.0022],\n",
            "        [0.9811, 0.0144, 0.0045],\n",
            "        [0.9809, 0.0065, 0.0126],\n",
            "        [0.9948, 0.0035, 0.0017],\n",
            "        [0.0081, 0.9873, 0.0046],\n",
            "        [0.0032, 0.0837, 0.9131],\n",
            "        [0.1230, 0.0642, 0.8128],\n",
            "        [0.9876, 0.0083, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 0, 0, 1, 2, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 0, 0, 0, 1, 2, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 49/63 [00:33<00:09,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0084, 0.9861, 0.0055],\n",
            "        [0.9931, 0.0029, 0.0041],\n",
            "        [0.0128, 0.0137, 0.9735],\n",
            "        [0.9929, 0.0034, 0.0037],\n",
            "        [0.0046, 0.0248, 0.9706],\n",
            "        [0.0019, 0.9956, 0.0025],\n",
            "        [0.5733, 0.2468, 0.1799],\n",
            "        [0.0367, 0.0323, 0.9310]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0084, 0.9861, 0.0055],\n",
            "        [0.9931, 0.0029, 0.0041],\n",
            "        [0.0128, 0.0137, 0.9735],\n",
            "        [0.9929, 0.0034, 0.0037],\n",
            "        [0.0046, 0.0248, 0.9706],\n",
            "        [0.0019, 0.9956, 0.0025],\n",
            "        [0.5733, 0.2468, 0.1799],\n",
            "        [0.0367, 0.0323, 0.9310]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 0, 2, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "train labels: tensor([1, 0, 2, 2, 2, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 50/63 [00:34<00:09,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0131, 0.0292, 0.9577],\n",
            "        [0.9807, 0.0111, 0.0082],\n",
            "        [0.0043, 0.0085, 0.9871],\n",
            "        [0.0057, 0.8917, 0.1027],\n",
            "        [0.6284, 0.2266, 0.1451],\n",
            "        [0.0159, 0.9797, 0.0044],\n",
            "        [0.0121, 0.9534, 0.0344],\n",
            "        [0.0277, 0.0775, 0.8949]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0131, 0.0292, 0.9577],\n",
            "        [0.9807, 0.0111, 0.0082],\n",
            "        [0.0043, 0.0085, 0.9871],\n",
            "        [0.0057, 0.8917, 0.1027],\n",
            "        [0.6284, 0.2266, 0.1451],\n",
            "        [0.0159, 0.9797, 0.0044],\n",
            "        [0.0121, 0.9534, 0.0344],\n",
            "        [0.0277, 0.0775, 0.8949]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 1, 0, 1, 1, 2], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 2, 2, 1, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 51/63 [00:34<00:08,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6432, 0.1768, 0.1799],\n",
            "        [0.3669, 0.5239, 0.1093],\n",
            "        [0.0253, 0.9689, 0.0058],\n",
            "        [0.6597, 0.0855, 0.2548],\n",
            "        [0.0054, 0.9915, 0.0031],\n",
            "        [0.9902, 0.0052, 0.0046],\n",
            "        [0.9959, 0.0027, 0.0014],\n",
            "        [0.0171, 0.9762, 0.0067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6432, 0.1768, 0.1799],\n",
            "        [0.3669, 0.5239, 0.1093],\n",
            "        [0.0253, 0.9689, 0.0058],\n",
            "        [0.6597, 0.0855, 0.2548],\n",
            "        [0.0054, 0.9915, 0.0031],\n",
            "        [0.9902, 0.0052, 0.0046],\n",
            "        [0.9959, 0.0027, 0.0014],\n",
            "        [0.0171, 0.9762, 0.0067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 2, 1, 1, 1, 0, 2, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 52/63 [00:35<00:07,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0051, 0.9911, 0.0038],\n",
            "        [0.0159, 0.9759, 0.0081],\n",
            "        [0.9902, 0.0051, 0.0048],\n",
            "        [0.0051, 0.9923, 0.0026],\n",
            "        [0.0114, 0.9766, 0.0120],\n",
            "        [0.9917, 0.0023, 0.0060],\n",
            "        [0.0046, 0.0195, 0.9760],\n",
            "        [0.9947, 0.0028, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0051, 0.9911, 0.0038],\n",
            "        [0.0159, 0.9759, 0.0081],\n",
            "        [0.9902, 0.0051, 0.0048],\n",
            "        [0.0051, 0.9923, 0.0026],\n",
            "        [0.0114, 0.9766, 0.0120],\n",
            "        [0.9917, 0.0023, 0.0060],\n",
            "        [0.0046, 0.0195, 0.9760],\n",
            "        [0.9947, 0.0028, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 1, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 1, 1, 0, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 53/63 [00:36<00:06,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0058, 0.0114, 0.9828],\n",
            "        [0.7648, 0.0437, 0.1915],\n",
            "        [0.0027, 0.9902, 0.0071],\n",
            "        [0.0037, 0.0235, 0.9728],\n",
            "        [0.0077, 0.1758, 0.8165],\n",
            "        [0.9925, 0.0043, 0.0032],\n",
            "        [0.0081, 0.9828, 0.0091],\n",
            "        [0.9298, 0.0214, 0.0488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0058, 0.0114, 0.9828],\n",
            "        [0.7648, 0.0437, 0.1915],\n",
            "        [0.0027, 0.9902, 0.0071],\n",
            "        [0.0037, 0.0235, 0.9728],\n",
            "        [0.0077, 0.1758, 0.8165],\n",
            "        [0.9925, 0.0043, 0.0032],\n",
            "        [0.0081, 0.9828, 0.0091],\n",
            "        [0.9298, 0.0214, 0.0488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 1, 2, 2, 0, 1, 0], device='cuda:0')\n",
            "train labels: tensor([2, 0, 1, 2, 2, 0, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 54/63 [00:36<00:06,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0349, 0.0460, 0.9191],\n",
            "        [0.6443, 0.0075, 0.3482],\n",
            "        [0.9945, 0.0026, 0.0029],\n",
            "        [0.0049, 0.0126, 0.9825],\n",
            "        [0.9859, 0.0078, 0.0063],\n",
            "        [0.9909, 0.0052, 0.0039],\n",
            "        [0.9936, 0.0046, 0.0018],\n",
            "        [0.0096, 0.0643, 0.9261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0349, 0.0460, 0.9191],\n",
            "        [0.6443, 0.0075, 0.3482],\n",
            "        [0.9945, 0.0026, 0.0029],\n",
            "        [0.0049, 0.0126, 0.9825],\n",
            "        [0.9859, 0.0078, 0.0063],\n",
            "        [0.9909, 0.0052, 0.0039],\n",
            "        [0.9936, 0.0046, 0.0018],\n",
            "        [0.0096, 0.0643, 0.9261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 2, 0, 0, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 2, 0, 2, 0, 0, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 55/63 [00:37<00:05,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0422, 0.0089, 0.9489],\n",
            "        [0.9888, 0.0064, 0.0048],\n",
            "        [0.9936, 0.0029, 0.0035],\n",
            "        [0.0059, 0.0134, 0.9806],\n",
            "        [0.9032, 0.0068, 0.0900],\n",
            "        [0.1714, 0.0179, 0.8107],\n",
            "        [0.9796, 0.0109, 0.0094],\n",
            "        [0.0101, 0.9663, 0.0237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0422, 0.0089, 0.9489],\n",
            "        [0.9888, 0.0064, 0.0048],\n",
            "        [0.9936, 0.0029, 0.0035],\n",
            "        [0.0059, 0.0134, 0.9806],\n",
            "        [0.9032, 0.0068, 0.0900],\n",
            "        [0.1714, 0.0179, 0.8107],\n",
            "        [0.9796, 0.0109, 0.0094],\n",
            "        [0.0101, 0.9663, 0.0237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 0, 2, 0, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 0, 2, 2, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 56/63 [00:38<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0116, 0.0091, 0.9793],\n",
            "        [0.9860, 0.0040, 0.0100],\n",
            "        [0.0052, 0.0078, 0.9870],\n",
            "        [0.0093, 0.0187, 0.9720],\n",
            "        [0.6482, 0.1299, 0.2219],\n",
            "        [0.0583, 0.0163, 0.9254],\n",
            "        [0.9640, 0.0172, 0.0187],\n",
            "        [0.0053, 0.9878, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0116, 0.0091, 0.9793],\n",
            "        [0.9860, 0.0040, 0.0100],\n",
            "        [0.0052, 0.0078, 0.9870],\n",
            "        [0.0093, 0.0187, 0.9720],\n",
            "        [0.6482, 0.1299, 0.2219],\n",
            "        [0.0583, 0.0163, 0.9254],\n",
            "        [0.9640, 0.0172, 0.0187],\n",
            "        [0.0053, 0.9878, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([2, 0, 2, 2, 0, 2, 0, 1], device='cuda:0')\n",
            "train labels: tensor([2, 0, 2, 2, 0, 2, 0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 57/63 [00:39<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9928, 0.0046, 0.0027],\n",
            "        [0.5315, 0.1696, 0.2989],\n",
            "        [0.4287, 0.2467, 0.3246],\n",
            "        [0.9918, 0.0045, 0.0037],\n",
            "        [0.0031, 0.9867, 0.0101],\n",
            "        [0.0121, 0.0133, 0.9747],\n",
            "        [0.0025, 0.9939, 0.0036],\n",
            "        [0.0125, 0.1005, 0.8870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9928, 0.0046, 0.0027],\n",
            "        [0.5315, 0.1696, 0.2989],\n",
            "        [0.4287, 0.2467, 0.3246],\n",
            "        [0.9918, 0.0045, 0.0037],\n",
            "        [0.0031, 0.9867, 0.0101],\n",
            "        [0.0121, 0.0133, 0.9747],\n",
            "        [0.0025, 0.9939, 0.0036],\n",
            "        [0.0125, 0.1005, 0.8870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 0, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 0, 0, 1, 2, 1, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 58/63 [00:39<00:03,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.0078, 0.9837, 0.0084],\n",
            "        [0.0039, 0.9926, 0.0035],\n",
            "        [0.9867, 0.0034, 0.0099],\n",
            "        [0.0067, 0.9872, 0.0061],\n",
            "        [0.0369, 0.0310, 0.9321],\n",
            "        [0.0286, 0.0212, 0.9503],\n",
            "        [0.0051, 0.0031, 0.9918],\n",
            "        [0.0081, 0.0257, 0.9662]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.0078, 0.9837, 0.0084],\n",
            "        [0.0039, 0.9926, 0.0035],\n",
            "        [0.9867, 0.0034, 0.0099],\n",
            "        [0.0067, 0.9872, 0.0061],\n",
            "        [0.0369, 0.0310, 0.9321],\n",
            "        [0.0286, 0.0212, 0.9503],\n",
            "        [0.0051, 0.0031, 0.9918],\n",
            "        [0.0081, 0.0257, 0.9662]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([1, 1, 0, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "train labels: tensor([1, 1, 0, 1, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 59/63 [00:40<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6211, 0.1141, 0.2648],\n",
            "        [0.0080, 0.9850, 0.0070],\n",
            "        [0.0055, 0.9878, 0.0067],\n",
            "        [0.5930, 0.2252, 0.1818],\n",
            "        [0.0055, 0.9860, 0.0085],\n",
            "        [0.0043, 0.9939, 0.0018],\n",
            "        [0.0083, 0.9847, 0.0070],\n",
            "        [0.9921, 0.0041, 0.0037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6211, 0.1141, 0.2648],\n",
            "        [0.0080, 0.9850, 0.0070],\n",
            "        [0.0055, 0.9878, 0.0067],\n",
            "        [0.5930, 0.2252, 0.1818],\n",
            "        [0.0055, 0.9860, 0.0085],\n",
            "        [0.0043, 0.9939, 0.0018],\n",
            "        [0.0083, 0.9847, 0.0070],\n",
            "        [0.9921, 0.0041, 0.0037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
            "train labels: tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 60/63 [00:41<00:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9917, 0.0024, 0.0059],\n",
            "        [0.9927, 0.0040, 0.0033],\n",
            "        [0.0092, 0.9809, 0.0099],\n",
            "        [0.9523, 0.0056, 0.0421],\n",
            "        [0.9895, 0.0038, 0.0067],\n",
            "        [0.0080, 0.0169, 0.9751],\n",
            "        [0.0026, 0.9921, 0.0052],\n",
            "        [0.1673, 0.4139, 0.4188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9917, 0.0024, 0.0059],\n",
            "        [0.9927, 0.0040, 0.0033],\n",
            "        [0.0092, 0.9809, 0.0099],\n",
            "        [0.9523, 0.0056, 0.0421],\n",
            "        [0.9895, 0.0038, 0.0067],\n",
            "        [0.0080, 0.0169, 0.9751],\n",
            "        [0.0026, 0.9921, 0.0052],\n",
            "        [0.1673, 0.4139, 0.4188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 0, 1, 0, 0, 2, 1, 2], device='cuda:0')\n",
            "train labels: tensor([0, 0, 1, 0, 0, 2, 1, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 61/63 [00:41<00:01,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.9830, 0.0048, 0.0121],\n",
            "        [0.0114, 0.0089, 0.9797],\n",
            "        [0.0052, 0.2876, 0.7072],\n",
            "        [0.0093, 0.0143, 0.9764],\n",
            "        [0.9770, 0.0017, 0.0212],\n",
            "        [0.5002, 0.2359, 0.2639],\n",
            "        [0.0083, 0.0081, 0.9837],\n",
            "        [0.9791, 0.0036, 0.0173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.9830, 0.0048, 0.0121],\n",
            "        [0.0114, 0.0089, 0.9797],\n",
            "        [0.0052, 0.2876, 0.7072],\n",
            "        [0.0093, 0.0143, 0.9764],\n",
            "        [0.9770, 0.0017, 0.0212],\n",
            "        [0.5002, 0.2359, 0.2639],\n",
            "        [0.0083, 0.0081, 0.9837],\n",
            "        [0.9791, 0.0036, 0.0173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 2, 2, 0, 0, 2, 0], device='cuda:0')\n",
            "train labels: tensor([0, 2, 1, 2, 0, 1, 2, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 62/63 [00:42<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training logits: tensor([[0.6891, 0.1102, 0.2007],\n",
            "        [0.0025, 0.0069, 0.9906],\n",
            "        [0.9652, 0.0182, 0.0166],\n",
            "        [0.0057, 0.0118, 0.9826]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "training outputs\n",
            "tensor([[0.6891, 0.1102, 0.2007],\n",
            "        [0.0025, 0.0069, 0.9906],\n",
            "        [0.9652, 0.0182, 0.0166],\n",
            "        [0.0057, 0.0118, 0.9826]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "prediction: tensor([0, 2, 0, 2], device='cuda:0')\n",
            "train labels: tensor([2, 1, 0, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0069, 0.0083, 0.9849],\n",
            "        [0.0016, 0.9938, 0.0046],\n",
            "        [0.9758, 0.0045, 0.0197],\n",
            "        [0.0063, 0.0056, 0.9881],\n",
            "        [0.9934, 0.0018, 0.0048],\n",
            "        [0.0101, 0.9859, 0.0040],\n",
            "        [0.0081, 0.9878, 0.0041],\n",
            "        [0.9930, 0.0028, 0.0042]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 2, 0, 1, 1, 0], device='cuda:0')\n",
            "tensor([[0.0069, 0.0083, 0.9849],\n",
            "        [0.0016, 0.9938, 0.0046],\n",
            "        [0.9758, 0.0045, 0.0197],\n",
            "        [0.0063, 0.0056, 0.9881],\n",
            "        [0.9934, 0.0018, 0.0048],\n",
            "        [0.0101, 0.9859, 0.0040],\n",
            "        [0.0081, 0.9878, 0.0041],\n",
            "        [0.9930, 0.0028, 0.0042]], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0035, 0.0244, 0.9721],\n",
            "        [0.0144, 0.0318, 0.9538],\n",
            "        [0.0081, 0.9868, 0.0051],\n",
            "        [0.0069, 0.0106, 0.9825],\n",
            "        [0.0062, 0.0158, 0.9780],\n",
            "        [0.0053, 0.9898, 0.0049],\n",
            "        [0.9917, 0.0055, 0.0028],\n",
            "        [0.0059, 0.0140, 0.9801]], device='cuda:0')\n",
            "prediction: tensor([2, 2, 1, 2, 2, 1, 0, 2], device='cuda:0')\n",
            "tensor([[0.0035, 0.0244, 0.9721],\n",
            "        [0.0144, 0.0318, 0.9538],\n",
            "        [0.0081, 0.9868, 0.0051],\n",
            "        [0.0069, 0.0106, 0.9825],\n",
            "        [0.0062, 0.0158, 0.9780],\n",
            "        [0.0053, 0.9898, 0.0049],\n",
            "        [0.9917, 0.0055, 0.0028],\n",
            "        [0.0059, 0.0140, 0.9801]], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0046, 0.9825, 0.0129],\n",
            "        [0.9674, 0.0139, 0.0187],\n",
            "        [0.9957, 0.0023, 0.0020],\n",
            "        [0.0032, 0.9949, 0.0020],\n",
            "        [0.0014, 0.0033, 0.9953],\n",
            "        [0.0071, 0.0029, 0.9901],\n",
            "        [0.0050, 0.9812, 0.0138],\n",
            "        [0.2745, 0.0044, 0.7210]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 0, 1, 2, 2, 1, 2], device='cuda:0')\n",
            "tensor([[0.0046, 0.9825, 0.0129],\n",
            "        [0.9674, 0.0139, 0.0187],\n",
            "        [0.9957, 0.0023, 0.0020],\n",
            "        [0.0032, 0.9949, 0.0020],\n",
            "        [0.0014, 0.0033, 0.9953],\n",
            "        [0.0071, 0.0029, 0.9901],\n",
            "        [0.0050, 0.9812, 0.0138],\n",
            "        [0.2745, 0.0044, 0.7210]], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 1, 0, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0044, 0.9884, 0.0072],\n",
            "        [0.9859, 0.0085, 0.0056],\n",
            "        [0.0054, 0.0093, 0.9853],\n",
            "        [0.0121, 0.0136, 0.9743],\n",
            "        [0.0063, 0.9862, 0.0075],\n",
            "        [0.3171, 0.0100, 0.6729],\n",
            "        [0.0099, 0.0108, 0.9793],\n",
            "        [0.9724, 0.0022, 0.0254]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 2, 1, 2, 2, 0], device='cuda:0')\n",
            "tensor([[0.0044, 0.9884, 0.0072],\n",
            "        [0.9859, 0.0085, 0.0056],\n",
            "        [0.0054, 0.0093, 0.9853],\n",
            "        [0.0121, 0.0136, 0.9743],\n",
            "        [0.0063, 0.9862, 0.0075],\n",
            "        [0.3171, 0.0100, 0.6729],\n",
            "        [0.0099, 0.0108, 0.9793],\n",
            "        [0.9724, 0.0022, 0.0254]], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0044, 0.9923, 0.0033],\n",
            "        [0.0039, 0.9882, 0.0080],\n",
            "        [0.0100, 0.0199, 0.9701],\n",
            "        [0.8983, 0.0062, 0.0955],\n",
            "        [0.0035, 0.9729, 0.0236],\n",
            "        [0.9608, 0.0070, 0.0322],\n",
            "        [0.0097, 0.0116, 0.9787],\n",
            "        [0.0034, 0.0102, 0.9864]], device='cuda:0')\n",
            "prediction: tensor([1, 1, 2, 0, 1, 0, 2, 2], device='cuda:0')\n",
            "tensor([[0.0044, 0.9923, 0.0033],\n",
            "        [0.0039, 0.9882, 0.0080],\n",
            "        [0.0100, 0.0199, 0.9701],\n",
            "        [0.8983, 0.0062, 0.0955],\n",
            "        [0.0035, 0.9729, 0.0236],\n",
            "        [0.9608, 0.0070, 0.0322],\n",
            "        [0.0097, 0.0116, 0.9787],\n",
            "        [0.0034, 0.0102, 0.9864]], device='cuda:0')\n",
            "tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.9941, 0.0029, 0.0029],\n",
            "        [0.0113, 0.9826, 0.0061],\n",
            "        [0.0078, 0.0143, 0.9779],\n",
            "        [0.9869, 0.0021, 0.0110],\n",
            "        [0.9920, 0.0033, 0.0047],\n",
            "        [0.9630, 0.0023, 0.0347],\n",
            "        [0.0102, 0.0273, 0.9624],\n",
            "        [0.0030, 0.9923, 0.0047]], device='cuda:0')\n",
            "prediction: tensor([0, 1, 2, 0, 0, 0, 2, 1], device='cuda:0')\n",
            "tensor([[0.9941, 0.0029, 0.0029],\n",
            "        [0.0113, 0.9826, 0.0061],\n",
            "        [0.0078, 0.0143, 0.9779],\n",
            "        [0.9869, 0.0021, 0.0110],\n",
            "        [0.9920, 0.0033, 0.0047],\n",
            "        [0.9630, 0.0023, 0.0347],\n",
            "        [0.0102, 0.0273, 0.9624],\n",
            "        [0.0030, 0.9923, 0.0047]], device='cuda:0')\n",
            "tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0039, 0.9878, 0.0083],\n",
            "        [0.9882, 0.0046, 0.0071],\n",
            "        [0.0071, 0.0073, 0.9856],\n",
            "        [0.0099, 0.9795, 0.0105],\n",
            "        [0.9678, 0.0051, 0.0271],\n",
            "        [0.0048, 0.0060, 0.9893],\n",
            "        [0.0032, 0.9941, 0.0027],\n",
            "        [0.0039, 0.0080, 0.9881]], device='cuda:0')\n",
            "prediction: tensor([1, 0, 2, 1, 0, 2, 1, 2], device='cuda:0')\n",
            "tensor([[0.0039, 0.9878, 0.0083],\n",
            "        [0.9882, 0.0046, 0.0071],\n",
            "        [0.0071, 0.0073, 0.9856],\n",
            "        [0.0099, 0.9795, 0.0105],\n",
            "        [0.9678, 0.0051, 0.0271],\n",
            "        [0.0048, 0.0060, 0.9893],\n",
            "        [0.0032, 0.9941, 0.0027],\n",
            "        [0.0039, 0.0080, 0.9881]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9939, 0.0035, 0.0026],\n",
            "        [0.1225, 0.1129, 0.7646],\n",
            "        [0.5376, 0.2319, 0.2306],\n",
            "        [0.6885, 0.1057, 0.2058],\n",
            "        [0.9689, 0.0066, 0.0245],\n",
            "        [0.7080, 0.1149, 0.1771],\n",
            "        [0.0204, 0.0415, 0.9381],\n",
            "        [0.7234, 0.0953, 0.1813]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 0, 0, 0, 0, 2, 0], device='cuda:0')\n",
            "tensor([[0.9939, 0.0035, 0.0026],\n",
            "        [0.1225, 0.1129, 0.7646],\n",
            "        [0.5376, 0.2319, 0.2306],\n",
            "        [0.6885, 0.1057, 0.2058],\n",
            "        [0.9689, 0.0066, 0.0245],\n",
            "        [0.7080, 0.1149, 0.1771],\n",
            "        [0.0204, 0.0415, 0.9381],\n",
            "        [0.7234, 0.0953, 0.1813]], device='cuda:0')\n",
            "tensor([2, 1, 1, 0, 2, 1, 0, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.0152, 0.0295, 0.9553],\n",
            "        [0.1591, 0.7354, 0.1055],\n",
            "        [0.0034, 0.9944, 0.0021],\n",
            "        [0.7506, 0.1673, 0.0820],\n",
            "        [0.3137, 0.1686, 0.5177],\n",
            "        [0.0077, 0.8930, 0.0992],\n",
            "        [0.6165, 0.1695, 0.2141],\n",
            "        [0.7478, 0.1168, 0.1354]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 1, 0, 2, 1, 0, 0], device='cuda:0')\n",
            "tensor([[0.0152, 0.0295, 0.9553],\n",
            "        [0.1591, 0.7354, 0.1055],\n",
            "        [0.0034, 0.9944, 0.0021],\n",
            "        [0.7506, 0.1673, 0.0820],\n",
            "        [0.3137, 0.1686, 0.5177],\n",
            "        [0.0077, 0.8930, 0.0992],\n",
            "        [0.6165, 0.1695, 0.2141],\n",
            "        [0.7478, 0.1168, 0.1354]], device='cuda:0')\n",
            "tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.0513, 0.3374, 0.6113],\n",
            "        [0.0044, 0.9820, 0.0136],\n",
            "        [0.9883, 0.0060, 0.0057],\n",
            "        [0.0044, 0.0267, 0.9688],\n",
            "        [0.1567, 0.5365, 0.3068],\n",
            "        [0.9768, 0.0160, 0.0072],\n",
            "        [0.0079, 0.9782, 0.0139],\n",
            "        [0.9867, 0.0047, 0.0086]], device='cuda:0')\n",
            "prediction: tensor([2, 1, 0, 2, 1, 0, 1, 0], device='cuda:0')\n",
            "tensor([[0.0513, 0.3374, 0.6113],\n",
            "        [0.0044, 0.9820, 0.0136],\n",
            "        [0.9883, 0.0060, 0.0057],\n",
            "        [0.0044, 0.0267, 0.9688],\n",
            "        [0.1567, 0.5365, 0.3068],\n",
            "        [0.9768, 0.0160, 0.0072],\n",
            "        [0.0079, 0.9782, 0.0139],\n",
            "        [0.9867, 0.0047, 0.0086]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "validating logits: tensor([[0.0042, 0.0069, 0.9888],\n",
            "        [0.9544, 0.0092, 0.0364],\n",
            "        [0.0635, 0.8425, 0.0940],\n",
            "        [0.9780, 0.0136, 0.0084],\n",
            "        [0.9265, 0.0097, 0.0638],\n",
            "        [0.0175, 0.9706, 0.0119],\n",
            "        [0.0033, 0.0124, 0.9843],\n",
            "        [0.0019, 0.9808, 0.0173]], device='cuda:0')\n",
            "prediction: tensor([2, 0, 1, 0, 0, 1, 2, 1], device='cuda:0')\n",
            "tensor([[0.0042, 0.0069, 0.9888],\n",
            "        [0.9544, 0.0092, 0.0364],\n",
            "        [0.0635, 0.8425, 0.0940],\n",
            "        [0.9780, 0.0136, 0.0084],\n",
            "        [0.9265, 0.0097, 0.0638],\n",
            "        [0.0175, 0.9706, 0.0119],\n",
            "        [0.0033, 0.0124, 0.9843],\n",
            "        [0.0019, 0.9808, 0.0173]], device='cuda:0')\n",
            "tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "validating logits: tensor([[0.9959, 0.0023, 0.0018],\n",
            "        [0.0032, 0.0131, 0.9837],\n",
            "        [0.0048, 0.9904, 0.0048],\n",
            "        [0.6044, 0.0101, 0.3855],\n",
            "        [0.0051, 0.9861, 0.0088],\n",
            "        [0.0058, 0.0300, 0.9642],\n",
            "        [0.0022, 0.9913, 0.0065],\n",
            "        [0.0067, 0.0055, 0.9878]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 1, 0, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([[0.9959, 0.0023, 0.0018],\n",
            "        [0.0032, 0.0131, 0.9837],\n",
            "        [0.0048, 0.9904, 0.0048],\n",
            "        [0.6044, 0.0101, 0.3855],\n",
            "        [0.0051, 0.9861, 0.0088],\n",
            "        [0.0058, 0.0300, 0.9642],\n",
            "        [0.0022, 0.9913, 0.0065],\n",
            "        [0.0067, 0.0055, 0.9878]], device='cuda:0')\n",
            "tensor([0, 2, 2, 0], device='cuda:0')\n",
            "validating logits: tensor([[0.9903, 0.0045, 0.0052],\n",
            "        [0.0062, 0.0050, 0.9888],\n",
            "        [0.0098, 0.0095, 0.9806],\n",
            "        [0.9211, 0.0046, 0.0744]], device='cuda:0')\n",
            "prediction: tensor([0, 2, 2, 0], device='cuda:0')\n",
            "tensor([[0.9903, 0.0045, 0.0052],\n",
            "        [0.0062, 0.0050, 0.9888],\n",
            "        [0.0098, 0.0095, 0.9806],\n",
            "        [0.9211, 0.0046, 0.0744]], device='cuda:0')\n",
            "Epochs: 8 | Train Loss:  0.085             | Train Accuracy:  0.884             | Val Loss:  0.082             | Val Accuracy:  0.940\n",
            "Found a better model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import RobertaTokenizer, RobertaModel, RobertaForSequenceClassification, AdamW, RobertaConfig, RobertaTokenizerFast\n",
        "#from tokenizers import BertWordPieceTokenizer\n",
        "from torch import nn\n",
        "np.random.seed(321)\n",
        "\n",
        "\n",
        "ROOT_PATH = \"/content/cellularlint-codes\"\n",
        "DATA_PATH = os.path.join(ROOT_PATH, \"Data/SNLI\")\n",
        "PRETRAINED_PATH = os.path.join(ROOT_PATH, \"Pretrained Models/roberta_weights/saved/\")\n",
        "SAVE_MODEL_AT = os.path.join(ROOT_PATH, \"saved_models/roberta\")\n",
        "PRETRAINED_TOKENIZER = SAVE_MODEL_AT  # Tokenizer is usually saved in the same model folder\n",
        "MODEL_PATH = None\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_train.csv\"))\n",
        "df_dev = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_dev.csv\"))\n",
        "df_test = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_test.csv\"))\n",
        "\n",
        "df_train = df_train.iloc[:500]\n",
        "df_dev = df_train.copy().iloc[:1000]\n",
        "\n",
        "\n",
        "#tokenizer = BertTokenizerFast.from_pretrained(os.path.join(ROOT_PATH,PRETRAINED_TOKENIZER))\n",
        "#tokenizer = BertTokenizerFast.from_pretrained(os.path.join(ROOT_PATH,PRETRAINED_PATH))\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"FacebookAI/roberta-base\")\n",
        "\n",
        "\n",
        "labels = {'contradiction':1,\n",
        "          'entailment':0,\n",
        "          'neutral':2,\n",
        "          }\n",
        "NUM_LABELS = len(labels)\n",
        "\n",
        "\n",
        "def roberta_encoding(sequence):\n",
        "    return tokenizer.encode(sequence, add_special_tokens = False)\n",
        "def str_to_int_list(data):\n",
        "    return list(map(int, data))\n",
        "\n",
        "\n",
        "df_train['token_type'] = df_train['token_type'].str.split()\n",
        "df_train['token_type'] = df_train['token_type'].apply(str_to_int_list)\n",
        "\n",
        "df_dev['token_type'] = df_dev['token_type'].str.split()\n",
        "df_dev['token_type'] = df_dev['token_type'].apply(str_to_int_list)\n",
        "\n",
        "df_test['token_type'] = df_test['token_type'].str.split()\n",
        "df_test['token_type'] = df_test['token_type'].apply(str_to_int_list)\n",
        "\n",
        "\n",
        "df_train['attention_mask'] = df_train['attention_mask'].str.split()\n",
        "df_train['attention_mask'] = df_train['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].str.split()\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "df_test['attention_mask'] = df_test['attention_mask'].str.split()\n",
        "df_test['attention_mask'] = df_test['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "\n",
        "df_train['input_ids'] = df_train['sequence'].apply(roberta_encoding)\n",
        "df_dev['input_ids'] = df_dev['sequence'].apply(roberta_encoding)\n",
        "df_test['input_ids'] = df_test['sequence'].apply(roberta_encoding)\n",
        "\n",
        "\n",
        "max_length = 512\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = []\n",
        "        self.labels = [labels[label] for label in df['gold_label']]\n",
        "        for _, row in df.iterrows():\n",
        "            token_type_ids = row['token_type']\n",
        "            token_type_ids += [0] * (max_length - len(token_type_ids))\n",
        "            attention_mask = row['attention_mask']\n",
        "            attention_mask += [0] * (max_length - len(attention_mask))\n",
        "            input_ids = tokenizer.encode(\n",
        "                row['sequence'],\n",
        "                add_special_tokens=False,\n",
        "                padding='max_length',\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            datadict = {\n",
        "                'input_ids': input_ids.squeeze(0),\n",
        "                'token_type_ids': torch.tensor(token_type_ids),\n",
        "                'attention_mask': torch.tensor(attention_mask)\n",
        "            }\n",
        "            self.texts.append(datadict)\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_text = self.texts[idx]\n",
        "        batch_y = self.labels[idx]\n",
        "        return batch_text, batch_y\n",
        "\n",
        "\n",
        "class RobertaClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, load_path = None, dropout=0.5):\n",
        "\n",
        "        super(RobertaClassifier, self).__init__()\n",
        "\n",
        "        #self.bert = BertModel.from_pretrained(os.path.join(ROOT_PATH, load_path))\n",
        "        self.roberta = RobertaModel.from_pretrained(load_path)\n",
        "\n",
        "        #self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, NUM_LABELS)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, input_id, mask, token_type_id):\n",
        "        _, pooled_output = self.roberta(input_ids= input_id, attention_mask = mask, return_dict = False)\n",
        "\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "\n",
        "        linear_output = self.linear(dropout_output)\n",
        "\n",
        "        final_layer = self.softmax(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "    def save(self, save_dir, tokenizer, model_name = \"model_roberta.pt\"):\n",
        "\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        # Save model weights\n",
        "        #model_path = os.path.join(save_dir, model_name)\n",
        "        #torch.save(self.state_dict(), model_path)\n",
        "        self.roberta.save_pretrained(save_dir)\n",
        "\n",
        "        # Save tokenizer\n",
        "        tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "        # Save other related information\n",
        "        #config_path = os.path.join(save_dir, \"config.json\")\n",
        "        #self.roberta.config.to_json_file(config_path)\n",
        "\n",
        "    def load(self, load_dir, is_eval = True, model_name = \"model_roberta.pt\"):\n",
        "        # Load tokenizer\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(load_dir)\n",
        "\n",
        "        # Load other related information\n",
        "        config_path = os.path.join(load_dir, \"config.json\")\n",
        "        config = RobertaConfig.from_json_file(config_path)\n",
        "        self.roberta = RobertaModel(config)\n",
        "        if is_eval:\n",
        "            self.roberta.eval()  # Set to evaluation mode\n",
        "\n",
        "        # Load model weights\n",
        "        model_path = os.path.join(load_dir, model_name)\n",
        "        self.load_state_dict(torch.load(model_path))\n",
        "\n",
        "        # Update the tokenizer\n",
        "        self.roberta.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "learning_rates = [1e-5] #[5e-6, 1e-5, 2e-5, 3e-5, 5e-5]\n",
        "batch_sizes = [8] #[16, 24, 32, 40]\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs, batch_size):\n",
        "    #out_file.write(f\"-------------Starting with LR = {learning_rate} and BS = {batch_size}-----------------\\n\")\n",
        "    best_acc_val = -99999\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "                #print(train_input)\n",
        "                train_label = train_label.to(device)\n",
        "\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "                mask = train_input['attention_mask'].squeeze(1).to(device)\n",
        "                token_type_id = train_input['token_type_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask, token_type_id)\n",
        "                #logits = output.logits #For BertForSequenceClassification\n",
        "                logits = output\n",
        "                #print(f'training logits: {logits}')\n",
        "                #print(\"training outputs\")\n",
        "                #print(output)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                batch_loss = criterion(logits, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                #print(f'prediction: {torch.argmax(logits, dim=1)}')\n",
        "                #print(f\"train labels: {train_label}\")\n",
        "                acc = (torch.argmax(logits, dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for val_input, val_label in val_dataloader:\n",
        "\n",
        "                val_label = val_label.to(device)\n",
        "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "                mask = val_input['attention_mask'].squeeze(1).to(device)\n",
        "                token_type_id = val_input['token_type_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask, token_type_id)\n",
        "                #logits = output.logits #For BertForSequenceClassification\n",
        "                logits = output\n",
        "                #print(val_label)\n",
        "                #print(f'validating logits: {logits}')\n",
        "                #print(f'prediction: {torch.argmax(logits, dim=1)}')\n",
        "\n",
        "                batch_loss = criterion(logits, val_label.long())\n",
        "                total_loss_val += batch_loss.item()\n",
        "                #print(output)\n",
        "                acc = (torch.argmax(logits, dim=1) == val_label).sum().item()\n",
        "                total_acc_val += acc\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "            | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "\n",
        "        if(total_acc_val / len(val_data) > best_acc_val):\n",
        "            best_acc_val = total_acc_val / len(val_data)\n",
        "            #model.bert.save_pretrained(os.path.join(ROOT_PATH,\"saved_models/finetune_p1/bert/\"))\n",
        "            #tokenizer.save_pretrained(os.path.join(ROOT_PATH,\"saved_models/finetune_p1/bert/\"))\n",
        "\n",
        "            model.save(save_dir = SAVE_MODEL_AT, tokenizer = tokenizer)\n",
        "            print(\"Found a better model\")\n",
        "\n",
        "EPOCHS = 8\n",
        "for LR in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        #model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = NUM_LABELS)\n",
        "        model = RobertaClassifier(load_path = PRETRAINED_PATH)\n",
        "        train(model, df_train, df_dev, LR, EPOCHS, bs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648,
          "referenced_widgets": [
            "95e877e5a42b4b0ba98bd6c2f6bf0a31",
            "b1de7e2a651343358dbbd3f114381515",
            "71bf7eb726bf4e2fa13d8d63ba79e244",
            "6434a08bee9640e399a4a68522c2b7fe",
            "4e30207e50834cf9b7fc3f96d9683a10",
            "8a2ad9d910d0403f908ae35c32bfe175",
            "a200939d5c03458886a46e308c86c7e6",
            "2bd6f7654a2543d3b444b967702f4215",
            "c6452d4012d94922aaf53f9d413c0464",
            "179c64ded93a42fc9ccbcfd284474d46",
            "23591268f4104357aa1294e5b5012671",
            "31c45fba852e440c8b89981438ee1518",
            "a08254c86a724268839cc352d9de3fa6",
            "1e7c71ca638c4ccca3da85eee6d3087d",
            "9bcff0106b484ddc95eb63beb0c0a127",
            "28cdef20fc8f4e0f9256daea45674633",
            "c045b58b6a17423692d91d3e5dc49262",
            "e2bf57f4b59a4658be7138f03690b2b2",
            "ace726a8f523469e9a31856f93233d50",
            "7dcdbf4546d143dc8fe6a7820b7f6417",
            "608951a98c3b49bf8487e0f7f03fdaed",
            "aa35e752b55c4f31b7d75759f59bdb71",
            "159b7cffbd60428e868beb1308abe5b8",
            "c481e2fc4623483da547539d0e6ed13d",
            "158843fc852d4497bad860b22f5a7f2e",
            "4926114433b44a059e8edff256055fb3",
            "c49427dd561d470d842a0690e1c5c4cf",
            "94ec7bdb718047fd9b41f48d995da09b",
            "5eca492203c24d77aa414994ee3e9de7",
            "1e7acaf165244f3f900bfda06e18c9f1",
            "f69fdaf623a644139a73711b1b40205c",
            "6068515f2eca4fc88f29200dd3dea50a",
            "0e0e3a138e974b9c94cffb80cde67964",
            "174b58551a5c478085d9a76c2eb82415",
            "b02567c75e0946ab82071a470b910591",
            "d0d011bf6ff44ff8b20fb63c7a9e7f64",
            "15ae771f2865463390ccc8250509d375",
            "5568f48d6a0d43a598f0f79020c9a883",
            "62493f9cc738410d83f292db7a299816",
            "6b5af0c792b243ffbe92398e3797b4d1",
            "57fd9f332aec4e579ffad5b9ebc4980d",
            "66db060d1fdc4f24b902a742f38379da",
            "2864c36a54794242a92118954ca50d33",
            "223dd7970d8745c2ba49f4569348cc4e",
            "ff8b61c43e55480984d0cd107501b7da",
            "ee1d75bb1a60492f83dc5530a7ee501d",
            "85620ce9bc2a497e90b8b62ec87daee0",
            "1babd1b2970c44aba33bd8ce1aa25ae8",
            "fbe26941b149479d82c1d9d0c98b07b8",
            "5c90f6d69a2e49ac9c00c86045425a9f",
            "2563baaf46894936ace37632a04172b2",
            "fb1c088e06f343b8a0ee4ebee2d9a881",
            "e82ce0fead6c44f4b7f5306bebbac74f",
            "07707b0803864bed9bbb7ebbc5a4f9fd",
            "83ebf3f0622f44a28a85340b924c51f0"
          ]
        },
        "id": "qNUyc_I-43ed",
        "outputId": "56417405-ff43-4b49-ef2a-90e1b0adbfb2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95e877e5a42b4b0ba98bd6c2f6bf0a31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31c45fba852e440c8b89981438ee1518"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "159b7cffbd60428e868beb1308abe5b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "174b58551a5c478085d9a76c2eb82415"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff8b61c43e55480984d0cd107501b7da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/cellularlint-codes/Pretrained Models/roberta_weights/saved/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.139             | Train Accuracy:  0.330             | Val Loss:  0.138             | Val Accuracy:  0.370\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:41<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.139             | Train Accuracy:  0.312             | Val Loss:  0.138             | Val Accuracy:  0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.139             | Train Accuracy:  0.310             | Val Loss:  0.138             | Val Accuracy:  0.362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.138             | Train Accuracy:  0.350             | Val Loss:  0.138             | Val Accuracy:  0.374\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.138             | Train Accuracy:  0.374             | Val Loss:  0.136             | Val Accuracy:  0.418\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:41<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.137             | Train Accuracy:  0.380             | Val Loss:  0.136             | Val Accuracy:  0.426\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.135             | Train Accuracy:  0.406             | Val Loss:  0.130             | Val Accuracy:  0.510\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.131             | Train Accuracy:  0.490             | Val Loss:  0.119             | Val Accuracy:  0.630\n",
            "Found a better model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification, AdamW, XLNetConfig\n",
        "#from tokenizers import BertWordPieceTokenizer\n",
        "from torch import nn\n",
        "np.random.seed(321)\n",
        "\n",
        "PRETRAINED_PATH = os.path.join(ROOT_PATH, \"Pretrained Models/xlnet_weights/\")\n",
        "SAVE_MODEL_AT = os.path.join(ROOT_PATH, \"saved_models/xlnet\")\n",
        "PRETRAINED_TOKENIZER = SAVE_MODEL_AT  # Tokenizer is usually saved in the same model folder\n",
        "MODEL_PATH = None\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_train.csv\"))\n",
        "df_dev = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_dev.csv\"))\n",
        "df_test = pd.read_csv(os.path.join(DATA_PATH,\"snli_1.0_test.csv\"))\n",
        "\n",
        "df_train = df_train.iloc[:500]\n",
        "df_dev = df_train.copy().iloc[:200]\n",
        "\n",
        "#tokenizer = BertTokenizerFast.from_pretrained(os.path.join(ROOT_PATH,PRETRAINED_TOKENIZER))\n",
        "#tokenizer = BertTokenizerFast.from_pretrained(os.path.join(ROOT_PATH,PRETRAINED_PATH))\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "\n",
        "labels = {'contradiction':1,\n",
        "          'entailment':0,\n",
        "          'neutral':2,\n",
        "          }\n",
        "NUM_LABELS = len(labels)\n",
        "\n",
        "\n",
        "def xlnet_encoding(sequence):\n",
        "    return tokenizer.encode(sequence, add_special_tokens = False)\n",
        "def str_to_int_list(data):\n",
        "    return list(map(int, data))\n",
        "\n",
        "df_train['token_type'] = df_train['token_type'].str.split()\n",
        "df_train['token_type'] = df_train['token_type'].apply(str_to_int_list)\n",
        "\n",
        "df_dev['token_type'] = df_dev['token_type'].str.split()\n",
        "df_dev['token_type'] = df_dev['token_type'].apply(str_to_int_list)\n",
        "\n",
        "df_test['token_type'] = df_test['token_type'].str.split()\n",
        "df_test['token_type'] = df_test['token_type'].apply(str_to_int_list)\n",
        "\n",
        "\n",
        "df_train['attention_mask'] = df_train['attention_mask'].str.split()\n",
        "df_train['attention_mask'] = df_train['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].str.split()\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "df_test['attention_mask'] = df_test['attention_mask'].str.split()\n",
        "df_test['attention_mask'] = df_test['attention_mask'].apply(str_to_int_list)\n",
        "\n",
        "df_train['input_ids'] = df_train['sequence'].apply(xlnet_encoding)\n",
        "df_dev['input_ids'] = df_dev['sequence'].apply(xlnet_encoding)\n",
        "df_test['input_ids'] = df_test['sequence'].apply(xlnet_encoding)\n",
        "\n",
        "max_length = 512\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = []\n",
        "        self.labels = [labels[label] for label in df['gold_label']]\n",
        "        for _, row in df.iterrows():\n",
        "            token_type_ids = row['token_type']\n",
        "            token_type_ids += [0] * (max_length - len(token_type_ids))\n",
        "            attention_mask = row['attention_mask']\n",
        "            attention_mask += [0] * (max_length - len(attention_mask))\n",
        "            input_ids = tokenizer.encode(\n",
        "                row['sequence'],\n",
        "                add_special_tokens=False,\n",
        "                padding='max_length',\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            datadict = {\n",
        "                'input_ids': input_ids.squeeze(0),\n",
        "                'token_type_ids': torch.tensor(token_type_ids),\n",
        "                'attention_mask': torch.tensor(attention_mask)\n",
        "            }\n",
        "            self.texts.append(datadict)\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_text = self.texts[idx]\n",
        "        batch_y = self.labels[idx]\n",
        "        return batch_text, batch_y\n",
        "\n",
        "class XLNetClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, load_path = None, dropout=0.5):\n",
        "\n",
        "        super(XLNetClassifier, self).__init__()\n",
        "\n",
        "        #self.bert = BertModel.from_pretrained(os.path.join(ROOT_PATH, load_path))\n",
        "        self.xlnet = XLNetModel.from_pretrained(load_path)\n",
        "\n",
        "        #self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, NUM_LABELS)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, input_id, mask, token_type_id):\n",
        "        output = self.xlnet(input_ids= input_id, attention_mask = mask, token_type_ids = token_type_id,return_dict = False)\n",
        "        #_, pooled_output = self.xlnet(input_ids= input_id, attention_mask = mask, return_dict = False)\n",
        "\n",
        "        pooled_output = output[0][:,-1,:] #Representation from last token\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "\n",
        "        linear_output = self.linear(dropout_output)\n",
        "\n",
        "        final_layer = self.softmax(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "    def save(self, save_dir, tokenizer, model_name = \"model_xlnet.pt\"):\n",
        "\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        # Save model weights\n",
        "        #model_path = os.path.join(save_dir, model_name)\n",
        "        #torch.save(self.state_dict(), model_path)\n",
        "        self.xlnet.save_pretrained(save_dir)\n",
        "\n",
        "        # Save tokenizer\n",
        "        tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "        # Save other related information\n",
        "        #config_path = os.path.join(save_dir, \"config.json\")\n",
        "        #self.xlnet.config.to_json_file(config_path)\n",
        "\n",
        "    def load(self, load_dir, is_eval = True, model_name = \"model_xlnet.pt\"):\n",
        "        # Load tokenizer\n",
        "        tokenizer = XLNetTokenizer.from_pretrained(load_dir)\n",
        "\n",
        "        # Load other related information\n",
        "        config_path = os.path.join(load_dir, \"config.json\")\n",
        "        config = XLNetConfig.from_json_file(config_path)\n",
        "        self.xlnet = XLNetModel(config)\n",
        "        if is_eval:\n",
        "            self.xlnet.eval()  # Set to evaluation mode\n",
        "\n",
        "        # Load model weights\n",
        "        model_path = os.path.join(load_dir, model_name)\n",
        "        self.load_state_dict(torch.load(model_path))\n",
        "\n",
        "        # Update the tokenizer\n",
        "        self.xlnet.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "from tqdm import tqdm\n",
        "learning_rates = [1e-5] #[5e-6, 1e-5, 2e-5, 3e-5, 5e-5]\n",
        "batch_sizes = [8] #[16, 24, 32, 40]\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs, batch_size):\n",
        "    #out_file.write(f\"-------------Starting with LR = {learning_rate} and BS = {batch_size}-----------------\\n\")\n",
        "    best_acc_val = -99999\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "                #print(train_input)\n",
        "                train_label = train_label.to(device)\n",
        "\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "                mask = train_input['attention_mask'].squeeze(1).to(device)\n",
        "                token_type_id = train_input['token_type_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask, token_type_id)\n",
        "                #logits = output.logits #For BertForSequenceClassification\n",
        "                logits = output\n",
        "                #print(f'training logits: {logits}')\n",
        "                #print(\"training outputs\")\n",
        "                #print(output)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                batch_loss = criterion(logits, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                #print(f'prediction: {torch.argmax(logits, dim=1)}')\n",
        "                #print(f\"train labels: {train_label}\")\n",
        "                acc = (torch.argmax(logits, dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for val_input, val_label in val_dataloader:\n",
        "\n",
        "                val_label = val_label.to(device)\n",
        "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "                mask = val_input['attention_mask'].squeeze(1).to(device)\n",
        "                token_type_id = val_input['token_type_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask, token_type_id)\n",
        "                #logits = output.logits #For BertForSequenceClassification\n",
        "                logits = output\n",
        "                #print(val_label)\n",
        "                #print(f'validating logits: {logits}')\n",
        "                #print(f'prediction: {torch.argmax(logits, dim=1)}')\n",
        "\n",
        "                batch_loss = criterion(logits, val_label.long())\n",
        "                total_loss_val += batch_loss.item()\n",
        "                #print(output)\n",
        "                acc = (torch.argmax(logits, dim=1) == val_label).sum().item()\n",
        "                total_acc_val += acc\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "            | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "\n",
        "        if(total_acc_val / len(val_data) > best_acc_val):\n",
        "            best_acc_val = total_acc_val / len(val_data)\n",
        "            #model.bert.save_pretrained(os.path.join(ROOT_PATH,\"saved_models/finetune_p1/bert/\"))\n",
        "            #tokenizer.save_pretrained(os.path.join(ROOT_PATH,\"saved_models/finetune_p1/bert/\"))\n",
        "\n",
        "            model.save(save_dir = SAVE_MODEL_AT, tokenizer = tokenizer)\n",
        "            print(\"Found a better model\")\n",
        "\n",
        "EPOCHS = 8\n",
        "for LR in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        #model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = NUM_LABELS)\n",
        "        model = XLNetClassifier(load_path = PRETRAINED_PATH)\n",
        "        train(model, df_train, df_dev, LR, EPOCHS, bs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "bd27de7d86b44954bf67aa918a3a54b4",
            "d67196fa291c4c8db6b63a2321df4251",
            "73e12c963ec1446eaee9665bf7752a53",
            "a2600c1cfc9841bb96313dbb1026923d",
            "2512c2ea17d64be7b7f8023a4debbd54",
            "f0f490255594452587eb1066335b816b",
            "e0a53649e685499fb5b497a54dab2324",
            "bf3cc044ba5c4acaae6b03bc1b67a833",
            "59e59ea38a25491f8cca5440b0a59f6c",
            "cb6f20e5b5674ee1bdf47a80729c9ef5",
            "2a4c1c20d80e405a85d91fbf9cf9432a",
            "c74a315647174ca7b98077dead4a996d",
            "c04218a519f2401ba1f8b81593468a7d",
            "45baf3962b2a40e58e3b382ff2bd61ff",
            "60ae75a782564cf09c3526fa2a42ade2",
            "a7515933d2984da8b0afa7db4b88438a",
            "277938db9c0649a0bef8d87d977c5b2b",
            "358eef977aa745ad8e6afeadcf050c6c",
            "8f2317af87f549f384e3a1d933018aca",
            "1377f13fcd424c4cbe3fed3e70be2d2d",
            "2262e44a3f8c4a8787d809864fb6b737",
            "fc083c6a19c049d19cf8216c10ed21ec",
            "ddf40df9ae154fbc96bf84b61e49dc18",
            "862a236e7c9247cbb1668f61fcc3880f",
            "e37cfda91d9844e8a9221fdff92529c8",
            "36b8040cd0254a5e856d09db580be82a",
            "c5d4285ee38645c68d901b4b32935fc3",
            "50043f9a85534a5d8b312203ec7daca8",
            "afd29396911f40cd912b4afec1f348da",
            "80c7cfe5af0149e99c02820afa041311",
            "1a2d4e2142e046eb9020ce1fb50dc900",
            "a069975a826541c69a8d0c7b2d5dd10b",
            "b190aea9884042b59332b394183647ca"
          ]
        },
        "id": "gHmy3IoJ83az",
        "outputId": "be9c4bd1-e997-4f8d-e02f-07a143e5c37a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd27de7d86b44954bf67aa918a3a54b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c74a315647174ca7b98077dead4a996d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddf40df9ae154fbc96bf84b61e49dc18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 63/63 [01:36<00:00,  1.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.149             | Train Accuracy:  0.334             | Val Loss:  0.145             | Val Accuracy:  0.315\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [01:36<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.145             | Train Accuracy:  0.366             | Val Loss:  0.143             | Val Accuracy:  0.335\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [01:35<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.145             | Train Accuracy:  0.344             | Val Loss:  0.141             | Val Accuracy:  0.375\n",
            "Found a better model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [01:36<00:00,  1.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.150             | Train Accuracy:  0.322             | Val Loss:  0.150             | Val Accuracy:  0.320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [01:35<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.150             | Train Accuracy:  0.310             | Val Loss:  0.145             | Val Accuracy:  0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [01:35<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.147             | Train Accuracy:  0.332             | Val Loss:  0.142             | Val Accuracy:  0.330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [01:35<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.147             | Train Accuracy:  0.310             | Val Loss:  0.143             | Val Accuracy:  0.330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [01:35<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.143             | Train Accuracy:  0.364             | Val Loss:  0.143             | Val Accuracy:  0.325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd eval\n",
        "!python3 -W ignore eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryPDsbDIB_tO",
        "outputId": "67db52a8-e648-4c16-8149-7d1739c497eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cellularlint-codes/eval\n",
            "Predictions after majority voting: [1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 2, 0, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1]\n",
            "Metrices successfully calculated. Please check output_metrices.txt file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# Set file paths in Google Drive\n",
        "NET_TYPE = '4G'\n",
        "\n",
        "input_path = f\"/content/cellularlint-codes/Data/Raw_{NET_TYPE}\"  # Update with your Drive folder\n",
        "output_path = f\"/content/cellularlint-codes/Data/Processed_{NET_TYPE}\"\n",
        "\n",
        "# Create output directory if not exists\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "class Preprocessor:\n",
        "    def __init__(self, output_path):\n",
        "        self.output_path = output_path\n",
        "        self.output_file = None\n",
        "        self.line_count = 0\n",
        "        self.file_count = 0\n",
        "        self.nas_end_idx = 0\n",
        "\n",
        "    def find_sections(self, line):\n",
        "        section_header = re.compile(r'\\d(\\.\\d+)+[A-Za-z]*')\n",
        "        return section_header.match(line) is not None\n",
        "\n",
        "    def process_all(self, input_path):\n",
        "        \"\"\"\n",
        "        Processes all .txt files in input_path and saves extracted segments.\n",
        "        \"\"\"\n",
        "        self.file_count = 0\n",
        "        output_file_path = os.path.join(self.output_path, f'conflict_segments_{NET_TYPE}.txt')\n",
        "\n",
        "        if os.path.exists(output_file_path):\n",
        "            with open(output_file_path, 'r', encoding=\"utf-8\") as fp:\n",
        "                self.line_count = len(fp.readlines())\n",
        "\n",
        "        self.output_file = open(output_file_path, 'w', encoding=\"utf-8\")\n",
        "        f_count = 0\n",
        "        extracted_lines = 0\n",
        "\n",
        "        for file in glob.glob(os.path.join(input_path, \"**/*.txt\"), recursive=True):\n",
        "            print(f\"Processing: {os.path.basename(file)}\")\n",
        "            self.process_file(file)\n",
        "\n",
        "            if f_count == 0:\n",
        "                self.output_file.write('---------File Ends-------\\n')\n",
        "            f_count += 1\n",
        "\n",
        "        self.output_file.close()\n",
        "        print(f\"Total extracted lines: {extracted_lines}\")\n",
        "\n",
        "    def process_file(self, file):\n",
        "        \"\"\"\n",
        "        Reads and processes a single file.\n",
        "        \"\"\"\n",
        "        self.file_count += 1\n",
        "        file_line_count = 0\n",
        "        file_section_count = -1\n",
        "\n",
        "        with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            text = f.readlines()\n",
        "            for line in text:\n",
        "                if self.find_sections(line):\n",
        "                    self.output_file.write(\".\\n------\\n\")\n",
        "                    file_section_count += 1\n",
        "                    continue\n",
        "                if len(line.split()) < 4 or \"Editor's Note\" in line:\n",
        "                    continue\n",
        "\n",
        "                line = self.clean_text(line)\n",
        "\n",
        "                if line:\n",
        "                    line_set = line.split('. ')\n",
        "                    for i, sentence in enumerate(line_set):\n",
        "                        self.line_count += 1\n",
        "                        file_line_count += 1\n",
        "                        if i != len(line_set) - 1:\n",
        "                            self.output_file.write(sentence + '.\\n')\n",
        "                        else:\n",
        "                            self.output_file.write(sentence + \" \")\n",
        "\n",
        "            self.output_file.write('\\n')\n",
        "            print(f\"Completed {self.file_count} files. {file_section_count} sections added. {file_line_count} lines processed.\")\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"\n",
        "        Cleans a single line of text.\n",
        "        \"\"\"\n",
        "        text = re.sub(r' +', ' ', text)  # Remove multiple spaces\n",
        "        text = re.sub(r'(\\n)+', '', text)  # Remove extra newlines\n",
        "        text = re.sub(r'^[\\.·\\-]', '', text)  # Remove leading special characters\n",
        "        text = re.sub(r'^ ', '', text)  # Remove leading spaces\n",
        "        text = re.sub(r'[\\.:,;\\-]*$', '', text)  # Remove trailing special characters\n",
        "        text = re.sub(r'(\\( )', '(', text)  # Fix spacing in parentheses\n",
        "        text = re.sub(r'( \\))', ')', text)\n",
        "        text = re.sub(r'(\\(\\))|(\\[\\])|(\\{\\})', '', text)  # Remove empty brackets\n",
        "        text = re.sub(r'(as shown below|[Ss]ee figure below):*\\-*', '', text)  # Remove unnecessary text\n",
        "        text = re.sub(r'([,;:])(\\w)', r'\\1 \\2', text)  # Ensure space after punctuation\n",
        "        text = re.sub(r'\\ue000', '', text, re.UNICODE)  # Remove Unicode artifacts\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    def pair_up(self, file, num_sentences_per_article=3):\n",
        "        \"\"\"\n",
        "        Segments and pairs up text for TF-IDF similarity analysis.\n",
        "        \"\"\"\n",
        "        corpus = []\n",
        "        data_string = \"\"\n",
        "        with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            text = f.readlines()\n",
        "            num_lines = 0\n",
        "            for line in text:\n",
        "                if \"---------File Ends-------\" in line:\n",
        "                    self.nas_end_idx = len(corpus)\n",
        "                    continue\n",
        "                if line in ['.\\n', '.', '\\n', \"------\\n\"]:\n",
        "                    if data_string:\n",
        "                        corpus.append(data_string)\n",
        "                        num_lines = 0\n",
        "                    data_string = \"\"\n",
        "                else:\n",
        "                    data_string += line\n",
        "                    num_lines += 1\n",
        "\n",
        "                if num_lines == num_sentences_per_article or len(data_string.split()) > 50:\n",
        "                    corpus.append(data_string)\n",
        "                    data_string = \"\"\n",
        "                    num_lines = 0\n",
        "            if data_string:\n",
        "                corpus.append(data_string)\n",
        "\n",
        "        print(f\"Processed {len(corpus)} segments.\")\n",
        "\n",
        "        vect = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
        "        tfidf = vect.fit_transform(corpus)\n",
        "        pairwise_similarity = tfidf * tfidf.T\n",
        "\n",
        "        return corpus, pairwise_similarity\n",
        "\n",
        "# ===========================\n",
        "# Run Preprocessing\n",
        "# ===========================\n",
        "\n",
        "dataProcessor = Preprocessor(output_path)\n",
        "dataProcessor.process_all(input_path)\n",
        "print(f\"NAS End Index: {dataProcessor.nas_end_idx}\")\n",
        "\n",
        "# ===========================\n",
        "# Pair Up Sentences for Similarity Analysis\n",
        "# ===========================\n",
        "conflict_file_path = os.path.join(output_path, f\"conflict_segments_{NET_TYPE}.txt\")\n",
        "corpus, pair_sim = dataProcessor.pair_up(conflict_file_path)\n",
        "print(f\"NAS End Index after pairing: {dataProcessor.nas_end_idx}\")\n",
        "\n",
        "# ===========================\n",
        "# Save Processed Corpus\n",
        "# ===========================\n",
        "pickle_file_path = os.path.join(output_path, f\"cp_corpus_{NET_TYPE}.pkl\")\n",
        "with open(pickle_file_path, \"wb\") as fp:\n",
        "   pickle.dump(corpus, fp)\n",
        "\n",
        "print(f\"Processed corpus saved: {pickle_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm1YJSA0XBSH",
        "outputId": "ddc71177-232e-4216-e2e1-31e54085fec4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: Security_4G.txt\n",
            "Completed 1 files. 120 sections added. 6416 lines processed.\n",
            "Processing: NAS_4G.txt\n",
            "Completed 2 files. 890 sections added. 8466 lines processed.\n",
            "Total extracted lines: 0\n",
            "NAS End Index: 0\n",
            "Processed 2596 segments.\n",
            "NAS End Index after pairing: 720\n",
            "Processed corpus saved: /content/cellularlint-codes/Data/Processed_4G/cp_corpus_4G.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "\n",
        "\n",
        "NET_TYPE = '4G'\n",
        "input_path = f\"/content/cellularlint-codes/Data/Processed_4G/cp_corpus_4G.pkl\"\n",
        "\n",
        "# Load the corpus\n",
        "with open(input_path, \"rb\") as fp:\n",
        "    corpus_4G = pickle.load(fp)\n",
        "\n",
        "print(f\"Loaded {len(corpus_5G)} sentences from {input_path}\")\n",
        "\n",
        "\n",
        "TYPE = '4G'\n",
        "SEP_IDX_4G = 720  # Security section boundary\n",
        "SEP_IDX_5G = 1233  # If evaluating 5G corpus\n",
        "\n",
        "if TYPE == '4G':\n",
        "    sentences = corpus_4G\n",
        "    SEP_IDX = SEP_IDX_4G\n",
        "elif TYPE == '5G':\n",
        "    sentences = corpus_5G\n",
        "    SEP_IDX = SEP_IDX_5G\n",
        "else:\n",
        "    raise ValueError(\"Invalid TYPE. Use '4G' or '5G'.\")\n",
        "\n",
        "# ===========================\n",
        "# Step: Compute Doc2Vec Embeddings\n",
        "# ===========================\n",
        "tagged_data = [TaggedDocument(words=sentence.lower().split(), tags=[str(i)]) for i, sentence in enumerate(sentences)]\n",
        "\n",
        "# Train Doc2Vec\n",
        "doc2vec_model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
        "doc2vec_model.build_vocab(tagged_data)\n",
        "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
        "\n",
        "# Get embeddings & similarity matrix\n",
        "doc2vec_embeddings = [doc2vec_model.infer_vector(doc.words) for doc in tagged_data]\n",
        "cosine_sim_matrix_doc2vec = cosine_similarity(doc2vec_embeddings)\n",
        "\n",
        "print(\"Doc2Vec similarity matrix computed.\")\n",
        "\n",
        "# ===========================\n",
        "# Step: Compute SBERT & MPNet Embeddings\n",
        "# ===========================\n",
        "def compute_transformer_embeddings(model_name):\n",
        "    \"\"\"Computes embeddings using a Sentence Transformer model.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Tokenize and embed sentences\n",
        "    tokenized_sentences = [tokenizer.encode(sentence, padding='max_length', truncation=True, max_length=128) for sentence in sentences]\n",
        "    input_ids = torch.tensor(tokenized_sentences, dtype=torch.long).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    batch_size = 32\n",
        "    embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(input_ids), batch_size):\n",
        "            batch_inputs = input_ids[i:i+batch_size]\n",
        "            outputs = model(input_ids=batch_inputs)\n",
        "            batch_embeddings = outputs.last_hidden_state[:, 0].cpu().numpy()\n",
        "            embeddings.append(batch_embeddings)\n",
        "\n",
        "    return np.concatenate(embeddings, axis=0)\n",
        "\n",
        "# Compute embeddings\n",
        "sbert_embeddings = compute_transformer_embeddings(\"sentence-transformers/distilbert-base-nli-stsb-mean-tokens\")\n",
        "cosine_sim_matrix_sbert = cosine_similarity(sbert_embeddings)\n",
        "print(\"SBERT similarity matrix computed.\")\n",
        "\n",
        "mpnet_embeddings = compute_transformer_embeddings(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
        "cosine_sim_matrix_use = cosine_similarity(mpnet_embeddings)\n",
        "print(\"MPNet similarity matrix computed.\")\n",
        "\n",
        "# ===========================\n",
        "# Step: Compute Word2Vec Embeddings\n",
        "# ===========================\n",
        "tokenized_sentences = [sentence.lower().split() for sentence in sentences]\n",
        "\n",
        "# Train Word2Vec\n",
        "word2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
        "\n",
        "# Compute embeddings & similarity\n",
        "word2vec_embeddings = np.array([np.mean([word2vec_model.wv[word] for word in sentence], axis=0) for sentence in tokenized_sentences])\n",
        "cosine_sim_matrix_word2vec = cosine_similarity(word2vec_embeddings)\n",
        "\n",
        "print(\"Word2Vec similarity matrix computed.\")\n",
        "\n",
        "# ===========================\n",
        "# Step: Compute TF-IDF Similarity\n",
        "# ===========================\n",
        "tfidf_vect = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
        "tfidf_matrix = tfidf_vect.fit_transform(sentences)\n",
        "cosine_sim_matrix_tfidf = (tfidf_matrix * tfidf_matrix.T).toarray()\n",
        "\n",
        "print(\"TF-IDF similarity matrix computed.\")\n",
        "\n",
        "# ===========================\n",
        "# Step: Save Results\n",
        "# ===========================\n",
        "output_csv = f\"/content/cellularlint-codes/Data/Processed_{NET_TYPE}/tokenizer_comparison_result_{TYPE}.csv\"\n",
        "df = pd.DataFrame({\n",
        "    \"sbert\": cosine_sim_matrix_sbert.flatten(),\n",
        "    \"doc2vec\": cosine_sim_matrix_doc2vec.flatten(),\n",
        "    \"use\": cosine_sim_matrix_use.flatten(),\n",
        "    \"word2vec\": cosine_sim_matrix_word2vec.flatten(),\n",
        "    \"tfidf\": cosine_sim_matrix_tfidf.flatten()\n",
        "})\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"Tokenizer comparison results saved: {output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgveCt11dGNo",
        "outputId": "7350c5dc-8913-4d08-d8ef-577ec6fba928"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2596 sentences from /content/cellularlint-codes/Data/Processed_4G/cp_corpus_4G.pkl\n",
            "Doc2Vec similarity matrix computed.\n",
            "SBERT similarity matrix computed.\n",
            "MPNet similarity matrix computed.\n",
            "Word2Vec similarity matrix computed.\n",
            "TF-IDF similarity matrix computed.\n",
            "Tokenizer comparison results saved: /content/cellularlint-codes/Data/Processed_4G/tokenizer_comparison_result_4G.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NET_TYPE = '5G'\n",
        "local_output_path = f\"/content/cellularlint-codes/Data/Processed_{NET_TYPE}/\"  # Local output folder\n",
        "drive_output_path = f\"/content/drive/MyDrive/Data/Processed_{NET_TYPE}/\"  # Google Drive folder\n",
        "\n",
        "# Ensure the Drive directory exists\n",
        "os.makedirs(drive_output_path, exist_ok=True)\n",
        "print(f\"Google Drive save location: {drive_output_path}\")\n",
        "\n",
        "def save_to_drive(filename):\n",
        "    local_file = os.path.join(local_output_path, filename)\n",
        "    drive_file = os.path.join(drive_output_path, filename)\n",
        "\n",
        "    if os.path.exists(local_file):\n",
        "        os.system(f'cp \"{local_file}\" \"{drive_file}\"')\n",
        "        print(f\"Saved: {drive_file}\")\n",
        "    else:\n",
        "        print(f\"ERROR: {filename} not found!\")\n",
        "\n",
        "files_to_save = [\n",
        "    f\"conflict_segments_{NET_TYPE}.txt\",\n",
        "    f\"cp_corpus_{NET_TYPE}.pkl\",\n",
        "    f\"tokenizer_comparison_result_{NET_TYPE}.csv\",\n",
        "]\n",
        "\n",
        "\n",
        "for file in files_to_save:\n",
        "    save_to_drive(file)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGJuMAcyfFhv",
        "outputId": "e01a9b70-465a-4b82-b84c-862251532874"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive save location: /content/drive/MyDrive/Data/Processed_5G/\n",
            "Saved: /content/drive/MyDrive/Data/Processed_5G/conflict_segments_5G.txt\n",
            "Saved: /content/drive/MyDrive/Data/Processed_5G/cp_corpus_5G.pkl\n",
            "Saved: /content/drive/MyDrive/Data/Processed_5G/tokenizer_comparison_result_5G.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "from collections import Counter\n",
        "from transformers import BertForSequenceClassification, BertTokenizerFast\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizerFast\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizerFast\n",
        "\n",
        "# ===========================\n",
        "# STEP 1: Setup and Load Trained Models\n",
        "# ===========================\n",
        "\n",
        "# Define model paths\n",
        "from collections import Counter\n",
        "from transformers import BertForSequenceClassification, BertTokenizerFast\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizerFast\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizerFast\n",
        "\n",
        "# ===========================\n",
        "# STEP 1: Load the Trained Models\n",
        "# ===========================\n",
        "\n",
        "# Define model paths (Modify based on your Drive path)\n",
        "BERT_PATH = \"/content/cellularlint-codes/saved_models/finetune_p1/bert\"\n",
        "ROBERTA_PATH = \"/content/cellularlint-codes/saved_models/roberta\"\n",
        "XLNET_PATH = \"/content/cellularlint-codes/saved_models/xlnet\"\n",
        "\n",
        "# Load BERT\n",
        "bert_model = BertForSequenceClassification.from_pretrained(BERT_PATH)\n",
        "bert_tokenizer = BertTokenizerFast.from_pretrained(BERT_PATH)\n",
        "\n",
        "# Load RoBERTa\n",
        "roberta_model = RobertaForSequenceClassification.from_pretrained(ROBERTA_PATH)\n",
        "roberta_tokenizer = RobertaTokenizerFast.from_pretrained(ROBERTA_PATH)\n",
        "\n",
        "# Load XLNet\n",
        "xlnet_model = XLNetForSequenceClassification.from_pretrained(XLNET_PATH)\n",
        "xlnet_tokenizer = XLNetTokenizerFast.from_pretrained(XLNET_PATH)\n",
        "\n",
        "# Move models to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model.to(device)\n",
        "roberta_model.to(device)\n",
        "xlnet_model.to(device)\n",
        "\n",
        "# Set models to evaluation mode\n",
        "bert_model.eval()\n",
        "roberta_model.eval()\n",
        "xlnet_model.eval()\n",
        "\n",
        "# Load models and tokenizers\n",
        "def load_model(model_path, model_class, tokenizer_class):\n",
        "    model = model_class.from_pretrained(model_path).eval()\n",
        "    tokenizer = tokenizer_class.from_pretrained(model_path)\n",
        "    return model, tokenizer\n",
        "\n",
        "print(\"Loading trained models...\")\n",
        "bert_model, bert_tokenizer = load_model(BERT_PATH, BertForSequenceClassification, BertTokenizerFast)\n",
        "roberta_model, roberta_tokenizer = load_model(ROBERTA_PATH, RobertaForSequenceClassification, RobertaTokenizerFast)\n",
        "xlnet_model, xlnet_tokenizer = load_model(XLNET_PATH, XLNetForSequenceClassification, XLNetTokenizerFast)\n",
        "\n",
        "# Move models to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model.to(device)\n",
        "roberta_model.to(device)\n",
        "xlnet_model.to(device)\n",
        "\n",
        "# ===========================\n",
        "# STEP 2: Load `cp_corpus_4G.pkl`\n",
        "# ===========================\n",
        "\n",
        "PICKLE_FILE = \"/content/cellularlint-codes/Data/Processed_4G/cp_corpus_4G.pkl\"\n",
        "\n",
        "# Load the processed corpus from pickle\n",
        "with open(PICKLE_FILE, \"rb\") as f:\n",
        "    corpus_4G = pickle.load(f)\n",
        "\n",
        "print(f\"Loaded {len(corpus_4G)} sentences from cp_corpus_4G.pkl\")\n",
        "\n",
        "# ===========================\n",
        "# STEP 3: Batch Prediction Function\n",
        "# ===========================\n",
        "\n",
        "def batch_predict(texts, model, tokenizer, batch_size=8):\n",
        "    \"\"\"\n",
        "    Predicts batch labels using a trained model.\n",
        "    Prevents OOM by using a smaller batch size.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i : i + batch_size]\n",
        "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            preds = torch.argmax(outputs.logits, dim=1).tolist()\n",
        "\n",
        "        predictions.extend(preds)\n",
        "        torch.cuda.empty_cache()  #Clear unused GPU memory\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Define class labels\n",
        "LABEL_MAP = {0: \"Consistent\", 1: \"Inconsistent\", 2: \"Neutral\"}  # Adjust if needed\n",
        "\n",
        "# ===========================\n",
        "# STEP 4: Perform Predictions and Apply Majority Voting\n",
        "# ===========================\n",
        "\n",
        "print(\"\\nRunning Majority Voting on cp_corpus_4G.pkl...\")\n",
        "\n",
        "#Reduce batch size to avoid OOM\n",
        "# Get predictions in batch mode\n",
        "bert_preds = batch_predict(corpus_4G, bert_model, bert_tokenizer)\n",
        "roberta_preds = batch_predict(corpus_4G, roberta_model, roberta_tokenizer)\n",
        "xlnet_preds = batch_predict(corpus_4G, xlnet_model, xlnet_tokenizer)\n",
        "\n",
        "# Convert numeric predictions to labels\n",
        "bert_preds = [LABEL_MAP[p] for p in bert_preds]\n",
        "roberta_preds = [LABEL_MAP[p] for p in roberta_preds]\n",
        "xlnet_preds = [LABEL_MAP[p] for p in xlnet_preds]\n",
        "\n",
        "# Majority voting function (Fix for randomness)\n",
        "def majority_vote(list1, list2, list3):\n",
        "    majority_list = []\n",
        "    for a, b, c in zip(list1, list2, list3):\n",
        "        vote_count = Counter([a, b, c])\n",
        "        if vote_count.most_common(1)[0][1] == 1:  # If all predictions are different, choose randomly\n",
        "            majority_element = random.choice([a, b, c])\n",
        "        else:\n",
        "            majority_element = vote_count.most_common(1)[0][0]  # Most frequent label\n",
        "        majority_list.append(majority_element)\n",
        "    return majority_list\n",
        "\n",
        "# Perform majority voting\n",
        "final_predictions = majority_vote(bert_preds, roberta_preds, xlnet_preds)\n",
        "\n",
        "# Store results in a DataFrame\n",
        "df_results = pd.DataFrame({\n",
        "    \"Text\": corpus_5G,\n",
        "    \"BERT Prediction\": bert_preds,\n",
        "    \"RoBERTa Prediction\": roberta_preds,\n",
        "    \"XLNet Prediction\": xlnet_preds,\n",
        "    \"Final Prediction\": final_predictions\n",
        "})\n",
        "\n",
        "print(\"Majority voting completed!\")\n",
        "# ===========================\n",
        "# STEP 5: Save Results to CSV\n",
        "# ===========================\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/majority_voting_cp_corpus_4G.csv\"\n",
        "df_results.to_csv(SAVE_PATH, index=False)\n",
        "\n",
        "print(f\"Majority voting results saved to: {SAVE_PATH}\")\n",
        "\n",
        "# ===========================\n",
        "# STEP 6: Display Sample Predictions\n",
        "# ===========================\n",
        "print(\"\\nSample Predictions:\")\n",
        "print(df_results.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hBXKjL3H1oj",
        "outputId": "6c88ebe6-c1e5-4ad5-aa1c-62a23e3fd239"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/cellularlint-codes/saved_models/finetune_p1/bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /content/cellularlint-codes/saved_models/roberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at /content/cellularlint-codes/saved_models/xlnet and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading trained models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/cellularlint-codes/saved_models/finetune_p1/bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /content/cellularlint-codes/saved_models/roberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at /content/cellularlint-codes/saved_models/xlnet and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2596 sentences from cp_corpus_4G.pkl\n",
            "\n",
            "Running Majority Voting on cp_corpus_4G.pkl...\n",
            "Majority voting completed!\n",
            "Majority voting results saved to: /content/drive/MyDrive/majority_voting_cp_corpus_4G.csv\n",
            "\n",
            "Sample Predictions:\n",
            "                                                Text BERT Prediction  \\\n",
            "0  4 Overview of Security Architecture Five secur...    Inconsistent   \n",
            "1  They combine the functionalities of ME and AN ...      Consistent   \n",
            "2  The statements relating to eNBs in clause 5.1 ...      Consistent   \n",
            "3  User identity confidentiality is as defined by...      Consistent   \n",
            "4  When NAS confidentiality protection is beyond ...      Consistent   \n",
            "5  Entity authentication is as defined by TS 33.1...      Consistent   \n",
            "6  Ciphering may be provided to RRC-signalling to...    Inconsistent   \n",
            "7  NAS signalling confidentiality is an operator ...      Consistent   \n",
            "8  This shall be accomplished by the network by s...    Inconsistent   \n",
            "9  All algorithms specified in this clause are al...    Inconsistent   \n",
            "\n",
            "  RoBERTa Prediction XLNet Prediction Final Prediction  \n",
            "0         Consistent       Consistent       Consistent  \n",
            "1       Inconsistent       Consistent       Consistent  \n",
            "2       Inconsistent       Consistent       Consistent  \n",
            "3       Inconsistent       Consistent       Consistent  \n",
            "4       Inconsistent       Consistent       Consistent  \n",
            "5       Inconsistent       Consistent       Consistent  \n",
            "6       Inconsistent       Consistent     Inconsistent  \n",
            "7       Inconsistent       Consistent       Consistent  \n",
            "8       Inconsistent       Consistent     Inconsistent  \n",
            "9       Inconsistent       Consistent     Inconsistent  \n"
          ]
        }
      ]
    }
  ]
}