# -*- coding: utf-8 -*-
"""Spec-to-CVE Matches.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EQfjoGxgdFW_W8dOBCfhgCSh5K_jJBG_
"""

# ============================================================
# Matching 3GPP Spec Inconsistencies to CVEs
# ============================================================

# Install required packages
!pip install -q sentence-transformers

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util
import torch


# Upload and load files
conflict_path = "/content/conflict_segments_gpt_enhanced.xlsx"
cve_path = "/content/cve_dataset_with_inferred_symptoms.csv"

conflict_df = pd.read_excel(conflict_path)
cve_df = pd.read_csv(cve_path)


# For spec conflicts: concatenate conflict_explanation + effect_gpt
conflict_texts = (
    conflict_df['conflict_explanation'].fillna('') + ". Effect: " + conflict_df['effect_gpt'].fillna('')
).tolist()

# For CVEs: concatenate description + inferred symptoms
cve_texts = (
    cve_df['detailed_description'].fillna('') + ". Symptoms: " + cve_df['inferred_user_symptoms'].fillna('')
).tolist()


# Load sentence transformer model
model = SentenceTransformer('all-mpnet-base-v2')

# Compute embeddings
conflict_embeddings = model.encode(conflict_texts, convert_to_tensor=True, batch_size=32)
cve_embeddings = model.encode(cve_texts, convert_to_tensor=True, batch_size=32)


# For each spec conflict, find the top matching CVEs
results = []

for idx, conflict_emb in enumerate(conflict_embeddings):
    # Compute similarity to all CVEs
    similarities = util.cos_sim(conflict_emb, cve_embeddings)[0]

    # Get top-k matches
    top_k = torch.topk(similarities, k=5)

    for score, cve_idx in zip(top_k.values, top_k.indices):
      cve_idx = int(cve_idx)
      result = {
        'conflict_id': conflict_df.iloc[idx]['conflict_id'],
        'cve_id': cve_df.iloc[cve_idx]['cve_id'],
        'similarity_score': score.item(),
        'conflict_explanation': conflict_df.iloc[idx]['conflict_explanation'],
        'cve_description': cve_df.iloc[cve_idx]['detailed_description'],
        'conflict_effect': conflict_df.iloc[idx]['effect_gpt'],
        'cve_effect': cve_df.iloc[cve_idx]['inferred_user_symptoms']
    }
    results.append(result)



matches_df = pd.DataFrame(results)
output_path = "/content/spec_to_cve_matches.csv"
matches_df.to_csv(output_path, index=False)

print(f"Matching complete. Results saved to {output_path}")

# Display preview
matches_df.head(10)

import matplotlib.pyplot as plt

# Plot histogram of similarity scores
plt.figure(figsize=(8,5))
plt.hist(matches_df['similarity_score'], bins=20, color='skyblue', edgecolor='black')
plt.title('Similarity Score Distribution (Spec Conflicts to CVEs)')
plt.xlabel('Cosine Similarity Score')
plt.ylabel('Number of Matches')
plt.grid(True)
plt.show()

# ============================================================
# Filter, Select Top-1, and Save Cleaned Spec-to-CVE Matches
# ============================================================

import pandas as pd

# Load the raw matching results
data_path = "/content/spec_to_cve_matches.csv"  # adjust path if needed
matches_df = pd.read_csv(data_path)


# Set a threshold
SIMILARITY_THRESHOLD = 0.5

# Filter matches
filtered_df = matches_df[matches_df['similarity_score'] >= SIMILARITY_THRESHOLD]
print(f"Remaining matches after filtering: {len(filtered_df)}")


# Sort by conflict_id and similarity_score descending
filtered_df = filtered_df.sort_values(by=["conflict_id", "similarity_score"], ascending=[True, False])

# Pick top-1 per conflict_id
top1_df = filtered_df.groupby("conflict_id").head(1).reset_index(drop=True)

print(f"Number of unique spec conflicts matched: {top1_df['conflict_id'].nunique()}")


output_path = "/content/spec_to_cve_matches_top1_filtered.csv"
top1_df.to_csv(output_path, index=False)

print(f"Cleaned Top-1 matches saved to {output_path}")

top1_df.head(10)

import matplotlib.pyplot as plt

# Plot histogram of similarity scores
plt.figure(figsize=(8,5))
plt.hist(top1_df['similarity_score'], bins=20, color='skyblue', edgecolor='black')
plt.title('Similarity Score Distribution (Spec Conflicts to CVEs)')
plt.xlabel('Cosine Similarity Score')
plt.ylabel('Number of Matches')
plt.grid(True)
plt.show()

# Matching statistics
num_conflicts = top1_df['conflict_id'].nunique()
avg_similarity = top1_df['similarity_score'].mean()
std_similarity = top1_df['similarity_score'].std()

print(f"Matched {num_conflicts} specification conflicts to CVEs.")
print(f"Average similarity score: {avg_similarity:.4f} (Std: {std_similarity:.4f})")

# ============================================================
# LLM-Assisted Validation of Spec-to-CVE Matches
# ============================================================

!pip install -q openai
import pandas as pd
import openai
import time

# Set your OpenAI API key
openai.api_key = "XXXXX"  # Replace with your actual key

# Load Top-1 filtered matches
data_path = "/content/spec_to_cve_matches_top1_filtered.csv"
matches_df = pd.read_csv(data_path)

# ---------------------- Define GPT Prompt Function ----------------------

def build_validation_prompt(row):
    return f"""
You are a cellular security analyst.

Given the following information:
- Spec Inconsistency Explanation: {row['conflict_effect']}
- Matched CVE Description: {row['cve_description']}
- Inferred User Symptoms: {row['cve_effect']}

Task:
1. Is there a plausible causal link between the spec inconsistency and the CVE? (Answer only YES or NO)
2. Are the expected user symptoms aligned with the CVE description? (Answer only ALIGNED or NOT ALIGNED)
3. Give your confidence in the mapping (number between 0 and 10).
4. Briefly explain your reasoning (1 sentences).
"""

def gpt_validate(row):
    try:
        prompt = build_validation_prompt(row)
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=200
        )
        content = response.choices[0].message.content
        return content
    except Exception as e:
        print("Error:", e)
        return "GPT_ERROR"

validation_outputs = []

for idx, row in matches_df.iterrows():
    print(f"Processing {row['conflict_id']} â†” {row['cve_id']}...")
    output = gpt_validate(row)
    validation_outputs.append(output)
    time.sleep(1.2)  # to avoid hitting rate limits

matches_df['gpt_validation_output'] = validation_outputs


output_path = "/content/spec_to_cve_matches_validated_gpt.csv"
matches_df.to_csv(output_path, index=False)

print(f"GPT-assisted validation complete. Results saved to {output_path}")

# ============================================================
# Post-Process GPT Validation Outputs and Summarize
# ============================================================

import pandas as pd
import re

# Load the validated matches
data_path = "/content/spec_to_cve_matches_validated_gpt.csv"
matches_df = pd.read_csv(data_path)


def extract_field(pattern, text):
    match = re.search(pattern, text, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    else:
        return "UNKNOWN"

def parse_gpt_output(text):
    causal_link = extract_field(r"1\.\s*.*?\b(YES|NO)\b", text)
    symptom_alignment = extract_field(r"2\.\s*.*?\b(ALIGNED|NOT ALIGNED)\b", text)
    confidence = extract_field(r"3\.\s*.*?(\d{1,3})", text)
    reasoning = extract_field(r"4\.\s*(.+)", text)
    return causal_link, symptom_alignment, confidence, reasoning

# Apply parsing
causal_links, symptom_alignments, confidence_scores, reasonings = [], [], [], []

for output in matches_df['gpt_validation_output']:
    causal_link, symptom_alignment, confidence, reasoning = parse_gpt_output(output)
    causal_links.append(causal_link)
    symptom_alignments.append(symptom_alignment)
    confidence_scores.append(confidence)
    reasonings.append(reasoning)

matches_df['causal_link_gpt'] = causal_links
matches_df['symptom_alignment_gpt'] = symptom_alignments
matches_df['confidence_score_gpt'] = confidence_scores
matches_df['reasoning_gpt'] = reasonings


output_path = "/content/spec_to_cve_matches_validated_parsed.csv"
matches_df.to_csv(output_path, index=False)
print(f"Parsed validation results saved to {output_path}")


# Convert confidence scores to numeric
matches_df['confidence_score_gpt'] = pd.to_numeric(matches_df['confidence_score_gpt'], errors='coerce')

# Calculate stats
num_matches = len(matches_df)
causal_yes = (matches_df['causal_link_gpt'] == 'YES').sum()
symptom_aligned = (matches_df['symptom_alignment_gpt'] == 'ALIGNED').sum()
avg_confidence = matches_df['confidence_score_gpt'].mean()

print("\n Validation Summary:")
print(f"- Total Matches Validated: {num_matches}")
print(f"- Causal Links Found: {causal_yes} ({causal_yes/num_matches*100:.2f}%)")
print(f"- Symptom Alignment: {symptom_aligned} ({symptom_aligned/num_matches*100:.2f}%)")
print(f"- Average Confidence Score: {avg_confidence:.2f}")

filtered_matches = matches_df[
    (matches_df['causal_link_gpt'] == 'YES') &
    (matches_df['confidence_score_gpt'] >= 7)
]
filtered_matches.to_csv("/content/spec_to_cve_final_high_confidence.csv", index=False)
print(f"Final high-confidence matches: {len(filtered_matches)}")

avg_similarity = filtered_matches['similarity_score'].mean()
avg_confidence = filtered_matches['confidence_score_gpt'].mean()

print(f"Average similarity of validated matches: {avg_similarity:.2f}")
print(f"Average GPT confidence: {avg_confidence:.2f}")
print(f"Number of validated matches: {len(filtered_matches)}")

import matplotlib.pyplot as plt

# Similarity
plt.hist(filtered_matches['similarity_score'], bins=20, color='skyblue', edgecolor='black')
plt.title('Validated Matches: Similarity Score Distribution')
plt.xlabel('Similarity Score')
plt.ylabel('Count')
plt.grid(True)
plt.show()